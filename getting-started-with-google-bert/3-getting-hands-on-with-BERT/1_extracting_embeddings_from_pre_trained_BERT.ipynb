{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-extracting-embeddings-from-pre-trained-BERT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZ+gAbLSe5MmgNitb22dSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a7a0923e7fa46d79086dc1797d85fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a915535ca3b429ca311c5e333fd058d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e130d4e27d6f449484269a58e0cf8d25",
              "IPY_MODEL_e4323a1f1a714102b00ea20f2ac6c5fb"
            ]
          }
        },
        "9a915535ca3b429ca311c5e333fd058d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e130d4e27d6f449484269a58e0cf8d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f42601503134dc1a10db17cca1a5399",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_836e3adfd9724d2ba8b10224d946e0fa"
          }
        },
        "e4323a1f1a714102b00ea20f2ac6c5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2fb35b21bf4849d3a6ea608a721c61ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:10&lt;00:00, 40.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57f429ca4bf140b1b406a0124f12fbc4"
          }
        },
        "8f42601503134dc1a10db17cca1a5399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "836e3adfd9724d2ba8b10224d946e0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fb35b21bf4849d3a6ea608a721c61ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57f429ca4bf140b1b406a0124f12fbc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "643e15103cd84dc9b505f108599483bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5975baf17cda48c78ca3ed402ad757f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d44773cdfc74a25b9d8ad1a13647103",
              "IPY_MODEL_69e3bf2b9bb4428eadbd9d5f9442dc40"
            ]
          }
        },
        "5975baf17cda48c78ca3ed402ad757f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d44773cdfc74a25b9d8ad1a13647103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b007da44697f48e78b1dae41a7f79a15",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f6d1afe01b1489a8c1ed45dcbbaf02d"
          }
        },
        "69e3bf2b9bb4428eadbd9d5f9442dc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbeaa9bcabbf41a286574978461ff2a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 44.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33b21e76f1f14777b367083bbb7d191d"
          }
        },
        "b007da44697f48e78b1dae41a7f79a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f6d1afe01b1489a8c1ed45dcbbaf02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbeaa9bcabbf41a286574978461ff2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33b21e76f1f14777b367083bbb7d191d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd0354fb2de3437a83e2578ed62dd111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51ccd0beeadb4ee582eb2b9b4b52516e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2f9b44286094f12995d24bd9111f34c",
              "IPY_MODEL_2fa91d85cd1f4665a3c819a99c3a1455"
            ]
          }
        },
        "51ccd0beeadb4ee582eb2b9b4b52516e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2f9b44286094f12995d24bd9111f34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7a69782a23344998216495d3e44c077",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7895eb7c6c3402a942f5f30e9600e00"
          }
        },
        "2fa91d85cd1f4665a3c819a99c3a1455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99cb6232cf0c475c819b8a17cc309b20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 805kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e130bf51c3d44ce8bee124b448ed9b59"
          }
        },
        "a7a69782a23344998216495d3e44c077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7895eb7c6c3402a942f5f30e9600e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99cb6232cf0c475c819b8a17cc309b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e130bf51c3d44ce8bee124b448ed9b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/getting-started-with-google-bert/blob/main/3-getting-hands-on-with-BERT/1_extracting_embeddings_from_pre_trained_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-01JQRyEyPyK"
      },
      "source": [
        "## Extracting embeddings from pre-trained BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNSMwh6xyy5q"
      },
      "source": [
        "Pre-training BERT from scratch is computationally expensive. So, we can download the pre-trained BERT model and use it. Google has open sourced the pre-trained BERT model and we can download it from Google Research's GitHub repository – https://github.com/google-research/bert. They have released the pre-trained BERT model with various configurations.\n",
        "\n",
        "The pre-trained model is also available in the BERT-uncased and BERT-cased formats. In BERT-uncased, all the tokens are lowercased, but in BERT-cased, the tokens are not lowercased and are used directly for training. \n",
        "\n",
        "The BERT-uncased model is the one that is most commonly used, but if we are working on certain tasks such as **Named Entity Recognition (NER)** where we have to preserve the case, then we should use the BERT-cased model. Along with these, Google also released pre-trained BERT models trained using the whole word masking method.\n",
        "\n",
        "We can use the pre-trained model in the following two ways:\n",
        "- As a feature extractor by extracting embeddings\n",
        "- By fine-tuning the pre-trained BERT model on downstream tasks such as text\n",
        "classification, question-answering, and more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWWvPi3M1HOG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x28xzbu61xWn"
      },
      "source": [
        "**Hugging Face transformers**\n",
        "\n",
        "Hugging Face is an organization that is on a path to solve and democratize AI through natural language. Their open-source library 'transformers' is very popular among the NLP community. It is very useful and powerful for several NLP and NLU tasks. It includes thousands of pre-trained models in about 100+ languages. One of the many advantages of the transformer library is that it is compatible with both PyTorch and TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUvximYa1IeA"
      },
      "source": [
        "%%capture\n",
        "!pip install torch==1.4.0\n",
        "!pip install transformers==3.5.1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjC56MC91X7K"
      },
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADJ2dXfx1pln"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYEzpetO2Ge3"
      },
      "source": [
        "Consider a sentence – I love Paris. Say we need to extract the contextual embedding of each word in the sentence. To do this, first, we tokenize the sentence and feed the tokens to the pre-trained BERT model, which will return the embeddings for each of the tokens. Apart from obtaining the token-level (word-level) representation, we can also obtain the sentence-level\n",
        "representation.\n",
        "\n",
        "Let's suppose we want to perform a sentiment analysis task, and say we have the dataset shown in the following figure:\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/getting-started-with-google-bert/sample-dataset.png?raw=1' width='800'/>\n",
        "\n",
        "We have sentences and their corresponding labels, where 1 indicates positive sentiment and 0 indicates negative sentiment. We can train a classifier to classify the sentiment of a sentence using the given dataset.\n",
        "\n",
        "But we can't feed the given dataset directly to a classifier, since it has text. So first, we need to vectorize the text. We can vectorize the text using methods such as:-\n",
        "\n",
        "- TF-IDF, \n",
        "- word2vec,\n",
        "- BERT\n",
        "\n",
        "BERT learns the contextual embedding, unlike other context-free embedding models such as word2vec. Now, we will see how to use the pre-trained BERT model to vectorize the sentences in our dataset.\n",
        "\n",
        "Let's take the first sentence in our dataset – `I love Paris`. First, we tokenize the sentence using the WordPiece tokenizer and get the tokens (words).\n",
        "\n",
        "```\n",
        "tokens = [I, love, Paris]\n",
        "```\n",
        "\n",
        "Now, we add the `[CLS]` token at the beginning and the `[SEP]` token at the end.\n",
        "\n",
        "```\n",
        "tokens = [[CLS], I, love, Paris, [SEP]]\n",
        "```\n",
        "\n",
        "Similarly, we can tokenize all the sentences in our training set. But the length of each sentence varies, right? Yes, and so does the length of the tokens. We need to keep the length of all the tokens the same. \n",
        "\n",
        "Say we keep the length of the tokens to 7 for all the sentences in\n",
        "our dataset. If we look at our preceding tokens list, the tokens length is 5. To make the tokens length 7, we add a new token called `[PAD]`.\n",
        "\n",
        "```\n",
        "tokens = [[CLS], I, love, Paris, [SEP], [PAD], [PAD]]\n",
        "```\n",
        "\n",
        "As we can observe, now our tokens length is 7, as we have added two [PAD] tokens. \n",
        "\n",
        "**The next step is to make our model understand that the `[PAD]` token is added only to match the tokens length and it is not part of the actual tokens. To do this, we introduce an attention mask. We set the attention mask value to 1 in all positions and 0 to the position where we have a `[PAD]` token.**\n",
        "\n",
        "```\n",
        "attention_mask = [ 1,1,1,1,1,0,0]\n",
        "```\n",
        "\n",
        "Next, we map all the tokens to a unique token ID. Suppose the following is the mapped token ID:\n",
        "\n",
        "```\n",
        "token_ids = [101, 1045, 2293, 3000, 102, 0, 0]\n",
        "```\n",
        "\n",
        "It implies that ID 101 indicates the token [CLS], 1045 indicates the token I, 2293 indicates the token Love, and so on.\n",
        "\n",
        "**Now, we feed token_ids along with attention_mask as input to the pre-trained BERT model and obtain the vector representation (embedding) of each of the tokens.**\n",
        "\n",
        "As we can see, once we feed the tokens as the input, encoder 1 computes the representation of all the tokens and sends it to the next encoder, which is encoder 2. Encoder 2 takes the representation computed by encoder 1 as input, computes its representation, and sends it to the next encoder, which is encoder 3. In this way, each encoder sends its representation to the next\n",
        "encoder above it. The final encoder, which is encoder 12, returns the\n",
        "final representation (embedding) of all the tokens in our sentence:\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/getting-started-with-google-bert/pre-trained-BERT.png?raw=1' width='800'/>\n",
        "\n",
        "**Thus, in this way, we can obtain the representation of each of the tokens. These representations are basically the contextualized word (token) embeddings.** Say we are using the pre-trained BERT-base model; in that case, the representation size of each token is 768.\n",
        "\n",
        "We learned how to obtain the representation for each word in the sentence I love Paris. But how do we obtain the representation of the complete sentence?\n",
        "\n",
        "We learned that we have prepended the `[CLS]` token to the beginning of our sentence. The representation of the `[CLS]` token will hold the aggregate representation of the complete sentence. So, we can ignore the embeddings of all other tokens and take the embedding of the `[CLS]` token and assign it as a representation of our sentence. Thus, the representation of our sentence I love Paris is just the representation of the `[CLS]` token $R_{[CLS]}$.\n",
        "\n",
        "In a very similar fashion, we can compute the vector representation of all the sentences in our training set. Once we have the sentence representation of all the sentences in our training set, we can feed those representations as input and train a classifier to perform a sentiment analysis task.\n",
        "\n",
        "**Note that using the representation of the `[CLS]` token as a sentence representation is not always a good idea. The efficient way to obtain the representation of a sentence is either averaging or pooling the representation of all the tokens.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRIFkzvFAJzP"
      },
      "source": [
        "## Generating BERT embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_GOc2HcAKtN"
      },
      "source": [
        "We will learn how to extract embeddings from the pre-trained BERT model.\n",
        "Consider the sentence I love Paris. Let's see how to obtain the contextualized word embedding of all the words in the sentence using the pre-trained BERT model with Hugging Face's transformers library.\n",
        "\n",
        "We use the 'bert-base-uncased' model. As the name suggests, it is the BERT-base model with 12 encoders and it is trained with uncased tokens. Since we are using BERTbase, the representation size will be 768."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n0ByK_Z4AyK",
        "outputId": "f41e3834-e8b4-430c-e6b8-aff4b80a41a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "3a7a0923e7fa46d79086dc1797d85fe6",
            "9a915535ca3b429ca311c5e333fd058d",
            "e130d4e27d6f449484269a58e0cf8d25",
            "e4323a1f1a714102b00ea20f2ac6c5fb",
            "8f42601503134dc1a10db17cca1a5399",
            "836e3adfd9724d2ba8b10224d946e0fa",
            "2fb35b21bf4849d3a6ea608a721c61ee",
            "57f429ca4bf140b1b406a0124f12fbc4",
            "643e15103cd84dc9b505f108599483bf",
            "5975baf17cda48c78ca3ed402ad757f5",
            "9d44773cdfc74a25b9d8ad1a13647103",
            "69e3bf2b9bb4428eadbd9d5f9442dc40",
            "b007da44697f48e78b1dae41a7f79a15",
            "7f6d1afe01b1489a8c1ed45dcbbaf02d",
            "cbeaa9bcabbf41a286574978461ff2a4",
            "33b21e76f1f14777b367083bbb7d191d"
          ]
        }
      },
      "source": [
        "# Download and load the pre-trained bert-base-uncased model\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a7a0923e7fa46d79086dc1797d85fe6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "643e15103cd84dc9b505f108599483bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVZC3T2D4T3k"
      },
      "source": [
        "Next, we download and load the tokenizer that was used to pre-train the `bert-baseuncased` model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JznTE32L4TEC",
        "outputId": "759c2c9e-775f-4642-8c23-5e815d65e00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "cd0354fb2de3437a83e2578ed62dd111",
            "51ccd0beeadb4ee582eb2b9b4b52516e",
            "e2f9b44286094f12995d24bd9111f34c",
            "2fa91d85cd1f4665a3c819a99c3a1455",
            "a7a69782a23344998216495d3e44c077",
            "b7895eb7c6c3402a942f5f30e9600e00",
            "99cb6232cf0c475c819b8a17cc309b20",
            "e130bf51c3d44ce8bee124b448ed9b59"
          ]
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd0354fb2de3437a83e2578ed62dd111",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vq7Hsqo5dof"
      },
      "source": [
        "### Preprocessing the input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSR0HsRw5ena"
      },
      "source": [
        "Now, let's see how to preprocess the input before feeding it to BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT-dhPyt5P85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5b405d-7e8e-42ad-c62a-f7b2554b70c5"
      },
      "source": [
        "# Define the sentence\n",
        "sentence = \"I love Paris\"\n",
        "\n",
        "# Tokenize the sentence and obtain the tokens\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'love', 'paris']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGn8OfiZ5798"
      },
      "source": [
        "Now, we will add the `[CLS]` token at the beginning and the `[SEP]` token at the end of the tokens list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu2FYQXR54Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572043fd-53f3-4a53-ece9-94f807cf9479"
      },
      "source": [
        "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "print(tokens)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'i', 'love', 'paris', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPcEgKfh6kTt"
      },
      "source": [
        "As we can observe, we have a `[CLS]` token at the beginning and an `[SEP]` token at the end of our tokens list. We can also see that length of our tokens list is 5.\n",
        "\n",
        "Say we need to keep the length of our tokens list to 7; in that case, we add two `[PAD]` tokens at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb2kelXX6Lav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b44adb-237c-4a9e-e6ba-3c22740f71a3"
      },
      "source": [
        "tokens = tokens + [\"[PAD]\"] + [\"[PAD]\"]\n",
        "print(tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'i', 'love', 'paris', '[SEP]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk_-Bysk7B0U"
      },
      "source": [
        "As we can see, now we have the tokens list with `[PAD]` tokens and the length of our tokens list is 7.\n",
        "\n",
        "Next, we create the attention mask. We set the attention mask value to 1 if the token is not a `[PAD]` token, else we set the attention mask to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFLzGD469wC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac43c9f-17b0-4242-da7e-bce57a4308d0"
      },
      "source": [
        "attention_mask = [1 if i != '[PAD]' else 0 for i in tokens]\n",
        "print(attention_mask)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn5QGkHJ7e9C"
      },
      "source": [
        "As we can see, we have attention mask values 0 at positions where have a `[PAD]` token and 1 at other positions.\n",
        "\n",
        "Next, we convert all the tokens to their token IDs as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJVkdgT57YnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911850c7-189e-42de-8360-e4397d52b7b2"
      },
      "source": [
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(token_ids)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1045, 2293, 3000, 102, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1swT50Y7zOI"
      },
      "source": [
        "From the output, we can observe that each token is mapped to a unique token ID.\n",
        "\n",
        "Now, we convert token_ids and attention_mask to tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kOLKJf67toP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33436f3f-fae9-4d79-db0e-69ff67bb0c3e"
      },
      "source": [
        "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
        "attention_mask = torch.tensor(attention_mask).unsqueeze(0)\n",
        "print(token_ids)\n",
        "print(attention_mask)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 101, 1045, 2293, 3000,  102,    0,    0]])\n",
            "tensor([[1, 1, 1, 1, 1, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG1AkkzK8aEE"
      },
      "source": [
        "**That's it. Next, we feed token_ids and attention_mask to the pre-trained BERT model and get the embedding.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnEOvW4K8rgi"
      },
      "source": [
        "### Getting the embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8bfFbNN8tCJ"
      },
      "source": [
        "We feed `token_ids` and `attention_mask` to `model` and get the embeddings. Note that `model` returns the output as a tuple with two values. The first value indicates the hidden state representation, `hidden_rep`, and it consists of the representation of all the tokens obtained from the final encoder (encoder 12), and the second value, `cls_head`, consists of the representation of the `[CLS]` token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGgMwFbdChOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0dab06-17df-496d-ce72-086978531c11"
      },
      "source": [
        "hidden_rep, cls_head = model(token_ids, attention_mask=attention_mask)\n",
        "\n",
        "# hidden_rep contains the embedding (representation) of all the tokens in our input\n",
        "print(hidden_rep.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 7, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LywA_1sLJbG"
      },
      "source": [
        "The size `[1,7,768]` indicates `[batch_size, sequence_length, hidden_size]`.\n",
        "\n",
        "Our batch size is 1, the sequence length is the token length, since we have 7 tokens, the sequence length is 7, and the hidden size is the representation (embedding) size and it is 768 for the BERT-base model.\n",
        "\n",
        "We can obtain the representation of each token as:\n",
        "\n",
        "- `hidden_rep[0][0]` gives the representation of the first token which is `[CLS]`\n",
        "- `hidden_rep[0][1]` gives the representation of the second token which is 'I'\n",
        "- `hidden_repo[0][2]` gives the representation of the third token which is 'love'\n",
        "\n",
        "In this way, we can obtain the contextual representation of all the tokens. This is basically the contextualized word embeddings of all the words in the given sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Mh15CzMA4C"
      },
      "source": [
        "Now, let's take a look at the cls_head. It contains the representation of the `[CLS]` token. Let's print the shape of cls_head :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9bwVXbSMci1",
        "outputId": "98086957-a1c5-4040-c75c-faa27814bb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(cls_head.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns7px0prMjzF"
      },
      "source": [
        "The size `[1,768]` indicates `[batch_size, hidden_size]`.\n",
        "\n",
        "We learned that `cls_head` holds the aggregate representation of the sentence, so we can use `cls_head` as the representation of the sentence `I love Paris`.\n",
        "\n",
        "We learned how to extract embeddings from the pre-trained BERT model. But these are the embeddings obtained only from the topmost encoder layer of BERT, which is encoder 12.\n",
        "\n",
        "But we can also extract the embeddings from all the encoder layers of BERT."
      ]
    }
  ]
}