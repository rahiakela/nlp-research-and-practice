{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0hK4nU35JVaA",
        "N4dDTs-rJL_h",
        "TycHgKTZJ6a6"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMY8UaEnhpjwiwieGa/KpBZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/text-similarity-works/13_icd_10_code_highlight_with_keyword_match_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "u6vazPC0Ja4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install -U pdftotext\n",
        "!pip install PyPDF2\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "gdwgVvXuJdz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "id": "4QPcnYT5AKpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import difflib\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "import fitz\n",
        "import pdftotext\n",
        "from PyPDF2 import PdfFileReader, PdfReader, PdfFileWriter, PdfWriter\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.lang.en import English\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from string import punctuation\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ],
      "metadata": {
        "id": "gKbd7WsfyYX3",
        "outputId": "8400bfa7-eeaf-4805-cc4d-43e2a63ed6c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "/usr/local/lib/python3.8/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Imv6fB5gPBe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p input_files"
      ],
      "metadata": {
        "id": "2dfljcHuOVw3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Classes"
      ],
      "metadata": {
        "id": "9oNqjgIsRpNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Highlighter:\n",
        "  def __init__(self, code_df):\n",
        "    # loading and updating patterns for ICD-10 code\n",
        "    self.nlp_code10 = English()\n",
        "    self.nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"icd10_code_patterns-v5.jsonl\")\n",
        "\n",
        "    # define icd-10 code dataset\n",
        "    self.code_df = code_df\n",
        "    self.text_list = None\n",
        "\n",
        "    # define required directory path\n",
        "    self.PDF_FILES_PATH = \"pdf-files\"\n",
        "    self.TXT_FILES_PATH = \"txt-files\"\n",
        "    self.OUTPUT_FILES_PATH = \"output\"\n",
        "    create_directory(self.PDF_FILES_PATH)\n",
        "    create_directory(self.TXT_FILES_PATH)\n",
        "    create_directory(self.OUTPUT_FILES_PATH)\n",
        "\n",
        "  def split_pdf(self, pdf_path):\n",
        "      pdf_in_file = open(pdf_path, \"rb\")\n",
        "      pdf = PdfReader(pdf_in_file)\n",
        "      pdf_list = []\n",
        "      for page in range(len(pdf.pages)):\n",
        "          input_pdf = PdfReader(pdf_in_file)\n",
        "          output = PdfWriter()\n",
        "          #output.addPage(input_pdf.getPage(page))\n",
        "          output.add_page(input_pdf.pages[page])\n",
        "          with open(f\"{self.PDF_FILES_PATH}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "              output.write(outputStream)\n",
        "              pdf_list.append(f\"page-{page}.pdf\")\n",
        "      return pdf_list\n",
        "\n",
        "  def extract_text_from_pdf(self, pdf_list):\n",
        "    txt_file_list = []\n",
        "    i = 0\n",
        "    for pdf_file in pdf_list:\n",
        "      with open(os.path.join(self.PDF_FILES_PATH, pdf_file), \"rb\") as f:\n",
        "        pdf = pdftotext.PDF(f)\n",
        "\n",
        "      # Read all the text into one string\n",
        "      pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "      # write text into file\n",
        "      with open(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\", \"a\") as f:\n",
        "        f.write(pdf_text)\n",
        "      txt_file_list.append(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\")\n",
        "      i += 1\n",
        "    self.text_list = txt_file_list\n",
        "    return txt_file_list\n",
        "\n",
        "  def highlight_icd_code(self, icd10_code_dict, w_ratio=False, match_threshold=30, coordinate=False, pdf_file_name=None, cords_file_name=None):\n",
        "      pdf_file = fitz.open(pdf_file_name)\n",
        "      # create file to write coordinate\n",
        "      txt_output_file_name = open(f\"{self.OUTPUT_FILES_PATH}/{cords_file_name}\", \"a\")\n",
        "      # add file header \n",
        "      txt_output_file_name.write(\"| Page | Found Code | Actual ICD10-Code | Code Line # | ICD 10 description | Matched Line | Common Words | Matched Line # | confidence |\\n \")\n",
        "\n",
        "      def highlight_pdf(p_highlight, icd10_code, num_page):\n",
        "        match_list = []\n",
        "        sentence_list = []\n",
        "        line_list = []\n",
        "        keyword = \"\"\n",
        "        \n",
        "        # do the color coding\n",
        "        keyword = self.get_keyword(icd10_code)\n",
        "        if len(keyword) > 0:\n",
        "          match_list, sentence_list, line_list = self.get_best_token_match(icd10_code, num_page, w_ratio, match_threshold)\n",
        "          # highlight code if threshold is more than 30\n",
        "          if match_list and match_list[0][1] >= match_threshold:\n",
        "            page_highlight = page.add_highlight_annot(p_highlight)\n",
        "            page_highlight.set_colors(stroke=[0.66, 1, 0.07])  # light green\n",
        "            page_highlight.update()\n",
        "        return match_list, sentence_list, line_list, keyword\n",
        "\n",
        "      for page_num, page in enumerate(pdf_file):\n",
        "        # highlight ICD-10 code\n",
        "        if page_num in icd10_code_dict:\n",
        "          for code in icd10_code_dict[page_num]:\n",
        "            highlight_list = page.search_for(code)\n",
        "            print(f\"Code: {code}, Coordinate: {highlight_list}\")\n",
        "            # highlight pdf \n",
        "            for highlight in highlight_list:\n",
        "              match_list, sentence_list, line_list, keyword = highlight_pdf(highlight, code, page_num)\n",
        "              # write all info into text file\n",
        "              curr_match_score = 0.0\n",
        "              num_page = page_num + 1\n",
        "              for idx, match_found in enumerate(match_list):\n",
        "                curr_match_score = match_found[1]\n",
        "                if match_found[1] >= match_threshold:\n",
        "                  # | Page | Found Code | Actual ICD10-Code | Code Line # | ICD 10 description | Matched Line| Common Words | Matched Line # | confidence | \n",
        "                  code_cors_output = f\"|Page-{num_page} | {code} | {reverse_code_pattern(code)} | {line_list} | {keyword if keyword else 'Not available'} | {match_found[0]} | {get_common_words(keyword, match_found[0])} | {sentence_list.index(match_found[0]) + 1} | {match_found[1]} |\"\n",
        "                  txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "                break\n",
        "\n",
        "              if coordinate and curr_match_score >= match_threshold:\n",
        "                txt_output_file_name.write(\"%s\\n\" % f\"|{highlight}|\")\n",
        "              txt_output_file_name.write(\"\\n\") # add extra line on every match code\n",
        "\n",
        "      txt_output_file_name.close()\n",
        "\n",
        "      pdf_output_file_name = f\"{self.OUTPUT_FILES_PATH}/{pdf_file_name.split('/')[1].split('.')[0]}_output.pdf\"\n",
        "      pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "      return pdf_output_file_name, cords_file_name\n",
        "\n",
        "  def get_opt_pattern(self, icd_10_code):\n",
        "    # create alternate pattern\n",
        "    code_arr = icd_10_code.split(\".\")\n",
        "    if len(code_arr) > 1:\n",
        "      code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "      code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "      code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "      return [code1, code2, code3]\n",
        "    else:\n",
        "      return icd_10_code\n",
        "\n",
        "  def search_icd_code(self, txt_list):\n",
        "    pdf_page_vocab = {}\n",
        "    for txt_file in txt_list:\n",
        "      with open(txt_file, \"r\") as f:\n",
        "        page_txt = f.read()\n",
        "\n",
        "        # check the page that have line number instead of code\n",
        "        index_page = False\n",
        "        if re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "          index_page = True\n",
        "\n",
        "        doc = self.nlp_code10(page_txt)\n",
        "        code_list = []\n",
        "        for ent in doc.ents:\n",
        "          if index_page:\n",
        "            # check the code contain letter \"L\"\n",
        "            if re.search(\"(L[0-9]+)\", ent.text):\n",
        "              continue\n",
        "            else:\n",
        "              code_list.append(ent.text)\n",
        "          else:\n",
        "            code_list.append(ent.text)\n",
        "\n",
        "        #code_list = [ent.text for ent in doc.ents if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", ent.text)]\n",
        "        if len(code_list) != 0:\n",
        "          page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "          pdf_page_vocab[page_number] = list(set(code_list)) \n",
        "          # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "    return pdf_page_vocab\n",
        "\n",
        "  def get_keyword(self, p_code):\n",
        "    keyword = \"\"\n",
        "    # reverse code if required\n",
        "    code = reverse_code_pattern(p_code)\n",
        "    # get keyword from dataset\n",
        "    keyword_list = list(self.code_df.loc[self.code_df[\"Code\"] == code][\"Keyword\"])\n",
        "    if len(keyword_list) > 0:\n",
        "      keyword = keyword_list[0]\n",
        "    return keyword\n",
        "\n",
        "  def get_best_token_match(self, p_code, num_page, w_ratio, match_threshold):\n",
        "    # Step 1: reverse code pattern\n",
        "    reversed_icd_code = reverse_code_pattern(p_code)\n",
        "    # Step 2: fetch keyword based on code \n",
        "    keyword = self.get_keyword(reversed_icd_code)\n",
        "    # Step 3: prepare sentence list \n",
        "    sentence_list = get_sentence_list(self.text_list, num_page)\n",
        "    # Step 4: get best match token ratio or wratio\n",
        "    if w_ratio:\n",
        "      match_list = [(sentence, fuzz.WRatio(keyword, sentence)) for sentence in sentence_list if fuzz.WRatio(keyword, sentence) > match_threshold]\n",
        "    else:\n",
        "      match_list = [(sentence, fuzz.token_set_ratio(keyword, sentence)) for sentence in sentence_list if fuzz.token_set_ratio(keyword, sentence) > match_threshold]\n",
        "    # Step 5: get sentence line\n",
        "    line_list = get_sentence_line(p_code, sentence_list)\n",
        "    return sort_tuple(match_list), sentence_list, line_list\n",
        "\n",
        "  def get_match_sentence_and_line_data(self, p_code, num_page):\n",
        "    # Step 1: reverse code pattern\n",
        "    reversed_icd_code = reverse_code_pattern(p_code)\n",
        "    # Step 2: fetch keyword based on code \n",
        "    keyword = self.get_keyword(reversed_icd_code)\n",
        "    # Step 3: prepare sentence list \n",
        "    sentence_list = get_sentence_list(self.text_list, num_page)\n",
        "    # Step 4: get best 3 match ratio \n",
        "    match_list = process.extract(keyword, sentence_list, scorer = fuzz.ratio, limit = 3)\n",
        "    # Step 5: get sentence line\n",
        "    line_list = get_sentence_line(p_code, sentence_list)\n",
        "    return match_list, sentence_list, line_list\n",
        "\n",
        "def get_common_words(sent1, sent2):\n",
        "  sent1 = set(sent1.replace(\",\", \"\").lower().split())\n",
        "  sent2 = set(sent2.replace(\",\", \"\").lower().split())\n",
        "  return list(sent1 & sent2)\n",
        "\n",
        "def get_sentence_line(p_code, sentence_list):\n",
        "  line_list = [(line + 1) for line, sent in enumerate(sentence_list) if p_code in sent]\n",
        "  return line_list\n",
        "\n",
        "def get_sentence_list(text_list, num_page):\n",
        "  with open(f\"{text_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "  return sentence_list\n",
        "\n",
        "def reverse_code_pattern(p_code):\n",
        "  orig_code = p_code\n",
        "\n",
        "  # check for code contains space(\" \")\n",
        "  tmp_code = orig_code.split(\" \")\n",
        "  if len(tmp_code) > 1:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "\n",
        "  # check for code contains dot(\".\")\n",
        "  tmp_code = p_code.split(\".\")\n",
        "  if len(tmp_code) > 1:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "  \n",
        "  # check for code contains comma(\",\")\n",
        "  tmp_code = p_code.split(\",\")\n",
        "  if len(tmp_code) == 2:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "  elif len(tmp_code) == 2:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[2].strip()}\"\n",
        "\n",
        "  # handle if the first char of code is missing\n",
        "  alphabats = {\"Z\": \"2\", \"B\": \"8\", \"O\": \"0\", \"S\": \"5\", \"l\": \"1\", \"G\": \"6\", \"o\": \"9\", \"i\": \"1\"}\n",
        "  for key, val in alphabats.items():\n",
        "    # replcae char on 0 index\n",
        "    if orig_code.find(val) == 0:\n",
        "      #orig_code = orig_code.replace(val, key)\n",
        "      orig_code = replacer(orig_code, key, 0)\n",
        "    # replcae char on 1 index\n",
        "    if orig_code.find(key) == 1:\n",
        "      orig_code = replacer(orig_code, val, 1)\n",
        "      # replcae char on 2 index\n",
        "      if orig_code.find(key) == 2:\n",
        "        orig_code = replacer(orig_code, val, 2)\n",
        "      break\n",
        "\n",
        "  return orig_code\n",
        "\n",
        "def replacer(s, newstring, index, nofail=False):\n",
        "  # raise an error if index is outside of the string\n",
        "  if not nofail and index not in range(len(s)):\n",
        "      raise ValueError(\"index outside given string\")\n",
        "\n",
        "  # if not erroring, but the index is still not in the correct range..\n",
        "  if index < 0:  # add it to the beginning\n",
        "      return newstring + s\n",
        "  if index > len(s):  # add it to the end\n",
        "      return s + newstring\n",
        "\n",
        "  # insert the new string between \"slices\" of the original\n",
        "  return s[:index] + newstring + s[index + 1:]\n",
        "\n",
        "def sort_tuple(p_tup):\n",
        "  return(sorted(p_tup, key = lambda x: x[1], reverse=True)) \n",
        "\n",
        "def create_directory(dir_name):\n",
        "  if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)"
      ],
      "metadata": {
        "id": "jRYlndgDUtds"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Keyword Matching & Highlighting "
      ],
      "metadata": {
        "id": "7s7ZxYMUBAol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Step 1 - Z87.5\n",
        "- Step 2 - Personal history of complications of pregnancy, childbirth and the puerperium\n",
        "- Step 3 - Page keyword\n",
        "- Step 4 - calculate cosine similirity\n",
        "- Step 5 - \"Green\" > 60% otherwise \"Yellow\""
      ],
      "metadata": {
        "id": "9KDyJlx9bIH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input_files\n",
        "!mkdir -p input_files\n",
        "!rm -rf output\n",
        "!mkdir -p output"
      ],
      "metadata": {
        "id": "wfJwndx9vcTP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "32V_ohLAgvLg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: create highlighter instance\n",
        "INPUT_PDF_FILES_PATH = \"input_files\"\n",
        "code_df = pd.read_csv(\"icd_10_code_and_keywords_v2.csv\")\n",
        "\n",
        "highlighter = Highlighter(code_df)"
      ],
      "metadata": {
        "id": "leBmw505CQUl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for pdf_file in os.listdir(INPUT_PDF_FILES_PATH):\n",
        "  pdf_file_name = f\"{INPUT_PDF_FILES_PATH}/{pdf_file}\"\n",
        "  cords_file_name = f\"{pdf_file_name.split('/')[1].split('.')[0]}_cords.txt\"\n",
        "\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = highlighter.split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = highlighter.extract_text_from_pdf(pdf_list)\n",
        "\n",
        "  # Step-3: Searching ICD-10 code\n",
        "  icd10_code_dict = highlighter.search_icd_code(txt_list)\n",
        "\n",
        "  # Step-4: Highlighting ICD-10 code into pdf\n",
        "  pdf_output_file, txt_output_file = highlighter.highlight_icd_code(icd10_code_dict,\n",
        "                                                                    w_ratio=False,\n",
        "                                                                    match_threshold=45,\n",
        "                                                                    coordinate=True,\n",
        "                                                                    pdf_file_name=pdf_file_name,\n",
        "                                                                    cords_file_name=cords_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "id": "hiOT-aTfedMT",
        "outputId": "3f13b537-eaaa-4007-ed33-d03d3709f21d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: G47.33, Coordinate: [Rect(362.69000244140625, 463.8531494140625, 388.92999267578125, 474.84515380859375)]\n",
            "Code: G25.81, Coordinate: [Rect(362.69000244140625, 447.8531494140625, 388.92999267578125, 458.84515380859375)]\n",
            "Code: K57.92, Coordinate: [Rect(363.13800048828125, 431.8531494140625, 388.489990234375, 442.84515380859375)]\n",
            "Code: G43.909, Coordinate: [Rect(360.46600341796875, 383.8531494140625, 391.15399169921875, 394.84515380859375)]\n",
            "Code: G47.9, Coordinate: [Rect(364.91400146484375, 479.8531494140625, 386.70599365234375, 490.84515380859375)]\n",
            "Code: R00.9, Coordinate: [Rect(365.13800048828125, 351.8531494140625, 386.48199462890625, 362.84515380859375)]\n",
            "Code: G56.00, Coordinate: [Rect(362.69000244140625, 367.8531494140625, 388.92999267578125, 378.84515380859375)]\n",
            "Code: Z91.81, Coordinate: [Rect(363.36199951171875, 415.8531494140625, 388.2659912109375, 426.84515380859375)]\n",
            "Code: Z87.891, Coordinate: [Rect(361.13800048828125, 335.8531494140625, 390.489990234375, 346.84515380859375)]\n",
            "Code: E66.9, Coordinate: [Rect(365.36199951171875, 495.8531494140625, 386.2659912109375, 506.84515380859375)]\n",
            "Code: F41.9, Coordinate: [Rect(365.58599853515625, 511.8531188964844, 386.0419921875, 522.8451538085938)]\n",
            "Code: G64, Coordinate: [Rect(368.25, 399.8531494140625, 383.3699951171875, 410.84515380859375)]\n",
            "Code: G47.33, Coordinate: [Rect(144.94007873535156, 539.9200439453125, 162.4605255126953, 547.9239501953125)]\n",
            "Code: R06.83, Coordinate: [Rect(119.25902557373047, 551.7020263671875, 136.0590362548828, 558.7054443359375)]\n",
            "Code: G47.8, Coordinate: [Rect(144.78759765625, 560.7210083007812, 158.6255645751953, 567.7244262695312)]\n",
            "Code: RO6.3, Coordinate: [Rect(151.5601043701172, 580.2410278320312, 165.0604705810547, 588.2449340820312)]\n",
            "Code: G47.10, Coordinate: [Rect(344.2001037597656, 570.1610107421875, 362.8005065917969, 578.1649169921875)]\n",
            "Code: G47,39, Coordinate: [Rect(364.7200622558594, 550.093017578125, 382.2403259277344, 557.096435546875)]\n",
            "Code: G47.31, Coordinate: [Rect(131.78009033203125, 570.1610107421875, 149.18060302734375, 578.1649169921875)]\n",
            "Code: G47.34, Coordinate: [Rect(356.2000732421875, 539.9200439453125, 374.44049072265625, 547.9239501953125)]\n",
            "Code: O41, Coordinate: [Rect(392.39984130859375, 321.8952941894531, 398.8148498535156, 331.944580078125)]\n",
            "Code: O80, Coordinate: [Rect(418.31292724609375, 334.06817626953125, 425.3973083496094, 343.1217346191406)]\n",
            "Code: O68, Coordinate: [Rect(367.91259765625, 334.0444030761719, 374.86065673828125, 343.0969543457031)]\n",
            "Code: O00, Coordinate: [Rect(418.3200378417969, 321.90771484375, 425.14007568359375, 331.9598388671875)]\n",
            "File[output/01_final_output.pdf] is saved after highlighting ICD-10 code\n",
            "Highlighted coordinates are saved into [01_final_cords.txt] file.\n",
            "CPU times: user 1.59 s, sys: 62.4 ms, total: 1.65 s\n",
            "Wall time: 1.67 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "JlOdZaO9IL5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip output/*.*"
      ],
      "metadata": {
        "id": "MeS8LHhjjfzU",
        "outputId": "12fd02f6-b56a-4fca-a983-a63ad1ddae7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output/01_final_cords.txt (deflated 77%)\n",
            "  adding: output/01_final_output.pdf (deflated 9%)\n",
            "  adding: output/APS_38600000R_final_cords.txt (deflated 83%)\n",
            "  adding: output/APS_38600000R_final_output.pdf (deflated 1%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip pdf_text_output.zip pdf-files/*.* txt-files/*.*"
      ],
      "metadata": {
        "id": "AsPhCIH-h1Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: spliting pdf file\n",
        "pdf_file_name = \"APS_38600000R_final.pdf\"\n",
        "pdf_list = highlighter.split_pdf(pdf_file_name)\n",
        "\n",
        "# Step-2: Extracting text from pdf\n",
        "txt_list = highlighter.extract_text_from_pdf(pdf_list)"
      ],
      "metadata": {
        "id": "GJrJ862VBKhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Searching ICD-10 code\n",
        "page_code10_dict = highlighter.search_icd_code(txt_list)"
      ],
      "metadata": {
        "id": "wTFQkZtHBiLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_df = pd.read_csv(\"icd_10_code_and_keywords_v2.csv\")"
      ],
      "metadata": {
        "id": "1cqncdV0Lpj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Find keyword match"
      ],
      "metadata": {
        "id": "UK0Bb4L__7rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_match(text_file, keyword):\n",
        "  with open(text_file) as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "    ratios = [fuzz.ratio(keyword, line) for line in lines]\n",
        "    best_match = lines[ratios.index(max(ratios))]\n",
        "    print(f\"{lines.index(best_match) + 1}:{keyword}, {fuzz.partial_ratio(keyword, best_match)}: {best_match}\")"
      ],
      "metadata": {
        "id": "5LaNVFvDAjUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[7]}\", \"r\") as f:\n",
        "  lines = [line.rstrip('\\n') for line in f]\n",
        "  lines = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "lines"
      ],
      "metadata": {
        "id": "Ywx50dACOT5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similarity_score(keyword, text_file):\n",
        "  # load text file\n",
        "  with open(text_file, \"r\") as f:\n",
        "    my_text = f.read()\n",
        "\n",
        "  # prepare key phrase\n",
        "  key_phrase_list = []\n",
        "  for textlist in my_text.split(\"\\n\"):\n",
        "    for key_phrase in textlist.split(\",\"):\n",
        "      if len(key_phrase) > 0:\n",
        "        key_phrase_list.append(key_phrase)\n",
        "  # get max similarity score\n",
        "  score_list = [SequenceMatcher(None, k_phrase, keyword).ratio() for k_phrase in key_phrase_list]\n",
        "  max_score = max(score_list)\n",
        "  # get index position\n",
        "  index_pos = score_list.index(max_score)\n",
        "  # get most similar phrase\n",
        "  most_similar_phrase = key_phrase_list[index_pos]\n",
        "  return max_score, most_similar_phrase"
      ],
      "metadata": {
        "id": "w6oOPyyNcd4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_similarity_score(\"Snoring\", txt_list[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wikn8KpBd2VT",
        "outputId": "4efa55d1-5739-49a6-e23f-a1c5f30ff572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3333333333333333, ' octigraphy')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[7]}\", \"r\") as f:\n",
        "  my_text = f.read()\n",
        "for keyword in my_text.split(\",\"):\n",
        "  seq = SequenceMatcher(None, keyword, \"Snoring\")\n",
        "  print(f\"{round(seq.ratio(), 3)} : {keyword}\")\n",
        "  if round(seq.ratio(), 3) > .70:\n",
        "    print(f\"Max ratio found: {round(seq.ratio(), 3)} : {keyword}\")"
      ],
      "metadata": {
        "id": "vBZpE5-zZYlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text clean up"
      ],
      "metadata": {
        "id": "tCMut1zqMm76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[7]}\", \"r\") as f:\n",
        "  my_text = f.read()"
      ],
      "metadata": {
        "id": "qaQ1wb0PMyMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(my_text)\n",
        "sentences = [sentence.text for sentence in doc.sents]"
      ],
      "metadata": {
        "id": "nwcAI5BnMuzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "id": "E5SUHuvrPRn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(text_file):\n",
        "  sentence_list = []\n",
        "  stopwords = [\"is\", \"a\"]\n",
        "  doc = nlp(my_text)\n",
        "  sentences = [sentence.text for sentence in doc.sents]\n",
        "  for sent in sentences:\n",
        "    clean_text = \" \".join(sent.split())  # Remove extra spaces, tabs, and line breaks\n",
        "    clean_text = re.sub(f\"[{re.escape(punctuation)}]\", \"\", clean_text) # Remove punctuation\n",
        "    clean_text = re.sub(r\"\\b[0-9]+\\b\\s*\", \"\", clean_text)     # Remove numbers\n",
        "    clean_text = \" \".join([w for w in clean_text.split() if not w.isdigit()]) # Remove digits= Side effect: removes extra spaces\n",
        "    clean_text = \" \".join([w for w in clean_text.split() if w.isalpha()]) # Remove non-alphabetic characters= Side effect: removes extra spaces\n",
        "    clean_text = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", clean_text) # Remove all special characters and punctuation\n",
        "    # Remove stopwords from a list\n",
        "    tokens = clean_text.split()\n",
        "    clean_tokens = [t for t in tokens if not t in stopwords]\n",
        "    clean_text = \" \".join(clean_tokens)\n",
        "    # Remove short tokens\n",
        "    tokens = clean_text.split()\n",
        "    clean_tokens = [t for t in tokens if len(t) > 3]\n",
        "    clean_text = \" \".join(clean_tokens)\n",
        "    # Remove repeated characters\n",
        "    clean_text = re.sub(r'(.)\\1{3,}',r'\\1', clean_text)\n",
        "    if len(clean_text) > 0:\n",
        "      sentence_list.append(clean_text)\n",
        "  return sentence_list"
      ],
      "metadata": {
        "id": "QnlOii79PXSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = text_preprocess(my_text)\n",
        "sentence_list"
      ],
      "metadata": {
        "id": "anIOSkxxQzwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[7]}\", \"r\") as f:\n",
        "  lines = [line.rstrip('\\n') for line in f]\n",
        "  sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "sentence_list"
      ],
      "metadata": {
        "id": "7jG4M79MLz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_match(sentence_list, keyword):\n",
        "  print(\"#\"*10)\n",
        "  print(f\"Matching for : {keyword}\")\n",
        "  print()\n",
        "  ratios = [fuzz.ratio(keyword, sentence) for sentence in sentence_list]\n",
        "  best_match = sentence_list[ratios.index(max(ratios))]\n",
        "  print(f\"Best match: {fuzz.ratio(keyword, best_match)} | {best_match}\")\n",
        "  print(f\"Before Match: {fuzz.ratio(keyword, sentence_list[sentence_list.index(best_match) - 1])} | {sentence_list[sentence_list.index(best_match) - 1]}\")\n",
        "  print(f\"After Match: {fuzz.ratio(keyword, sentence_list[sentence_list.index(best_match) + 1])} | {sentence_list[sentence_list.index(best_match) + 1]}\")\n",
        "  print()\n",
        "\n",
        "  p_ratios = [fuzz.partial_ratio(keyword, sentence) for sentence in sentence_list]\n",
        "  p_best_match = sentence_list[p_ratios.index(max(p_ratios))]\n",
        "  print(f\"Partial Best match: {fuzz.partial_ratio(keyword, p_best_match)} | {p_best_match}\")\n",
        "  print(f\"Partial Before Match: {fuzz.partial_ratio(keyword, sentence_list[sentence_list.index(p_best_match) - 1])} | {sentence_list[sentence_list.index(p_best_match) - 1]}\")\n",
        "  print(f\"Partial After Match: {fuzz.partial_ratio(keyword, sentence_list[sentence_list.index(p_best_match) + 1])} | {sentence_list[sentence_list.index(p_best_match) + 1]}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "yRK1ILJFSZYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_list = [get_keyword(code) for code in clean_icd10_code]\n",
        "keyword_list"
      ],
      "metadata": {
        "id": "lpyTbAmGEkg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[get_best_match(sentence_list, keyword) for keyword in keyword_list]"
      ],
      "metadata": {
        "id": "zpQ1gCbVXNFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_match(sentence_list, keyword_list):\n",
        "  for keyword in keyword_list:\n",
        "    #for sentence in sentence_list:\n",
        "    print(\"#\"*10)\n",
        "    print(f\"Matching for : {keyword}\")\n",
        "    match_list = process.extract(keyword, sentence_list, scorer = fuzz.ratio, limit = 3)\n",
        "    for match_found in match_list:\n",
        "      print(f\"{match_found[0]} | {match_found[1]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "Tj28h6fOPXSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_match(sentence_list, keyword_list)\n",
        "#process.extract(query, choices, scorer = fuzz.partial_ratio, limit = 2)"
      ],
      "metadata": {
        "id": "Lpb7D5IOOk5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list.index(\"Moderate Obstructive Sleep Apnea .\")"
      ],
      "metadata": {
        "id": "7PF541tZWM00",
        "outputId": "5961f3d1-1f3b-4b1b-e55e-05c4f65d34c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sent in enumerate(sentence_list):\n",
        "  print(f\"{idx}>{sent}\")"
      ],
      "metadata": {
        "id": "_EsIKRI9WXpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##All Together"
      ],
      "metadata": {
        "id": "xnOyuVdwJf7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keyword(p_code):\n",
        "  keyword = \"\"\n",
        "   # reverse code if required\n",
        "  code = reverse_code_pattern(p_code)\n",
        "  # get keyword from dataset\n",
        "  keyword_list = list(code_df.loc[code_df[\"Code\"] == code][\"Keyword\"])\n",
        "  if len(keyword_list) > 0:\n",
        "    keyword = keyword_list[0]\n",
        "  return keyword\n",
        "\n",
        "def get_best_match(code10_dict, txt_list, num_page):\n",
        "  # Step 1: reverse code pattern\n",
        "  clean_icd10_code = [reverse_code_pattern(code) for code in page_code10_dict[num_page]]\n",
        "  # Step 2: fetch keyword based on code \n",
        "  keyword_list = [get_keyword(code) for code in clean_icd10_code]\n",
        "  # Step 3: prepare sentence list \n",
        "  with open(f\"{txt_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "\n",
        "  # Step 4: get best match \n",
        "  for keyword in keyword_list:\n",
        "    #for sentence in sentence_list:\n",
        "    print(\"#\"*10)\n",
        "    print(f\"Matching for : {keyword}\")\n",
        "    match_list = process.extract(keyword, sentence_list, scorer = fuzz.ratio, limit = 3)\n",
        "    print(match_list[0][1])\n",
        "    for idx, match_found in enumerate(match_list):\n",
        "      if match_found[1] > 40:\n",
        "        print(f\"{idx}> {match_found[0]} | {match_found[1]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "DmuQsrthJh24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_match(p_code, num_page):\n",
        "    # Step 1: reverse code pattern\n",
        "    reversed_icd_code = reverse_code_pattern(p_code)\n",
        "    # Step 2: fetch keyword based on code \n",
        "    keyword = get_keyword(reversed_icd_code)\n",
        "    # Step 3: prepare sentence list \n",
        "    with open(f\"{txt_list[num_page]}\", \"r\") as f:\n",
        "      lines = [line.rstrip('\\n') for line in f]\n",
        "      sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "    # Step 4: get best 3 match ratio \n",
        "    match_list = process.extract(keyword, sentence_list, scorer = fuzz.ratio, limit = 3)\n",
        "    return match_list, sentence_list"
      ],
      "metadata": {
        "id": "enKktNs2TkPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_icd10_code = [reverse_code_pattern(code) for code in page_code10_dict[7]]\n",
        "clean_icd10_code"
      ],
      "metadata": {
        "id": "XK9QcFYaUJvi",
        "outputId": "9717c3de-5613-444e-d3fd-20f54d05eac9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['G47.10', 'G47.31', 'R06.83', 'G47.39', 'G47.33', 'G47.8', 'G47.34', 'R06.3']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_list, sentence_list = get_best_match(\"G47.10\", 7)\n",
        "match_list"
      ],
      "metadata": {
        "id": "OKm64hdlLVow",
        "outputId": "b92d2816-c743-401c-8d58-cffa55eafa01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('(central sleep apnea (G47.31) CoHypersomnia, unspecified (G47.10)', 55),\n",
              " ('Diplomate in ABPN - Sleep Medicine', 45),\n",
              " ('Hypoxemia', 42)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding for `Hypersomnia, unspecified`:\n",
        "44 > Hypoxemia\n",
        "65 > (central sleep apnea (G47.31) CoHypersomnia, unspecified (G47.10)"
      ],
      "metadata": {
        "id": "n_z8v-H0ra7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[21]}\", \"r\") as f:\n",
        "  lines = [line.rstrip('\\n') for line in f]\n",
        "  sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks"
      ],
      "metadata": {
        "id": "6OgZL7IBOPbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_tuple(tup):\n",
        "  return(sorted(tup, key = lambda x: x[1], reverse=True)) \n",
        "\n",
        "def get_best_token_match(p_code, num_page):\n",
        "  # Step 1: reverse code pattern\n",
        "  reversed_icd_code = reverse_code_pattern(p_code)\n",
        "  # Step 2: fetch keyword based on code \n",
        "  keyword = get_keyword(reversed_icd_code)\n",
        "  # Step 3: prepare sentence list \n",
        "  with open(f\"{txt_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "  # Step 4: get best token match ratio \n",
        "  #match_list = [fuzz.token_set_ratio(keyword, sentence) for sentence in sentence_list]\n",
        "  print(f\"Finding for `{keyword}`:\")\n",
        "  match_list = []\n",
        "  for sentence in sentence_list:\n",
        "    token_ratio = fuzz.token_set_ratio(keyword, sentence)\n",
        "    if token_ratio >= 45:\n",
        "      print(f\"{p_code}: {token_ratio} > {sentence}\")\n",
        "      match_list.extend((sentence, token_ratio))\n",
        "  print()\n",
        "  #return match_list"
      ],
      "metadata": {
        "id": "LZA1Oh-DVsvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[code for code in page_code10_dict[21]]"
      ],
      "metadata": {
        "id": "ptMIwrFBdfyV",
        "outputId": "33d6cc10-5fa8-41ea-ec6c-4b39e2c628c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Z78.9',\n",
              " '268.25',\n",
              " 'Z00.00',\n",
              " 'S93.411A',\n",
              " 'R50.9',\n",
              " '287.5',\n",
              " '278.9',\n",
              " 'R03',\n",
              " 'R10.32',\n",
              " 'K46.9',\n",
              " 'D69.6',\n",
              " 'Z68.25',\n",
              " 'R05',\n",
              " 'J01.00',\n",
              " 'R53.83',\n",
              " 'L73.9',\n",
              " 'E78.3',\n",
              " '212.5',\n",
              " 'M54.5']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(code, get_keyword(code)) for code in page_code10_dict[21]]"
      ],
      "metadata": {
        "id": "Jl8ONBJOjpqI",
        "outputId": "1479f35e-17ee-402c-d53b-eba7fbb13b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('S93.411A', 'Sprain of calcaneofibular ligament of right ankle, init'),\n",
              " ('J01.00', 'Acute maxillary sinusitis, unspecified'),\n",
              " ('Z00.00', 'Encntr for general adult medical exam w/o abnormal findings'),\n",
              " ('287.5', 'Personal history of comp of preg, chldbrth and the puerp'),\n",
              " ('E78.3', 'Hyperchylomicronemia'),\n",
              " ('R10.32', 'Left lower quadrant pain'),\n",
              " ('M54.5', 'Low back pain'),\n",
              " ('212.5', 'Encounter for screening for malignant neoplasm of prostate'),\n",
              " ('R03', 'Abnormal blood-pressure reading, without diagnosis'),\n",
              " ('Z68.25', 'Body mass index [BMI] 25.0-25.9, adult'),\n",
              " ('R50.9', 'Fever, unspecified'),\n",
              " ('R53.83', 'Other fatigue'),\n",
              " ('Z78.9', 'Other specified health status'),\n",
              " ('K46.9', 'Unspecified abdominal hernia without obstruction or gangrene'),\n",
              " ('D69.6', 'Thrombocytopenia, unspecified'),\n",
              " ('L73.9', 'Follicular disorder, unspecified'),\n",
              " ('278.9', 'Other specified health status'),\n",
              " ('R05', 'Cough'),\n",
              " ('268.25', 'Body mass index [BMI] 25.0-25.9, adult')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[get_best_token_match(code, 21) for code in page_code10_dict[21]]"
      ],
      "metadata": {
        "id": "GlI7J8Ym313a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_token_match(p_code, num_page):\n",
        "  # Step 1: reverse code pattern\n",
        "  reversed_icd_code = reverse_code_pattern(p_code)\n",
        "  # Step 2: fetch keyword based on code \n",
        "  keyword = get_keyword(reversed_icd_code)\n",
        "  # Step 3: prepare sentence list \n",
        "  with open(f\"{txt_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "  # Step 4: get best token match ratio \n",
        "  match_list = [(sentence, fuzz.WRatio(keyword, sentence)) for sentence in sentence_list if fuzz.token_set_ratio(keyword, sentence) > 40]\n",
        "  return sort_tuple(match_list)"
      ],
      "metadata": {
        "id": "jCgz8N-1ySsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_list = [get_best_token_match(code, 21) for code in page_code10_dict[21]]"
      ],
      "metadata": {
        "id": "a8n55LWtWSFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_list"
      ],
      "metadata": {
        "id": "e3eWcMCedToP",
        "outputId": "b63970b3-3b1a-48c0-c4a0-173f810e282a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Diagnosis Encntr for general adult medical exam w/o abnormal findings (Z00.00), Screening for prostate cancer (212.5)',\n",
              "   90),\n",
              "  ('Diagnosis Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic (E78.3)',\n",
              "   86)],\n",
              " [('Diagnosis Contact with and (suspected) exposureto other viral communicable diseases, Cough (R05)',\n",
              "   86),\n",
              "  ('Diagnosis Contact with/suspected exposure to COVID-19, Cough (R05), Fatigue (R53.83), Overweight (BMI 25.0 - 29.9), Body mass index (BMI)',\n",
              "   57),\n",
              "  ('Encounter 7 Date 12/12/2019', 56)],\n",
              " [('Diagnosis Contact with and (suspected) exposureto COVID-19, Body mass index (BMI) of 25.0-25.9 in adult (Z68.25), Non-smoker (278.9)',\n",
              "   86),\n",
              "  ('Diagnosis Contact with/suspected exposure to COVID-19, Cough (R05), Fatigue (R53.83), Overweight (BMI 25.0 - 29.9), Body mass index (BMI)',\n",
              "   86),\n",
              "  ('Diagnosis Folliculitis (L73.9), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of 26.0-25.9 in adult (Z68.25), Dietary',\n",
              "   86),\n",
              "  ('Diagnosis Sinusitis, acute, maxillary, Thrombocytopenia (287.5) (D69.6), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index',\n",
              "   86),\n",
              "  ('(BMI) of 25.0-25.9 in adult (268.25), Dietary counseling and surveillance',\n",
              "   86),\n",
              "  ('Diagnosis Hypertrig ceridemia, sporadic (E78.3), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of 25.0-25.9 in adult (268.25), Dietary',\n",
              "   86),\n",
              "  ('Diagnosis Acute maxillary sinusitis (J01.00), Body mass index (BMI) of 25.0-25.9 in adult (268.25)',\n",
              "   86),\n",
              "  ('Diagnosis Left lower quadrant pain (R10.32), Non-smoker (Z78.9), Hernia (K46.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   86),\n",
              "  ('25.0-25.9 in adult (Z68.25), Dietary counseling and surveillance', 86),\n",
              "  ('Diagnosis Chronic midline low back pain without sciatica (M54.5), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   86),\n",
              "  ('25.0-25.9 in adult (Z68.25), Dietary counseling and surveillance', 86),\n",
              "  ('of 25.0-25.9 in adult (268.25), Non-smoker (Z78.9)', 52)],\n",
              " [('Diagnosis Left lower quadrant pain (R10.32), Non-smoker (Z78.9), Hernia (K46.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   90)],\n",
              " [('ROO) Sinusitis, acute, frontal, Hypertriglyceridemia, sporadic (E78.3), Elevated blood pressure reading without diagnosis of hypertension',\n",
              "   86),\n",
              "  ('Diagnosis Acute non-recurrent maxillary sinusitis (J01.00), Hypertriglyceridemia, sporadic (E78.3)',\n",
              "   86),\n",
              "  ('Diagnosis Sinusitis, acute, maxillary, Thrombocytopenia (287.5) (D69.6), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index',\n",
              "   86),\n",
              "  ('Diagnosis Acute maxillary sinusitis (J01.00), Body mass index (BMI) of 25.0-25.9 in adult (268.25)',\n",
              "   86),\n",
              "  ('Diagnosis Acute non-recurrent maxillary sinusitis (J01.00), Non-smoker (Z78.9)',\n",
              "   86),\n",
              "  ('Diagnosis Fever (R50.9), Sinusitis, acute, maxillary', 77)],\n",
              " [],\n",
              " [],\n",
              " [('Diagnosis Cough (R05)', 90),\n",
              "  ('Diagnosis Contact with and (suspected) exposureto other viral communicable diseases, Cough (R05)',\n",
              "   60),\n",
              "  ('Diagnosis Contact with/suspected exposure to COVID-19, Cough (R05), Fatigue (R53.83), Overweight (BMI 25.0 - 29.9), Body mass index (BMI)',\n",
              "   60)],\n",
              " [('ROO) Sinusitis, acute, frontal, Hypertriglyceridemia, sporadic (E78.3), Elevated blood pressure reading without diagnosis of hypertension',\n",
              "   86),\n",
              "  ('Diagnosis Contact with and (suspected) exposureto other viral communicable diseases, Cough (R05)',\n",
              "   86),\n",
              "  ('Diagnosis Cough (R05)', 86),\n",
              "  ('Diagnosis Fever (R50.9)', 86),\n",
              "  ('Diagnosis Encntr for general adult medical exam w/o abnormal findings (Z00.00), Screening for prostate cancer (212.5)',\n",
              "   86),\n",
              "  ('Diagnosis Chronic midline low back pain without sciatica (M54.5), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   86),\n",
              "  ('Diagnosis Contact with and (suspected) exposure to COVID-19', 55),\n",
              "  ('Diagnosis Fever (R50.9), Sinusitis, acute, maxillary', 46),\n",
              "  ('Diagnosis Influenza vaccine needed', 40)],\n",
              " [('Diagnosis Fever (R50.9), Sinusitis, acute, maxillary', 86),\n",
              "  ('Diagnosis Fever (R50.9)', 45)],\n",
              " [],\n",
              " [('Diagnosis Contact with and (suspected) exposureto COVID-19, Body mass index (BMI) of 25.0-25.9 in adult (Z68.25), Non-smoker (278.9)',\n",
              "   86),\n",
              "  ('Diagnosis Contact with/suspected exposure to COVID-19, Cough (R05), Fatigue (R53.83), Overweight (BMI 25.0 - 29.9), Body mass index (BMI)',\n",
              "   86),\n",
              "  ('Diagnosis Folliculitis (L73.9), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of 26.0-25.9 in adult (Z68.25), Dietary',\n",
              "   86),\n",
              "  ('Diagnosis Sinusitis, acute, maxillary, Thrombocytopenia (287.5) (D69.6), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index',\n",
              "   86),\n",
              "  ('(BMI) of 25.0-25.9 in adult (268.25), Dietary counseling and surveillance',\n",
              "   86),\n",
              "  ('Diagnosis Hypertrig ceridemia, sporadic (E78.3), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of 25.0-25.9 in adult (268.25), Dietary',\n",
              "   86),\n",
              "  ('Diagnosis Acute maxillary sinusitis (J01.00), Body mass index (BMI) of 25.0-25.9 in adult (268.25)',\n",
              "   86),\n",
              "  ('Diagnosis Left lower quadrant pain (R10.32), Non-smoker (Z78.9), Hernia (K46.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   86),\n",
              "  ('25.0-25.9 in adult (Z68.25), Dietary counseling and surveillance', 86),\n",
              "  ('Diagnosis Chronic midline low back pain without sciatica (M54.5), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   86),\n",
              "  ('25.0-25.9 in adult (Z68.25), Dietary counseling and surveillance', 86),\n",
              "  ('of 25.0-25.9 in adult (268.25), Non-smoker (Z78.9)', 52)],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [('Diagnosis Sinusitis, acute, maxillary, Thrombocytopenia (287.5) (D69.6), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index',\n",
              "   86)],\n",
              " [(\"Encounter 21 Date 12/28/202'\", 86),\n",
              "  ('Encounter 20 Date 12/27/2021', 86),\n",
              "  ('Encounter 19 Date 12/09/2021', 86),\n",
              "  ('Encounter 18 Date 03/25/2021', 86),\n",
              "  ('Encounter 17 Date 03/25/2021', 86),\n",
              "  ('Encounter 16 Date 01/25/2021', 86),\n",
              "  ('Encounter 15 Date 12/23/2020', 86),\n",
              "  ('Encounter 14 Date 12/23/2020', 86),\n",
              "  ('Encounter 13 Date 12/16/2020', 86),\n",
              "  ('Encounter 12 Date 05/08/2020', 86),\n",
              "  ('Encounter 11 Date 04/02/2020', 86),\n",
              "  ('Encounter 10 Date 03/30/2020', 86),\n",
              "  ('Encounter 9 Date 02/05/2020', 86),\n",
              "  ('Encounter 8 Date 12/18/2019', 86),\n",
              "  ('Diagnosis Encntr for general adult medical exam w/o abnormal findings (Z00.00), Screening for prostate cancer (212.5)',\n",
              "   86),\n",
              "  ('Encounter 7 Date 12/12/2019', 86),\n",
              "  ('Encounter 6 Date 11/25/2019', 86),\n",
              "  ('Encounter 5 Date 02/22/2019', 86),\n",
              "  ('Encounter 4 Date 10/31/2018', 86),\n",
              "  ('Encounter 3 Date 09/14/2018', 86),\n",
              "  ('Encounter 2 Date 05/10/2018', 86),\n",
              "  ('Diagnosis Sprain of calcaneofibular ligament of right ankle, initial encounter (S93.411A)',\n",
              "   86),\n",
              "  ('Encounter 1 Date 01/17/2018', 86)],\n",
              " [('Diagnosis Chronic midline low back pain without sciatica (M54.5), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   60),\n",
              "  ('Diagnosis Left lower quadrant pain (R10.32), Non-smoker (Z78.9), Hernia (K46.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of',\n",
              "   57)],\n",
              " [('Diagnosis Sprain of calcaneofibular ligament of right ankle, initial encounter (S93.411A)',\n",
              "   90)]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_list = get_best_token_match(\"R50.9\", 21)\n",
        "match_list"
      ],
      "metadata": {
        "id": "mVVptrS379Pw",
        "outputId": "6425df70-839c-452c-f29f-5b9ad62e35ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Diagnosis Fever (R50.9)', 47),\n",
              " ('Diagnosis Fever (R50.9), Sinusitis, acute, maxillary', 45)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.token_set_ratio(get_keyword(\"E78.3\"), \"Diagnosis Hypertriglyceridemia, sporadic (E78.3)\")"
      ],
      "metadata": {
        "id": "WzPXfOvFW9ym",
        "outputId": "e17b29b9-0a70-4950-c50e-f34ae62e0eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.token_set_ratio(get_keyword(\"R50.9\"), \"Diagnosis Fever (R50.9), Sinusitis, acute, maxillary\")"
      ],
      "metadata": {
        "id": "hsrQ6WMfXPBN",
        "outputId": "8319eb98-8512-4cea-df3a-85f059e4c3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.token_set_ratio(\"Fever, unspecified\", \"Diagnosis Fever (R50.9), Sinusitis, acute, maxillary\")"
      ],
      "metadata": {
        "id": "LZqInagFj_NX",
        "outputId": "eb7f6d8a-bbd3-4854-bdca-6ba9b54767d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.token_set_ratio(get_keyword(\"R50.9\"), \"Diagnosis Fever (R50.9)\")"
      ],
      "metadata": {
        "id": "MYDpgQjEXkiO",
        "outputId": "fd3bd2d9-2119-451a-83d1-46b489c3eb3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.WRatio(get_keyword(\"E78.3\"), \"Diagnosis Hypertriglyceridemia, sporadic (E78.3)\")"
      ],
      "metadata": {
        "id": "qhwxfW86vNQi",
        "outputId": "634ea3e4-f7c4-458b-9375-63f1215a07af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_words(sent1, sent2):\n",
        "  sent1 = set(sent1.replace(\",\", \"\").lower().split())\n",
        "  sent2 = set(sent2.replace(\",\", \"\").lower().split())\n",
        "\n",
        "  return list(sent1 & sent2)"
      ],
      "metadata": {
        "id": "m2rTAnaEFHit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_common_words(\n",
        "  \"Abnormal blood-pressure reading, without diagnosis\",\n",
        "  \"Diagnosis Chronic midline low back pain without sciatica (M54.5), Non-smoker (Z78.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of\"\n",
        ")"
      ],
      "metadata": {
        "id": "wdEqtIMDCifG",
        "outputId": "e7cebf35-027a-4855-9016-c8caf10bde84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['without', 'diagnosis']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest(array, value):\n",
        "  array = np.asarray(array)\n",
        "  idx = (np.abs(array - value)).argmin()\n",
        "  return array[idx]"
      ],
      "metadata": {
        "id": "1J1L0ncbDYWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.random.random(10)\n",
        "print(array)"
      ],
      "metadata": {
        "id": "coA4aXDBX8qA",
        "outputId": "c63f3377-0d7a-4eac-cf55-78c7a5f896f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.93361323 0.10674056 0.81360362 0.26873547 0.7892294  0.36625687\n",
            " 0.48473053 0.43495106 0.68754387 0.28034082]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(find_nearest(array, value=0.35))"
      ],
      "metadata": {
        "id": "cL-TT9m-YBJB",
        "outputId": "df4917ab-8aba-4b18-d5aa-917e69a62918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3662568679192558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fitz"
      ],
      "metadata": {
        "id": "lUbkfe9gA8uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest(array, value):\n",
        "  array = np.asarray(array)\n",
        "  idx = (np.abs(array - value)).argmin()\n",
        "  return array[idx]"
      ],
      "metadata": {
        "id": "rcCQw9qgYXZa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"page-11.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  #content_of_page = pdf_file.get_page_text(page) #Get page content\n",
        "  match_word = \"Z00.00\" \n",
        "  content_of_page = page_obj.get_text(\"words\", sort=False)  #get rect for all words\n",
        "\n",
        "  coords_array = []\n",
        "  y_coords_array = []\n",
        "  for content in content_of_page:\n",
        "    # print(word)\n",
        "    if content[4].replace(\"(\", \"\").replace(\")\", \"\") == match_word:\n",
        "      rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "      print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")\n",
        "      coords_array.append(rect_comp)\n",
        "      y_coords_array.append(content[1])\n",
        "      highlight = page_obj.add_highlight_annot(rect_comp)\n",
        "      highlight.set_colors(stroke=[0.2, 1, 0.8])\n",
        "      highlight.update()\n",
        "\n",
        "  # find closet y coordinate value\n",
        "  closet_y_coords = find_nearest(y_coords_array, value=74.320068359375)\n",
        "  match_word = \"Comprehensive\" \n",
        "  for content in content_of_page:\n",
        "    # print(word)\n",
        "    if content[4].replace(\"(\", \"\").replace(\")\", \"\") == match_word and (closet_y_coords-20) <= content[1] <= (closet_y_coords + 20):\n",
        "      rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "      print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")\n",
        "      highlight = page_obj.add_highlight_annot(rect_comp)\n",
        "      highlight.set_colors(stroke=[1, 1, 0])\n",
        "      highlight.update()\n",
        "\n",
        "pdf_output_file_name = f\"page_11_output.pdf\"\n",
        "pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)"
      ],
      "metadata": {
        "id": "uK6DLGv7bSar",
        "outputId": "7143eb96-b083-4b2a-af05-8a209705418c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line #3-(Z00.00) > Rect(341.4872131347656, 74.320068359375, 369.0046081542969, 82.323974609375)\n",
            "Line #5-(Z00.00) > Rect(341.4871826171875, 237.0400390625, 369.00457763671875, 245.0439453125)\n",
            "Line #5-(Z00.00) > Rect(340.287353515625, 409.8399658203125, 368.87152099609375, 417.8438720703125)\n",
            "Line #3-(Z00.00) > Rect(340.28729248046875, 572.5599975585938, 368.8714599609375, 580.5639038085938)\n",
            "Line #2-Comprehensive > Rect(181.42257690429688, 65.00006103515625, 235.34848022460938, 72.00347900390625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [74.320068359375, 237.0400390625, 409.8399658203125, 572.5599975585938]\n",
        "curr_value = 74.320068359375 + 20\n",
        "find_nearest(list1, value=curr_value)"
      ],
      "metadata": {
        "id": "XT0I4MwTe6AR",
        "outputId": "499fecb6-9b44-4c56-96ac-7f4ad63f7d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.320068359375"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_value = 74.320068359375 - 20\n",
        "find_nearest(list1, value=curr_value)"
      ],
      "metadata": {
        "id": "BQ1lu6yjsj_z",
        "outputId": "826e7082-f6d2-4f6e-c852-0c514d02a1b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.320068359375"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_coordinate(page_obj, common_words):\n",
        "  word_coords = {}\n",
        "  content_of_page = page_obj.get_text(\"words\", sort=False)  #get rect for all words\n",
        "  for content in content_of_page:\n",
        "    # print(word)\n",
        "    for idx, common_word in enumerate(common_words):\n",
        "      word_coord = {}\n",
        "      curr_word = content[4].replace(\"(\", \"\").replace(\")\", \"\")\n",
        "      if curr_word == match_word:\n",
        "        rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "        word_coord[common_word] = rect_comp\n",
        "        word_coord[\"Line#\"] = content[6]\n",
        "        word_coords[idx] = word_coord\n",
        "  return word_coords"
      ],
      "metadata": {
        "id": "kS5_-wkwkvZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"pdf-files/page-11.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  print(get_word_coordinate(page_obj, [\"general\", \"adult\", \"medical\", \"exam\"]))"
      ],
      "metadata": {
        "id": "2qs3rb4umbmS",
        "outputId": "b42ff6a5-0721-4c17-d1da-c1a22151bcbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: {'general': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}, 1: {'adult': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}, 2: {'medical': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}, 3: {'exam': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def highlight_common_words(page_obj, y_coords_array, curr_y_coord, common_word_list):\n",
        "  content_of_page = page_obj.get_text(\"words\", sort=False)  #get rect for all words\n",
        "\n",
        "  # find closet y coordinate value\n",
        "  closet_y_coords = find_nearest(y_coords_array, value=curr_y_coord)\n",
        "  match_word = \"Comprehensive\" \n",
        "  for content in content_of_page:\n",
        "    for common_word in common_word_list:\n",
        "      if content[4].replace(\"(\", \"\").replace(\")\", \"\") == common_word and (closet_y_coords-20) <= content[1] <= (closet_y_coords + 20):\n",
        "        rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "        print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")\n",
        "        highlight = page_obj.add_highlight_annot(rect_comp)\n",
        "        highlight.set_colors(stroke=[1, 1, 0])\n",
        "        highlight.update()"
      ],
      "metadata": {
        "id": "7rvJixWFeJlA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}