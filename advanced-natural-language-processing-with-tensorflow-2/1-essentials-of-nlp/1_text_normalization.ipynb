{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1-text-normalization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RS6j_Uu1aKr7",
        "Q5NI7lL_aPrR",
        "50W5rWfeOoR3"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-natural-language-processing-with-tensorflow-2/blob/main/1-essentials-of-nlp/1_text_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdA7sBdGl2S2"
      },
      "source": [
        "## Text Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xk0ZWFhsJg7"
      },
      "source": [
        "To understand how to process text, it is important to understand the general\n",
        "workflow for NLP.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/advanced-nlp-with-tensorflow-2/text-processing-workflow.png?raw=1' width='800'/>\n",
        "\n",
        "The first two steps of the process in the preceding diagram involve collecting labeled data. A supervised model or even a semi-supervised model needs data to operate.\n",
        "\n",
        "The next step is usually normalizing and featurizing the data. Models have a hard time processing text data as is. There is a lot of hidden structure in a given text that needs to be processed and exposed. These two steps focus on that. \n",
        "\n",
        "The last step is building a model with the processed inputs. While NLP has some unique models, this chapter will use only a simple deep neural network and focus more on the normalization and vectorization/featurization. Often, the last three stages operate in a cycle, even though the diagram may give the impression of linearity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZPInUZktiyI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9xCqLf9f0hM"
      },
      "source": [
        "%%shell\n",
        "\n",
        "pip install stopwordsiso\n",
        "# pip install stanfordnlp\n",
        "pip install stanza  # StanfordNLP has become https://github.com/stanfordnlp/stanza/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy9eSdb1cn4Z"
      },
      "source": [
        "%tensorflow_version 2.x     # magic command instructing to use TensorFlow version 2+\n",
        "import tensorflow as tf\n",
        "#from tf.keras.models import Sequential\n",
        "#from tf.keras.layers import Dense\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "\n",
        "import pandas as pd \n",
        "import stopwordsiso as stopwords\n",
        "import stanza\n",
        "import stanfordnlp as snlp\n",
        "# en = snlp.download('en')\n",
        "en = stanza.download('en')\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ3vRSqLvTu6"
      },
      "source": [
        "# Data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr1vzM27oyLD"
      },
      "source": [
        "**The first step of any Machine Learning (ML) project is to obtain a dataset.**\n",
        "\n",
        "We will be using the SMS Spam Collection dataset made available by University of California, Irvine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JSjikP_c0Ba"
      },
      "source": [
        "# Download the zip file\n",
        "path_to_zip = tf.keras.utils.get_file(\"smsspamcollection.zip\",\n",
        "                  origin=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\",\n",
        "                  extract=True)\n",
        "\n",
        "# Unzip the file into a folder\n",
        "!unzip $path_to_zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytFnxCGFaJ20"
      },
      "source": [
        "# optional step - helps if colab gets disconnected\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbXeir-dm0nr"
      },
      "source": [
        "Reading the data file is trivial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Kb8AF3wHaKE3",
        "outputId": "9f4ebd29-62b9-48d3-8560-f26b75062023"
      },
      "source": [
        "# Let's see if we read the data correctly\n",
        "# lines = io.open('/content/drive/My Drive/colab-data/SMSSpamCollection').read().strip().split('\\n')\n",
        "lines = io.open('/content/data/SMSSpamCollection').read().strip().split('\\n')\n",
        "lines[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dYG5LFyDm-C-",
        "outputId": "cd454294-464e-4bd4-a53d-8a381ad01e8d"
      },
      "source": [
        "lines[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCFBMGdWvnNn"
      },
      "source": [
        "## Pre-process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zle10-0pnUjv"
      },
      "source": [
        "The next step is to split each line into two columns â€“ one with the text of the message and the other as the label. While we are separating these labels, we will also convert the labels to numeric values. Since we are interested in predicting spam messages, we can assign a value of 1 to the spam\n",
        "messages. A value of 0 will be assigned to legitimate messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhpfi9lWC5We",
        "outputId": "585ab839-1353-4822-d447-5bec6edfd34b"
      },
      "source": [
        "spam_dataset = []\n",
        "spam_count = 0\n",
        "ham_count = 0\n",
        "for line in lines:\n",
        "  label, text = line.split('\\t')\n",
        "  if label.lower().strip() == 'spam':\n",
        "    spam_dataset.append((1, text.strip()))\n",
        "    spam_count += 1\n",
        "  else:\n",
        "    spam_dataset.append(((0, text.strip())))\n",
        "    ham_count += 1\n",
        "\n",
        "spam_dataset[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'),\n",
              " (0, 'Ok lar... Joking wif u oni...'),\n",
              " (1,\n",
              "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"),\n",
              " (0, 'U dun say so early hor... U c already then say...'),\n",
              " (0, \"Nah I don't think he goes to usf, he lives around here though\")]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV1uWIEUoLWQ",
        "outputId": "a525bbd4-7960-4db1-e251-8baa523cdcbd"
      },
      "source": [
        "print(\"Spam: \", spam_count, \", Ham: \", ham_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam:  747 , Ham:  4827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JReDkDrhoSWG"
      },
      "source": [
        "Now the dataset is ready for further processing in the pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SkoqwjizbBS"
      },
      "source": [
        "# Data Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hfv0a0JegCr"
      },
      "source": [
        "Text normalization is a pre-processing step aimed at improving the quality\n",
        "of the text and making it suitable for machines to process. \n",
        "\n",
        "Four main steps in text normalization are:\n",
        "\n",
        "- case normalization, \n",
        "- tokenization and stop word removal,\n",
        "- Parts-of-Speech (POS) tagging, \n",
        "- and stemming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuqsxAIAmT4l"
      },
      "source": [
        "## Case normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkX0qQ_Xmrx_"
      },
      "source": [
        "**Case normalization applies to languages that use uppercase and lowercase letters.**\n",
        "\n",
        "All languages based on the Latin alphabet or the Cyrillic alphabet (Russian,\n",
        "Mongolian, and so on) use upper- and lowercase letters. Other languages\n",
        "that sometimes use this are Greek, Armenian, Cherokee, and Coptic. \n",
        "\n",
        "In case normalization, all letters are converted to the same case. It is quite helpful in semantic use cases. However, in other cases, this may hinder performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js-XjZJmltdp"
      },
      "source": [
        "### Preprocessing case normalized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i3JudyHl0bs"
      },
      "source": [
        "Let's build a baseline model with three simple features:\n",
        "\n",
        "- Number of characters in the message\n",
        "- Number of capital letters in the message\n",
        "- Number of punctuation symbols in the message"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFCghF5YLcmb"
      },
      "source": [
        "# To do so, first, we will convert the data into a pandas DataFrame\n",
        "df = pd.DataFrame(spam_dataset, columns=['Spam', 'Message'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "DT0spdItiWIo",
        "outputId": "634d274c-de24-4254-f601-2e93c6144b83"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Spam                                            Message\n",
              "0     0  Go until jurong point, crazy.. Available only ...\n",
              "1     0                      Ok lar... Joking wif u oni...\n",
              "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3     0  U dun say so early hor... U c already then say...\n",
              "4     0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O615kHKggOz"
      },
      "source": [
        "Next, let's build some simple functions that can count the length of the message, and the numbers of capital letters and punctuation symbols. Python's regular expression package, re, will be used to implement these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRQZpvvHhI9K"
      },
      "source": [
        "# Normalization functions\n",
        "\n",
        "def message_length(x):\n",
        "  # returns total number of characters\n",
        "  return len(x)\n",
        "\n",
        "def num_capitals(x):\n",
        "  # get count of capital letters\n",
        "  _, count = re.subn(r'[A-Z]', '', x) # only works in english\n",
        "  return count\n",
        "\n",
        "def num_punctuation(x):\n",
        "  # get count the number of punctuation symbols\n",
        "  _, count = re.subn(r'\\W', '', x)\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "innAg2YOhKmk"
      },
      "source": [
        "Additional feature columns will be added to the DataFrame, and then the set will\n",
        "be split into test and train sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaPsdhs6mkd_"
      },
      "source": [
        "df['Capitals'] = df['Message'].apply(num_capitals)\n",
        "df['Punctuation'] = df['Message'].apply(num_punctuation)\n",
        "df['Length'] = df['Message'].apply(message_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "8fwkbELUilzd",
        "outputId": "34bf6d75-aa30-4bb3-a4e9-391179de592c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Message</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Spam                                            Message  ...  Punctuation  Length\n",
              "0     0  Go until jurong point, crazy.. Available only ...  ...           28     111\n",
              "1     0                      Ok lar... Joking wif u oni...  ...           11      29\n",
              "2     1  Free entry in 2 a wkly comp to win FA Cup fina...  ...           33     155\n",
              "3     0  U dun say so early hor... U c already then say...  ...           16      49\n",
              "4     0  Nah I don't think he goes to usf, he lives aro...  ...           14      61\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "7Oy5mN8nnrde",
        "outputId": "9703e399-3506-462b-fa9e-d08756c7a0d1"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5574.000000</td>\n",
              "      <td>5574.000000</td>\n",
              "      <td>5574.000000</td>\n",
              "      <td>5574.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.134015</td>\n",
              "      <td>5.621636</td>\n",
              "      <td>18.942591</td>\n",
              "      <td>80.443488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.340699</td>\n",
              "      <td>11.683233</td>\n",
              "      <td>14.825994</td>\n",
              "      <td>59.841746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>61.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>122.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>910.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Spam     Capitals  Punctuation       Length\n",
              "count  5574.000000  5574.000000  5574.000000  5574.000000\n",
              "mean      0.134015     5.621636    18.942591    80.443488\n",
              "std       0.340699    11.683233    14.825994    59.841746\n",
              "min       0.000000     0.000000     0.000000     2.000000\n",
              "25%       0.000000     1.000000     8.000000    36.000000\n",
              "50%       0.000000     2.000000    15.000000    61.000000\n",
              "75%       0.000000     4.000000    27.000000   122.000000\n",
              "max       1.000000   129.000000   253.000000   910.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGHh7BGZhiu_"
      },
      "source": [
        "Now let's split the dataset into training and test sets, with\n",
        "80% of the records in the training set and the rest in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX7Ne4NLoPIE"
      },
      "source": [
        "train=df.sample(frac=0.8,random_state=42) #random state is a seed value\n",
        "test=df.drop(train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "FemsnVTto-c6",
        "outputId": "2bb6499d-0bc4-4461-9705-6e7cd4a25e6b"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.132765</td>\n",
              "      <td>5.519399</td>\n",
              "      <td>18.886522</td>\n",
              "      <td>80.316439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.339359</td>\n",
              "      <td>11.405424</td>\n",
              "      <td>14.602023</td>\n",
              "      <td>59.346407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>61.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>122.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>910.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Spam     Capitals  Punctuation       Length\n",
              "count  4459.000000  4459.000000  4459.000000  4459.000000\n",
              "mean      0.132765     5.519399    18.886522    80.316439\n",
              "std       0.339359    11.405424    14.602023    59.346407\n",
              "min       0.000000     0.000000     0.000000     2.000000\n",
              "25%       0.000000     1.000000     8.000000    35.000000\n",
              "50%       0.000000     2.000000    15.000000    61.000000\n",
              "75%       0.000000     4.000000    27.000000   122.000000\n",
              "max       1.000000   129.000000   253.000000   910.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "CEe1TMcApCYS",
        "outputId": "980b82b1-e95a-4b9c-f022-fb630d3da82a"
      },
      "source": [
        "test.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.139013</td>\n",
              "      <td>6.030493</td>\n",
              "      <td>19.166816</td>\n",
              "      <td>80.951570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.346116</td>\n",
              "      <td>12.731059</td>\n",
              "      <td>15.694599</td>\n",
              "      <td>61.807655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>61.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>123.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>790.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Spam     Capitals  Punctuation       Length\n",
              "count  1115.000000  1115.000000  1115.000000  1115.000000\n",
              "mean      0.139013     6.030493    19.166816    80.951570\n",
              "std       0.346116    12.731059    15.694599    61.807655\n",
              "min       0.000000     0.000000     0.000000     2.000000\n",
              "25%       0.000000     1.000000     8.000000    36.000000\n",
              "50%       0.000000     2.000000    15.000000    61.000000\n",
              "75%       0.000000     4.000000    28.000000   123.000000\n",
              "max       1.000000   127.000000   195.000000   790.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EZeaklCiAEn"
      },
      "source": [
        "Further more, labels will be removed from both the training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnXJl3AgiBDu"
      },
      "source": [
        "x_train = train[['Length', 'Punctuation', 'Capitals']]\n",
        "y_train = train[['Spam']]\n",
        "\n",
        "x_test = test[['Length', 'Punctuation', 'Capitals']]\n",
        "y_test = test[['Spam']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB64N3y9iMSs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "2209f07b-b3eb-4889-d360-818d8715d955"
      },
      "source": [
        "x_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Capitals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>80.316439</td>\n",
              "      <td>18.886522</td>\n",
              "      <td>5.519399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>59.346407</td>\n",
              "      <td>14.602023</td>\n",
              "      <td>11.405424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>122.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>910.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>129.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Length  Punctuation     Capitals\n",
              "count  4459.000000  4459.000000  4459.000000\n",
              "mean     80.316439    18.886522     5.519399\n",
              "std      59.346407    14.602023    11.405424\n",
              "min       2.000000     0.000000     0.000000\n",
              "25%      35.000000     8.000000     1.000000\n",
              "50%      61.000000    15.000000     2.000000\n",
              "75%     122.000000    27.000000     4.000000\n",
              "max     910.000000   253.000000   129.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7AdstxMiS2l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "78ce27cd-b9ff-4837-e251-62ea6485dc69"
      },
      "source": [
        "x_test.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Capitals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>80.951570</td>\n",
              "      <td>19.166816</td>\n",
              "      <td>6.030493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>61.807655</td>\n",
              "      <td>15.694599</td>\n",
              "      <td>12.731059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>123.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>790.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>127.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Length  Punctuation     Capitals\n",
              "count  1115.000000  1115.000000  1115.000000\n",
              "mean     80.951570    19.166816     6.030493\n",
              "std      61.807655    15.694599    12.731059\n",
              "min       2.000000     0.000000     0.000000\n",
              "25%      36.000000     8.000000     1.000000\n",
              "50%      61.000000    15.000000     2.000000\n",
              "75%     123.000000    28.000000     4.000000\n",
              "max     790.000000   195.000000   127.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9rSWD4i1X3s"
      },
      "source": [
        "### Modeling case normalized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s74YoH-nSeO"
      },
      "source": [
        "We will use a very simple model, as the objective is to show different basic NLP data processing techniques more than modeling. Here, we want to see if three simple features can aid in the classification of spam. As more features are added, passing them through the same model will help in seeing if the\n",
        "featurization aids or hampers the accuracy of the classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WU6sxf2qcZd"
      },
      "source": [
        "# Basic 1-layer neural network model for evaluation\n",
        "def make_model(input_dims=3, num_units=12):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  # Adds a densely-connected layer with 12 units to the model:\n",
        "  model.add(tf.keras.layers.Dense(num_units, \n",
        "                                  input_dim=input_dims, \n",
        "                                  activation='relu'))\n",
        "\n",
        "  # Add a sigmoid layer with a binary output unit:\n",
        "  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_XRB02Rn0zP"
      },
      "source": [
        "This model uses binary cross-entropy for computing loss and the Adam optimizer\n",
        "for training. The key metric, given that this is a binary classification problem, is accuracy.\n",
        "\n",
        "We can train our simple baseline model with only three features like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz1aTS9LuFpF"
      },
      "source": [
        "model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otOL712wu4tW",
        "outputId": "3d11dca4-6a9b-449a-e600-2feb1b1d4a5b"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "446/446 [==============================] - 3s 2ms/step - loss: 1.0062 - accuracy: 0.8804\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2998 - accuracy: 0.9176\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2208 - accuracy: 0.9406\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.1931 - accuracy: 0.9412\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9346\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.9388\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.9327\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.9435\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.9442\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.9394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd240632fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJf7Xza5oRAD"
      },
      "source": [
        "This is not bad as our three simple features help us get to 93% accuracy. A quick check shows that there are 592 spam messages in the test set, out of a total of 4,459. So, this model is doing better than a very simple model that guesses everything as not spam.\n",
        "\n",
        "That model would have an accuracy of 87%. This number may be\n",
        "surprising but is fairly common in classification problems where there is a severe class imbalance in the data. Evaluating it on the training set gives an accuracy of around 93.27%:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svFEbDWzccXV",
        "outputId": "089f2f7e-bc2f-4da2-96e2-953bb56898e9"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.9417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19357681274414062, 0.9417040348052979]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vo6YuM0p960"
      },
      "source": [
        "Please note that the actual performance you see may be slightly different due to the data splits and computational vagaries. \n",
        "\n",
        "A quick verification can be performed by plotting the confusion matrix to see the performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Aw3qskjDC-j",
        "outputId": "b14be731-85dc-439d-f5ea-950d11a6b74c"
      },
      "source": [
        "y_train_pred = model.predict_classes(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c73dfRXaFD3F",
        "outputId": "80fa305b-f727-41af-f2c8-c87a10d08cd7"
      },
      "source": [
        "# confusion matrix\n",
        "tf.math.confusion_matrix(tf.constant(y_train.Spam), y_train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[3756,  111],\n",
              "       [ 157,  435]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdMnEPdqrsaq"
      },
      "source": [
        "This shows that 3,666 out of 3,867 regular messages were classified correctly, while 353 out of 592 spam messages were classified correctly. Again, you may get a slightly different result.\n",
        "\n",
        "|  | **Predicted Not Spam** | **Predicted Spam** |\n",
        "| --- | --- | --- |\n",
        "| **Actual Not Spam** | 3777 | 90 |\n",
        "| **Actual Spam** | 186 | 406 |\n",
        "\n",
        "We can get calculation as follow:\n",
        "\n",
        "|  | **Predicted Not Spam** | **Predicted Spam** | |\n",
        "| --- | --- | --- | |\n",
        "| **Actual Not Spam** | 3777 | 90 | 3777 + 90 = 3867 |\n",
        "| **Actual Spam**     | 186  | 406 |  186 + 406 = 592  |\n",
        "\n",
        "So confusion matrix show us that if we reduce the value 201 and 239 then accuracy would be increased."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmcZKcJqGiAK",
        "outputId": "0ec26e9d-03d8-4e1d-a5e5-50652cc345a5"
      },
      "source": [
        "sum(y_train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([546], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUBeCm5eDduc",
        "outputId": "56584023-26f1-4a22-e00d-f12266c18c31"
      },
      "source": [
        "y_test_pred = model.predict_classes(x_test)\n",
        "tf.math.confusion_matrix(tf.constant(y_test.Spam), y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[939,  21],\n",
              "       [ 44, 111]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG-KrlJ_jgaB"
      },
      "source": [
        "### Excersize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmOUztFG3hA0"
      },
      "source": [
        "To test the value of the features, try re-running the model by removing one of the features, such as punctuation or a number of capital letters, to get a sense of their contribution to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w73qPjPo6O7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ae3b84-db8c-4557-a4ba-4ce44f3b3249"
      },
      "source": [
        "x_train = train[['Length', 'Punctuation']]\n",
        "y_train = train[['Spam']]\n",
        "\n",
        "x_test = test[['Length', 'Punctuation']]\n",
        "y_test = test[['Spam']]\n",
        "\n",
        "x_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>80.316439</td>\n",
              "      <td>18.886522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>59.346407</td>\n",
              "      <td>14.602023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>122.000000</td>\n",
              "      <td>27.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>910.000000</td>\n",
              "      <td>253.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Length  Punctuation\n",
              "count  4459.000000  4459.000000\n",
              "mean     80.316439    18.886522\n",
              "std      59.346407    14.602023\n",
              "min       2.000000     0.000000\n",
              "25%      35.000000     8.000000\n",
              "50%      61.000000    15.000000\n",
              "75%     122.000000    27.000000\n",
              "max     910.000000   253.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ZY2PGA7AJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6b2088-d2de-48f2-8f34-cd927d5bfe51"
      },
      "source": [
        "x_test.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>80.951570</td>\n",
              "      <td>19.166816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>61.807655</td>\n",
              "      <td>15.694599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>123.000000</td>\n",
              "      <td>28.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>790.000000</td>\n",
              "      <td>195.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Length  Punctuation\n",
              "count  1115.000000  1115.000000\n",
              "mean     80.951570    19.166816\n",
              "std      61.807655    15.694599\n",
              "min       2.000000     0.000000\n",
              "25%      36.000000     8.000000\n",
              "50%      61.000000    15.000000\n",
              "75%     123.000000    28.000000\n",
              "max     790.000000   195.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqzLS6Se6cJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf11337-5793-4acc-ffc4-049b2d7a027c"
      },
      "source": [
        "model1 = make_model(input_dims=2)\n",
        "model1.fit(x_train, y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 7.1731 - accuracy: 0.3518\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.8673\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.4089 - accuracy: 0.8768\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8893\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2983 - accuracy: 0.8974\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2918 - accuracy: 0.8949\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.8901\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.8904\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.8967\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.8886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2404360d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl3fHX2v6kWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de09a84-03db-47be-cd66-098ae5e231ec"
      },
      "source": [
        "model1.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25163596868515015, 0.8923766613006592]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbHgc-4o6o7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2586bdf1-04ed-458a-9738-5987704da49d"
      },
      "source": [
        "y_train_pred = model1.predict_classes(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0tXsgdK669a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea663407-7d43-4d91-9d98-fb351db0b96f"
      },
      "source": [
        "# confusion matrix\n",
        "tf.math.confusion_matrix(tf.constant(y_train.Spam), y_train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[3646,  221],\n",
              "       [ 248,  344]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erz6fMIh7inz"
      },
      "source": [
        "Now trying to remove Punctuation letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPY5twmY7i-a"
      },
      "source": [
        "x_train = train[['Length', 'Capitals']]\n",
        "y_train = train[['Spam']]\n",
        "\n",
        "x_test = test[['Length', 'Capitals']]\n",
        "y_test = test[['Spam']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMjL2V7Q7oAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f24a8b9-2b16-472e-92bc-7a2753dd9a9a"
      },
      "source": [
        "model2 = make_model(input_dims=2)\n",
        "model2.fit(x_train, y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 6.8152 - accuracy: 0.8690\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.8870\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.3839 - accuracy: 0.9137\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.9249\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2678 - accuracy: 0.9188\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9143\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.9135\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2385 - accuracy: 0.9181\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.9216\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2296 - accuracy: 0.9196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2401b7c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R3euiud7qsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbfa25e3-71d4-4bd3-fef4-523bc60a71df"
      },
      "source": [
        "model2.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.9121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2676241099834442, 0.9121076464653015]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNcb5VU7sqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e720e733-cee6-43a1-c907-a6870724a663"
      },
      "source": [
        "y_train_pred = model2.predict_classes(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgAOpxmp7tJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d82b56-ae5f-4b28-b62f-40bd3adb88c5"
      },
      "source": [
        "# confusion matrix\n",
        "tf.math.confusion_matrix(tf.constant(y_train.Spam), y_train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[3724,  143],\n",
              "       [ 215,  377]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "warQbntF8NMc"
      },
      "source": [
        "We observe that removing one of the features punctuation letters, It contribute to the model accuracy by increasing upto 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY-ssfsAOusL"
      },
      "source": [
        "## Tokenization normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Ep_y1hmR29"
      },
      "source": [
        "This step takes a piece of text and converts it into a list of tokens. If the input is a sentence, then separating the words would be an example of tokenization. Depending on the model, different granularities can be chosen. At the lowest level, each character could become a token. In some cases, entire sentences of paragraphs can be considered as a token:\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/advanced-nlp-with-tensorflow-2/sentence-tokenizing.png?raw=1' width='800'/>\n",
        "\n",
        "The preceding diagram shows two ways a sentence can be tokenized. One way to\n",
        "tokenize is to chop a sentence into words. Another way is to chop into individual characters. However, this can be a complex proposition in some languages such as Japanese and Mandarin.\n",
        "\n",
        "\n",
        "Many languages use a word separator, a space, to separate words. This makes the\n",
        "task of tokenizing on words trivial. However, there are other languages that do not use any markers or separators between words. Some examples of such languages are Japanese and Chinese. In such languages, the task is referred to as segmentation.\n",
        "\n",
        "Fortunately, most languages are not as complex as Japanese and use spaces to\n",
        "separate words. In Python, splitting by spaces is trivial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MWyaX6IPk2l",
        "outputId": "802a83fd-5a71-46a1-c771-582cb529ad84"
      },
      "source": [
        "sentence = 'Go until jurong point, crazy.. Available only in bugis n great world'\n",
        "sentence.split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Go',\n",
              " 'until',\n",
              " 'jurong',\n",
              " 'point,',\n",
              " 'crazy..',\n",
              " 'Available',\n",
              " 'only',\n",
              " 'in',\n",
              " 'bugis',\n",
              " 'n',\n",
              " 'great',\n",
              " 'world']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKV-uwGNppag"
      },
      "source": [
        "The two lines(`point,` and `crazy..`) in the preceding output show that the naÃ¯ve approach in Python will result in punctuation being included in the words, among other issues. Consequently, this step is done through a library like StanfordNLP.\n",
        "\n",
        "This package provides capabilities for tokenization, POS tagging, and lemmatization out of the box. To start with tokenization, we instantiate a pipeline and tokenize a sample text to see how this works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RriSmiOlqMW3",
        "outputId": "88f368de-26c5-463b-d27b-edf07cdd4a55"
      },
      "source": [
        "en = snlp.Pipeline(lang=\"en\", processors=\"tokenize\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: gpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKF8dMc8tWlP"
      },
      "source": [
        "For now, only tokenization of text is desired, so only the tokenizer is used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qISguLeetXCe",
        "outputId": "5d29adba-3e79-4af6-ff27-bddf8f7771a9"
      },
      "source": [
        "tokenized = en(sentence)\n",
        "len(tokenized.sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB3TeWujtmIo"
      },
      "source": [
        "This shows that the tokenizer correctly divided the text into two sentences.\n",
        "\n",
        "To investigate what words were removed, the following code can be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW9jwgqEtmx6",
        "outputId": "fdd81d2f-e7a1-4906-afe9-a2690fa52388"
      },
      "source": [
        "for snt in tokenized.sentences:\n",
        "  for word in snt.tokens:\n",
        "    print(word.text)\n",
        "  print(\"<End of Sentence>\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go\n",
            "until\n",
            "jurong\n",
            "point\n",
            ",\n",
            "crazy\n",
            "..\n",
            "<End of Sentence>\n",
            "Available\n",
            "only\n",
            "in\n",
            "bugis\n",
            "n\n",
            "great\n",
            "world\n",
            "<End of Sentence>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WJVunh4t9dA"
      },
      "source": [
        "Punctuation marks were separated out into their own words. Text was split into multiple sentences. This is an improvement over only using spaces to split. In some applications, removal of punctuation may be required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5NI7lL_aPrR"
      },
      "source": [
        "### Japanese Tokenization Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7BlmnJdujAR"
      },
      "source": [
        "Consider the preceding example of Japanese. To see the performance of StanfordNLP on Japanese tokenization, the following piece of code can be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twQsK3NSRh3e",
        "outputId": "85d7e491-57f9-4d11-fe9a-f55bf99a7290"
      },
      "source": [
        "jp = snlp.download('ja')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default treebank \"ja_gsd\" for language \"ja\".\n",
            "Would you like to download the models for: ja_gsd now? (Y/n)\n",
            "Y\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "\n",
            "Downloading models for: ja_gsd\n",
            "Download location: /root/stanfordnlp_resources/ja_gsd_models.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 219M/219M [00:22<00:00, 9.61MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/ja_gsd_models.zip\n",
            "Extracting models file for: ja_gsd\n",
            "Cleaning up...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axyFewm6u768"
      },
      "source": [
        "Next, a Japanese pipeline will be instantiated and the words will be processed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM_AJ4mCS2ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659cb1ee-f320-4b8d-838c-044f02eacea7"
      },
      "source": [
        "jp = snlp.Pipeline(lang=\"ja\", processors=\"tokenize\")\n",
        "jp_line = jp(\"é¸æŒ™ç®¡ç†å§”å“¡ä¼š\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: gpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/ja_gsd_models/ja_gsd_tokenizer.pt', 'lang': 'ja', 'shorthand': 'ja_gsd', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EbAZGWLvEHR"
      },
      "source": [
        "You may recall that the Japanese text reads Election Administration Committee.\n",
        "Correct tokenization should produce three words, where first two should be two\n",
        "characters each, and the last word is three characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMo9DqvMTzX_",
        "outputId": "d6bedc7b-7c0c-467a-f01d-e46385744a72"
      },
      "source": [
        "for snt in jp_line.sentences:\n",
        "  for word in snt.tokens:\n",
        "    print(word.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "é¸æŒ™\n",
            "ç®¡ç†\n",
            "å§”å“¡ä¼š\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NAW2TRM2HSl"
      },
      "source": [
        "This matches the expected output. StanfordNLP supports 53 languages, so the same\n",
        "code can be used for tokenizing any language that is supported.\n",
        "\n",
        "Coming back to the spam detection example, a new feature can be implemented that\n",
        "counts the number of words in the message using this tokenization functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nKfjQeOaWtz"
      },
      "source": [
        "### Modeling tokenized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZghEI-h2cBL"
      },
      "source": [
        "It is possible that spam messages have different numbers of words than regular\n",
        "messages. The first step is to define a method to compute the number of words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBK3MokpYa6n"
      },
      "source": [
        "def word_counts(x, pipeline=en):\n",
        "  doc = pipeline(x)\n",
        "  count = sum( [ len(sentence.tokens) for sentence in doc.sentences] )\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQf6MQNmbazh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94975b39-19d9-4b2d-d36c-4f7fe2597cc2"
      },
      "source": [
        "en = snlp.Pipeline(lang='en', processors='tokenize')\n",
        "df['Words'] = df['Message'].apply(word_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: gpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "JGgd-Us74l5P",
        "outputId": "c41ea7fe-ab8d-47d8-964b-18147d1bea88"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Message</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>111</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "      <td>155</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>49</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>61</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Spam                                            Message  ...  Length  Words\n",
              "0     0  Go until jurong point, crazy.. Available only ...  ...     111     24\n",
              "1     0                      Ok lar... Joking wif u oni...  ...      29      8\n",
              "2     1  Free entry in 2 a wkly comp to win FA Cup fina...  ...     155     34\n",
              "3     0  U dun say so early hor... U c already then say...  ...      49     13\n",
              "4     0  Nah I don't think he goes to usf, he lives aro...  ...      61     15\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiIkXlIA32J_"
      },
      "source": [
        "Next, using the train and test splits, add a column for the word count feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-pqZ1a3dOg2"
      },
      "source": [
        "#train=df.sample(frac=0.8,random_state=42) #random state is a seed value\n",
        "#test=df.drop(train.index)\n",
        "\n",
        "train['Words'] = train['Message'].apply(word_counts)\n",
        "test['Words'] = test['Message'].apply(word_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lruns2ddQzT"
      },
      "source": [
        "x_train = train[['Length', 'Punctuation', 'Capitals', 'Words']]\n",
        "y_train = train[['Spam']]\n",
        "\n",
        "x_test = test[['Length', 'Punctuation', 'Capitals' , 'Words']]\n",
        "y_test = test[['Spam']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8So4_u34daa5",
        "outputId": "3c61b266-ea3b-4ce9-f05b-8e47eacd6d89"
      },
      "source": [
        "model = make_model(input_dims=4)\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 3.7059 - accuracy: 0.6091\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.4739 - accuracy: 0.8881\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.3698 - accuracy: 0.8862\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8912\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8983\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8893\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.8966\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.9017\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.9004\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2689 - accuracy: 0.8981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd1be3a9e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYOE-oB5EEz"
      },
      "source": [
        "There is only a marginal improvement in accuracy. One hypothesis is that the\n",
        "number of words is not useful. It would be useful if the average number of words in spam messages were smaller or larger than regular messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw__r38sdv60",
        "outputId": "fa2cdb2e-8b98-4eee-d334-50e869afea8a"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.8870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2666502594947815, 0.8869954943656921]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA9EZl155Nfw"
      },
      "source": [
        "Using pandas, this can be quickly verified:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "BZUvMagI5O5G",
        "outputId": "0dfb5815-b50a-40d3-f56f-5dde6e8adcb1"
      },
      "source": [
        "train.loc[train.Spam == 1].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>592.0</td>\n",
              "      <td>592.000000</td>\n",
              "      <td>592.000000</td>\n",
              "      <td>592.000000</td>\n",
              "      <td>592.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "      <td>15.320946</td>\n",
              "      <td>29.086149</td>\n",
              "      <td>138.856419</td>\n",
              "      <td>29.511824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>11.635105</td>\n",
              "      <td>7.083572</td>\n",
              "      <td>28.079980</td>\n",
              "      <td>7.474256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>49.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Spam    Capitals  Punctuation      Length       Words\n",
              "count  592.0  592.000000   592.000000  592.000000  592.000000\n",
              "mean     1.0   15.320946    29.086149  138.856419   29.511824\n",
              "std      0.0   11.635105     7.083572   28.079980    7.474256\n",
              "min      1.0    0.000000     2.000000   13.000000    3.000000\n",
              "25%      1.0    7.000000    26.000000  132.000000   26.000000\n",
              "50%      1.0   14.000000    30.000000  149.000000   30.000000\n",
              "75%      1.0   21.000000    34.000000  157.000000   35.000000\n",
              "max      1.0  128.000000    49.000000  197.000000   49.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8ctKayW5cWM"
      },
      "source": [
        "Let's compare the preceding results to the statistics for regular messages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "43pbHPeY5cwH",
        "outputId": "34dd87ca-0250-4b0a-ba8d-5391ede8e394"
      },
      "source": [
        "train.loc[train.Spam == 0].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3867.0</td>\n",
              "      <td>3867.000000</td>\n",
              "      <td>3867.000000</td>\n",
              "      <td>3867.000000</td>\n",
              "      <td>3867.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.018878</td>\n",
              "      <td>17.325058</td>\n",
              "      <td>71.354538</td>\n",
              "      <td>17.344194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>10.599291</td>\n",
              "      <td>14.826644</td>\n",
              "      <td>57.755351</td>\n",
              "      <td>13.811278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>22.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>910.000000</td>\n",
              "      <td>209.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Spam     Capitals  Punctuation       Length        Words\n",
              "count  3867.0  3867.000000  3867.000000  3867.000000  3867.000000\n",
              "mean      0.0     4.018878    17.325058    71.354538    17.344194\n",
              "std       0.0    10.599291    14.826644    57.755351    13.811278\n",
              "min       0.0     0.000000     0.000000     2.000000     1.000000\n",
              "25%       0.0     1.000000     8.000000    33.000000     8.000000\n",
              "50%       0.0     2.000000    13.000000    53.000000    13.000000\n",
              "75%       0.0     3.000000    23.000000    92.000000    22.000000\n",
              "max       0.0   129.000000   253.000000   910.000000   209.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvtjp9cL50sy"
      },
      "source": [
        "Some interesting patterns can quickly be seen. Spam messages usually have much\n",
        "less deviation from the mean. Focus on the Capitals feature column. It shows that regular messages use far fewer capitals than spam messages.\n",
        "\n",
        "This quick check yields an indication as to why adding the word features wasn't that useful. However, there are a couple of things to consider still. \n",
        "\n",
        "First, the tokenization model split out punctuation marks as words. Ideally, these words should be removed from the word counts as the punctuation feature is showing that spam messages use a lot more punctuation characters.\n",
        "\n",
        "Secondly, languages have some common words that are usually excluded. This is called stop word removal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH43JjrwS9Ta"
      },
      "source": [
        "## Stop Word Removal normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM_0pC-U41qO"
      },
      "source": [
        "Stop word removal involves removing common words such as articles (the, an)\n",
        "and conjunctions (and, but), among others. In the context of information retrieval or search, these words would not be helpful in identifying documents or web pages that would match the query.\n",
        "\n",
        "The step after text normalization is vectorization.The key step in vectorization is to build a vocabulary or dictionary of all the tokens. The size of this vocabulary can be reduced by removing stop words. While training and evaluating models, removing stop words reduces the number of computation steps that need to be performed. Hence, the removal of stop words can yield benefits in terms of computation speed and storage space.\n",
        "\n",
        "Many NLP packages provide lists of stop words. These can be removed from the\n",
        "text after tokenization. For this example, we will use\n",
        "an open source package called stopwordsiso.\n",
        "\n",
        "English language stop words can be checked as well to get an idea of some of the\n",
        "words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-kxi8XBTA1r",
        "outputId": "1c86f872-ea80-4507-c070-04dac9985996"
      },
      "source": [
        "import stopwordsiso as stopwords\n",
        "\n",
        "stopwords.langs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'af',\n",
              " 'ar',\n",
              " 'bg',\n",
              " 'bn',\n",
              " 'br',\n",
              " 'ca',\n",
              " 'cs',\n",
              " 'da',\n",
              " 'de',\n",
              " 'el',\n",
              " 'en',\n",
              " 'eo',\n",
              " 'es',\n",
              " 'et',\n",
              " 'eu',\n",
              " 'fa',\n",
              " 'fi',\n",
              " 'fr',\n",
              " 'ga',\n",
              " 'gl',\n",
              " 'gu',\n",
              " 'ha',\n",
              " 'he',\n",
              " 'hi',\n",
              " 'hr',\n",
              " 'hu',\n",
              " 'hy',\n",
              " 'id',\n",
              " 'it',\n",
              " 'ja',\n",
              " 'ko',\n",
              " 'ku',\n",
              " 'la',\n",
              " 'lt',\n",
              " 'lv',\n",
              " 'mr',\n",
              " 'ms',\n",
              " 'nl',\n",
              " 'no',\n",
              " 'pl',\n",
              " 'pt',\n",
              " 'ro',\n",
              " 'ru',\n",
              " 'sk',\n",
              " 'sl',\n",
              " 'so',\n",
              " 'st',\n",
              " 'sv',\n",
              " 'sw',\n",
              " 'th',\n",
              " 'tl',\n",
              " 'tr',\n",
              " 'uk',\n",
              " 'ur',\n",
              " 'vi',\n",
              " 'yo',\n",
              " 'zh',\n",
              " 'zu'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE093gWDT57H",
        "outputId": "b65fa351-611b-4124-900b-5aa7c1ed0c3a"
      },
      "source": [
        "sorted(stopwords.stopwords('en'))[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'ll\",\n",
              " \"'tis\",\n",
              " \"'twas\",\n",
              " \"'ve\",\n",
              " '10',\n",
              " '39',\n",
              " 'a',\n",
              " \"a's\",\n",
              " 'able',\n",
              " 'ableabout',\n",
              " 'about',\n",
              " 'above',\n",
              " 'abroad',\n",
              " 'abst',\n",
              " 'accordance',\n",
              " 'according',\n",
              " 'accordingly',\n",
              " 'across',\n",
              " 'act',\n",
              " 'actually',\n",
              " 'ad',\n",
              " 'added',\n",
              " 'adj',\n",
              " 'adopted',\n",
              " 'ae',\n",
              " 'af',\n",
              " 'affected',\n",
              " 'affecting',\n",
              " 'affects',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'ag',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ago',\n",
              " 'ah',\n",
              " 'ahead',\n",
              " 'ai',\n",
              " \"ain't\",\n",
              " 'aint',\n",
              " 'al',\n",
              " 'all',\n",
              " 'allow',\n",
              " 'allows',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'alongside',\n",
              " 'already',\n",
              " 'also']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TNqa4ji88dN"
      },
      "source": [
        "Given that tokenization was already implemented in the preceding word_counts()\n",
        "method, the implementation of that method can be updated to include removing\n",
        "stop words. However, all the stop words are in lowercase.\n",
        "\n",
        "In this case, tokens need to be converted to lowercase to effectively remove them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXUXOkhgnRol"
      },
      "source": [
        "en_sw = stopwords.stopwords('en')\n",
        "\n",
        "def word_counts(x, pipeline=en):\n",
        "  doc = pipeline(x)\n",
        "  count = 0\n",
        "  for sentence in doc.sentences:\n",
        "    for token in sentence.tokens:\n",
        "        if token.text.lower() not in en_sw:\n",
        "          count += 1\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52gGyUFV-mDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264c2818-bae2-4849-f4ac-f3ca51fdcb62"
      },
      "source": [
        "en = snlp.Pipeline(lang='en', processors='tokenize')\n",
        "df['Words'] = df['Message'].apply(word_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: gpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trbxkc1B4sNP"
      },
      "source": [
        "train['Words'] = train['Message'].apply(word_counts)\n",
        "test['Words'] = test['Message'].apply(word_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiY8B8I2CRrT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "d096d3b9-f165-412b-b4d1-35ccad340c28"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.132765</td>\n",
              "      <td>5.519399</td>\n",
              "      <td>18.886522</td>\n",
              "      <td>80.316439</td>\n",
              "      <td>9.312178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.339359</td>\n",
              "      <td>11.405424</td>\n",
              "      <td>14.602023</td>\n",
              "      <td>59.346407</td>\n",
              "      <td>8.019288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>910.000000</td>\n",
              "      <td>147.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Spam     Capitals  Punctuation       Length        Words\n",
              "count  4459.000000  4459.000000  4459.000000  4459.000000  4459.000000\n",
              "mean      0.132765     5.519399    18.886522    80.316439     9.312178\n",
              "std       0.339359    11.405424    14.602023    59.346407     8.019288\n",
              "min       0.000000     0.000000     0.000000     2.000000     0.000000\n",
              "25%       0.000000     1.000000     8.000000    35.000000     4.000000\n",
              "50%       0.000000     2.000000    15.000000    61.000000     7.000000\n",
              "75%       0.000000     4.000000    27.000000   122.000000    13.000000\n",
              "max       1.000000   129.000000   253.000000   910.000000   147.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9-oRMGjCqT7"
      },
      "source": [
        "The maximum number of words has also reduced from 209 to 147. The standard deviation of regular messages is about the same as its mean, indicating that there is a lot of variation in the number of words in regular messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1mdWC9sCW6R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "fa480c19-dcd8-4eae-8a0b-12749286bbcc"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Message</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3690</th>\n",
              "      <td>0</td>\n",
              "      <td>You still coming tonight?</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3527</th>\n",
              "      <td>0</td>\n",
              "      <td>\"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...</td>\n",
              "      <td>107</td>\n",
              "      <td>48</td>\n",
              "      <td>161</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>0</td>\n",
              "      <td>Ya even those cookies have jelly on them</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3370</th>\n",
              "      <td>0</td>\n",
              "      <td>Sorry i've not gone to that place. I.ll do so ...</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>69</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>0</td>\n",
              "      <td>When are you going to ride your bike?</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Spam                                            Message  ...  Length  Words\n",
              "3690     0                          You still coming tonight?  ...      25      3\n",
              "3527     0  \"HEY BABE! FAR 2 SPUN-OUT 2 SPK AT DA MO... DE...  ...     161     36\n",
              "724      0           Ya even those cookies have jelly on them  ...      40      3\n",
              "3370     0  Sorry i've not gone to that place. I.ll do so ...  ...      69      5\n",
              "468      0              When are you going to ride your bike?  ...      37      3\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXwbN2oOCwBD"
      },
      "source": [
        "### Modeling data with stop words removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiyJkZrbCw9t"
      },
      "source": [
        "Now, let's see if this helps us train a model and improve its accuracy.\n",
        "\n",
        "Now that the feature without stop words is computed, it can be added to the model to see its impact:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXxl8S1vCGi3",
        "outputId": "3bb5b98f-f588-431e-a454-ace2cbe071fb"
      },
      "source": [
        "x_train = train[['Length', 'Punctuation', 'Capitals', 'Words']]\n",
        "y_train = train[['Spam']]\n",
        "\n",
        "x_test = test[['Length', 'Punctuation', 'Capitals' , 'Words']]\n",
        "y_test = test[['Spam']]\n",
        "\n",
        "model = make_model(input_dims=4)\n",
        "#model = make_model(input_dims=3)\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 3.4133 - accuracy: 0.8159\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.8778\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.8967\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2404 - accuracy: 0.9202\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2389 - accuracy: 0.9157\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.9141\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2294 - accuracy: 0.9238\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9359\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2290 - accuracy: 0.9195\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 1s 2ms/step - loss: 0.2090 - accuracy: 0.9305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd1b051ba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAoWENTDDGe-"
      },
      "source": [
        "This accuracy reflects a slight improvement over the previous model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIJHEzSdDG-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f73f4d5-834f-4c64-e93a-250458eb7ac3"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23106859624385834, 0.9246636629104614]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4-0huTw5YFe"
      },
      "source": [
        "## Part-of-speech tagging(POS) normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gukzs2zoCSzw"
      },
      "source": [
        "Languages have a grammatical structure. In most languages, words can be\n",
        "categorized primarily into verbs, adverbs, nouns, and adjectives. The objective of this part of the processing step is to take a piece of text and tag each word token with a POS identifier.\n",
        "\n",
        "Note that this makes sense only in the case of word-level\n",
        "tokens. Commonly, the Penn Treebank POS tagger is used by libraries including\n",
        "StanfordNLP to tag words. By convention, POS tags are added by using a code\n",
        "after the word, separated by a slash. As an example, NNS is the tag for a plural noun.If the words goats was encountered, it would be represented as goats/NNS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bSXLgr6iiB0",
        "outputId": "4c7d03e1-1801-45e1-dffd-ca8d100dd0e9"
      },
      "source": [
        "en = stanza.Pipeline(lang=\"en\")\n",
        "\n",
        "txt = \"Yo you around? A friend of mine's lookin.\"\n",
        "pos = en(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-04 09:03:48 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | combined  |\n",
            "| pos       | combined  |\n",
            "| lemma     | combined  |\n",
            "| depparse  | combined  |\n",
            "| sentiment | sstplus   |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2021-03-04 09:03:48 INFO: Use device: gpu\n",
            "2021-03-04 09:03:48 INFO: Loading: tokenize\n",
            "2021-03-04 09:03:56 INFO: Loading: pos\n",
            "2021-03-04 09:03:56 INFO: Loading: lemma\n",
            "2021-03-04 09:03:56 INFO: Loading: depparse\n",
            "2021-03-04 09:03:57 INFO: Loading: sentiment\n",
            "2021-03-04 09:03:57 INFO: Loading: ner\n",
            "2021-03-04 09:03:58 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFU6nJsnC-1_"
      },
      "source": [
        "The preceding code instantiates an English pipeline and processes a sample piece of text. The next piece of code is a reusable function to print back the sentence tokens with the POS tags:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD9BUu6gkNi_"
      },
      "source": [
        "def print_pos(doc):\n",
        "    text = \"\"\n",
        "    for sentence in doc.sentences:\n",
        "        for token in sentence.tokens:\n",
        "          text += token.words[0].text + \"/\" + token.words[0].upos + \" \"\n",
        "        text += \"\\n\"\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTLrN-BgkuWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04db0da2-7a79-4bed-9cd3-55f26e9113f1"
      },
      "source": [
        "print(print_pos(pos))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yo/PRON you/PRON around/ADV ?/PUNCT \n",
            "A/DET friend/NOUN of/ADP mine/PRON 's/PART lookin/NOUN ./PUNCT \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZdQ1yvNIR18"
      },
      "source": [
        "Most of these tags would make sense, though there may be some inaccuracies. For\n",
        "example, the word lookin is miscategorized as a noun. Neither StanfordNLP, nor\n",
        "a model from another package, will be perfect. This is something that we have to\n",
        "account for in building models using such features. There are a couple of different features that can be built using these POS.\n",
        "\n",
        "As a next step, let's update the word_counts() method and add a feature to show\n",
        "the percentages of symbols and punctuation in a message â€“ with the hypothesis that maybe spam messages use more punctuation and symbols. Other features around\n",
        "types of different grammatical elements can also be built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGkdUgEdEDcB"
      },
      "source": [
        "en_sw = stopwords.stopwords('en')\n",
        "\n",
        "def word_counts_v3(x, pipeline=en):\n",
        "  doc = pipeline(x)\n",
        "  totals = 0.\n",
        "  count = 0.\n",
        "  non_word = 0.\n",
        "  for sentence in doc.sentences:\n",
        "    totals += len(sentence.tokens)  # (1)\n",
        "    for token in sentence.tokens:\n",
        "        if token.text.lower() not in en_sw:\n",
        "          if token.words[0].upos not in ['PUNCT', 'SYM']:\n",
        "            count += 1.\n",
        "          else:\n",
        "            non_word += 1.\n",
        "  non_word = non_word / totals\n",
        "  return pd.Series([count, non_word], index=['Words_NoPunct', 'Punct'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6LWE7QWIuyu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "15f240a3-5d75-43a8-ff18-bfe666708b3c"
      },
      "source": [
        "x = train[:10]\n",
        "x.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>72.70000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>32.948445</td>\n",
              "      <td>14.772723</td>\n",
              "      <td>50.36103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>23.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.250000</td>\n",
              "      <td>37.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>57.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>23.750000</td>\n",
              "      <td>88.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>161.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Spam    Capitals  Punctuation     Length\n",
              "count  10.0   10.000000    10.000000   10.00000\n",
              "mean    0.0   14.400000    18.300000   72.70000\n",
              "std     0.0   32.948445    14.772723   50.36103\n",
              "min     0.0    1.000000     4.000000   23.00000\n",
              "25%     0.0    1.000000     7.250000   37.75000\n",
              "50%     0.0    1.500000    13.000000   57.00000\n",
              "75%     0.0    9.000000    23.750000   88.00000\n",
              "max     0.0  107.000000    48.000000  161.00000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AERuVEJFfBiZ"
      },
      "source": [
        "Since there are multiple computations that need to be performed on the message in each row, these operations are combined and a Series object with column labels is returned. This can be merged with the main DataFrame like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97Y6_7E8KJnQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "f5ab8c99-88d7-4125-ad05-a40f4a2f0283"
      },
      "source": [
        "train_tmp = train['Message'].apply(word_counts_v3)\n",
        "train = pd.concat([train, train_tmp], axis=1)\n",
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words_NoPunct</th>\n",
              "      <th>Punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.132765</td>\n",
              "      <td>5.519399</td>\n",
              "      <td>18.886522</td>\n",
              "      <td>80.316439</td>\n",
              "      <td>6.444046</td>\n",
              "      <td>0.148006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.339359</td>\n",
              "      <td>11.405424</td>\n",
              "      <td>14.602023</td>\n",
              "      <td>59.346407</td>\n",
              "      <td>5.601280</td>\n",
              "      <td>0.095298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>910.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.818182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Spam     Capitals  ...  Words_NoPunct        Punct\n",
              "count  4459.000000  4459.000000  ...    4459.000000  4459.000000\n",
              "mean      0.132765     5.519399  ...       6.444046     0.148006\n",
              "std       0.339359    11.405424  ...       5.601280     0.095298\n",
              "min       0.000000     0.000000  ...       0.000000     0.000000\n",
              "25%       0.000000     1.000000  ...       3.000000     0.090909\n",
              "50%       0.000000     2.000000  ...       5.000000     0.142857\n",
              "75%       0.000000     4.000000  ...       9.000000     0.200000\n",
              "max       1.000000   129.000000  ...      55.000000     0.818182\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ULpLpPUfNw0"
      },
      "source": [
        "A similar process can be performed on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUdTWXvWbvc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "ac22d7a3-a279-486a-d535-2bd78fe4a09d"
      },
      "source": [
        "test_tmp = test['Message'].apply(word_counts_v3)\n",
        "test = pd.concat([test, test_tmp], axis=1)\n",
        "test.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words_NoPunct</th>\n",
              "      <th>Punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "      <td>1115.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.139013</td>\n",
              "      <td>6.030493</td>\n",
              "      <td>19.166816</td>\n",
              "      <td>80.951570</td>\n",
              "      <td>6.611659</td>\n",
              "      <td>0.151337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.346116</td>\n",
              "      <td>12.731059</td>\n",
              "      <td>15.694599</td>\n",
              "      <td>61.807655</td>\n",
              "      <td>5.828400</td>\n",
              "      <td>0.102153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.093750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>790.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Spam     Capitals  ...  Words_NoPunct        Punct\n",
              "count  1115.000000  1115.000000  ...    1115.000000  1115.000000\n",
              "mean      0.139013     6.030493  ...       6.611659     0.151337\n",
              "std       0.346116    12.731059  ...       5.828400     0.102153\n",
              "min       0.000000     0.000000  ...       0.000000     0.000000\n",
              "25%       0.000000     1.000000  ...       3.000000     0.093750\n",
              "50%       0.000000     2.000000  ...       4.000000     0.142857\n",
              "75%       0.000000     4.000000  ...       9.000000     0.200000\n",
              "max       1.000000   127.000000  ...      46.000000     1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMv1q8_mKdjI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "bfd5701d-ed5f-4040-f8dc-4f163e2407a5"
      },
      "source": [
        "z = pd.concat([x, train_tmp], axis=1)\n",
        "z.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words_NoPunct</th>\n",
              "      <th>Punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.00000</td>\n",
              "      <td>4459.000000</td>\n",
              "      <td>4459.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>72.70000</td>\n",
              "      <td>6.444046</td>\n",
              "      <td>0.148006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>32.948445</td>\n",
              "      <td>14.772723</td>\n",
              "      <td>50.36103</td>\n",
              "      <td>5.601280</td>\n",
              "      <td>0.095298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.250000</td>\n",
              "      <td>37.75000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>57.00000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>23.750000</td>\n",
              "      <td>88.00000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>161.00000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.818182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Spam    Capitals  Punctuation     Length  Words_NoPunct        Punct\n",
              "count  10.0   10.000000    10.000000   10.00000    4459.000000  4459.000000\n",
              "mean    0.0   14.400000    18.300000   72.70000       6.444046     0.148006\n",
              "std     0.0   32.948445    14.772723   50.36103       5.601280     0.095298\n",
              "min     0.0    1.000000     4.000000   23.00000       0.000000     0.000000\n",
              "25%     0.0    1.000000     7.250000   37.75000       3.000000     0.090909\n",
              "50%     0.0    1.500000    13.000000   57.00000       5.000000     0.142857\n",
              "75%     0.0    9.000000    23.750000   88.00000       9.000000     0.200000\n",
              "max     0.0  107.000000    48.000000  161.00000      55.000000     0.818182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zA3lTo1gC0-"
      },
      "source": [
        "A quick check of the statistics for spam and non-spam messages in the training set shows the following, first for non-spam messages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jkFZUJcPHA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "ced58c6b-638e-439e-8f4e-2704264b605f"
      },
      "source": [
        "z.loc[z['Spam']==0].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words_NoPunct</th>\n",
              "      <th>Punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.00000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>72.70000</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.152905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>32.948445</td>\n",
              "      <td>14.772723</td>\n",
              "      <td>50.36103</td>\n",
              "      <td>8.058122</td>\n",
              "      <td>0.063198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.250000</td>\n",
              "      <td>37.75000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.132775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>57.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.177083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>23.750000</td>\n",
              "      <td>88.00000</td>\n",
              "      <td>6.750000</td>\n",
              "      <td>0.196875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>161.00000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.208333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Spam    Capitals  Punctuation     Length  Words_NoPunct      Punct\n",
              "count  10.0   10.000000    10.000000   10.00000      10.000000  10.000000\n",
              "mean    0.0   14.400000    18.300000   72.70000       5.600000   0.152905\n",
              "std     0.0   32.948445    14.772723   50.36103       8.058122   0.063198\n",
              "min     0.0    1.000000     4.000000   23.00000       1.000000   0.000000\n",
              "25%     0.0    1.000000     7.250000   37.75000       1.250000   0.132775\n",
              "50%     0.0    1.500000    13.000000   57.00000       2.000000   0.177083\n",
              "75%     0.0    9.000000    23.750000   88.00000       6.750000   0.196875\n",
              "max     0.0  107.000000    48.000000  161.00000      27.000000   0.208333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l86GIgYvP9Mc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "a505455c-1f37-4cab-f04e-9f54e8af80b8"
      },
      "source": [
        "z.loc[z['Spam']==1].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spam</th>\n",
              "      <th>Capitals</th>\n",
              "      <th>Punctuation</th>\n",
              "      <th>Length</th>\n",
              "      <th>Words_NoPunct</th>\n",
              "      <th>Punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Spam  Capitals  Punctuation  Length  Words_NoPunct  Punct\n",
              "count   0.0       0.0          0.0     0.0            0.0    0.0\n",
              "mean    NaN       NaN          NaN     NaN            NaN    NaN\n",
              "std     NaN       NaN          NaN     NaN            NaN    NaN\n",
              "min     NaN       NaN          NaN     NaN            NaN    NaN\n",
              "25%     NaN       NaN          NaN     NaN            NaN    NaN\n",
              "50%     NaN       NaN          NaN     NaN            NaN    NaN\n",
              "75%     NaN       NaN          NaN     NaN            NaN    NaN\n",
              "max     NaN       NaN          NaN     NaN            NaN    NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-PdmMu_R01u"
      },
      "source": [
        "aa = [word_counts_v3(y) for y in x['Message']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBxbhHD_SMPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "e8f1e2be-be6d-4d8b-f569-a16afc3ae2c1"
      },
      "source": [
        "ab = pd.DataFrame(aa)\n",
        "ab.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words_NoPunct</th>\n",
              "      <th>Punct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.152905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.058122</td>\n",
              "      <td>0.063198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.132775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.177083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.750000</td>\n",
              "      <td>0.196875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.208333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Words_NoPunct      Punct\n",
              "count      10.000000  10.000000\n",
              "mean        5.600000   0.152905\n",
              "std         8.058122   0.063198\n",
              "min         1.000000   0.000000\n",
              "25%         1.250000   0.132775\n",
              "50%         2.000000   0.177083\n",
              "75%         6.750000   0.196875\n",
              "max        27.000000   0.208333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKPzzgAxgNLZ"
      },
      "source": [
        "In general, word counts have been reduced even further after stop word removal.\n",
        "Further more, the new Punct feature computes the ratio of punctuation tokens in a message relative to the total tokens. Now we can build a model with this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnm19eWgOwu"
      },
      "source": [
        "### Modeling data with POS tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_-1NgZUgRqE"
      },
      "source": [
        "Plugging these features into the model, the following results are obtained:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-laDcSVDgUKg",
        "outputId": "693588d5-0327-46d4-e589-809af890620c"
      },
      "source": [
        "x_train = train[[\"Length\", \"Punctuation\", \"Capitals\", \"Words_NoPunct\", \"Punct\"]]\n",
        "y_train = train[[\"Spam\"]]\n",
        "\n",
        "x_test = train[[\"Length\", \"Punctuation\", \"Capitals\", \"Words_NoPunct\", \"Punct\"]]\n",
        "y_test = train[[\"Spam\"]]\n",
        "\n",
        "# make build\n",
        "model = make_model(input_dims=5)\n",
        "\n",
        "# train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "446/446 [==============================] - 4s 3ms/step - loss: 9.6284 - accuracy: 0.3422\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.5432 - accuracy: 0.8596\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.4295 - accuracy: 0.8820\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8912\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.3257 - accuracy: 0.9034\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.9185\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9153\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.2460 - accuracy: 0.9266\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.9374\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 1s 3ms/step - loss: 0.2165 - accuracy: 0.9287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2f3fed7e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm5Nc3jjhySn"
      },
      "source": [
        "The accuracy shows a slight increase and is now up to 94.66%. Upon testing, it\n",
        "seems to hold:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsYiQvMehy-I",
        "outputId": "a9e6a179-199d-4d29-df0d-a33c59cb4b0d"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140/140 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20073966681957245, 0.939672589302063]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}