{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/ai-powered-search/13_3_semantic_search_with__quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51uM8gPIW0mO"
      },
      "source": [
        "## Setup\n",
        "\n",
        "In this notebook, we\"re going to install a transformer model, analyze the embedding output, and compare some vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#outdoors\n",
        "![ ! -d 'outdoors' ] && git clone --depth=1 https://github.com/ai-powered-search/outdoors.git\n",
        "! cd outdoors && git pull\n",
        "! cd outdoors && cat outdoors.tgz.part* > outdoors.tgz\n",
        "! cd outdoors && mkdir -p '../data/outdoors/' && tar -xvf outdoors.tgz -C '../data/outdoors/'"
      ],
      "metadata": {
        "id": "5xShS9pNXKtl",
        "outputId": "607e66bd-7e5b-41f1-a8b8-3359e4adfc03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'outdoors'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 25 (delta 0), reused 22 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 491.39 MiB | 24.78 MiB/s, done.\n",
            "Updating files: 100% (23/23), done.\n",
            "Already up to date.\n",
            "README.md\n",
            "concepts.pickle\n",
            "._guesses.csv\n",
            "guesses.csv\n",
            "._guesses_all.json\n",
            "guesses_all.json\n",
            "outdoors_concepts.pickle\n",
            "outdoors_embeddings.pickle\n",
            "._outdoors_golden_answers.csv\n",
            "outdoors_golden_answers.csv\n",
            "._outdoors_golden_answers.xlsx\n",
            "outdoors_golden_answers.xlsx\n",
            "._outdoors_golden_answers_20210130.csv\n",
            "outdoors_golden_answers_20210130.csv\n",
            "outdoors_labels.pickle\n",
            "outdoors_question_answering_contexts.json\n",
            "outdoors_questionanswering_test_set.json\n",
            "outdoors_questionanswering_train_set.json\n",
            "._posts.csv\n",
            "posts.csv\n",
            "predicates.pickle\n",
            "pull_aips_dependency.py\n",
            "._question-answer-seed-contexts.csv\n",
            "question-answer-seed-contexts.csv\n",
            "question-answer-squad2-guesses.csv\n",
            "._roberta-base-squad2-outdoors\n",
            "roberta-base-squad2-outdoors/\n",
            "roberta-base-squad2-outdoors/._tokenizer_config.json\n",
            "roberta-base-squad2-outdoors/tokenizer_config.json\n",
            "roberta-base-squad2-outdoors/._special_tokens_map.json\n",
            "roberta-base-squad2-outdoors/special_tokens_map.json\n",
            "roberta-base-squad2-outdoors/._config.json\n",
            "roberta-base-squad2-outdoors/config.json\n",
            "roberta-base-squad2-outdoors/._merges.txt\n",
            "roberta-base-squad2-outdoors/merges.txt\n",
            "roberta-base-squad2-outdoors/._training_args.bin\n",
            "roberta-base-squad2-outdoors/training_args.bin\n",
            "roberta-base-squad2-outdoors/._pytorch_model.bin\n",
            "roberta-base-squad2-outdoors/pytorch_model.bin\n",
            "roberta-base-squad2-outdoors/._vocab.json\n",
            "roberta-base-squad2-outdoors/vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install faiss-cpu --no-cache\n",
        "# !pip install faiss-gpu"
      ],
      "metadata": {
        "id": "HQRWkAsbmB_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xA3xmRRHW0mQ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "sys.path.append(\"../..\")\n",
        "# from aips import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "import tqdm\n",
        "\n",
        "import faiss\n",
        "import sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
        "from sentence_transformers.quantization import quantize_embeddings\n",
        "\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ruXhtGPW0mR"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\n",
        "    \"mixedbread-ai/mxbai-embed-large-v1\",\n",
        "    similarity_fn_name=SimilarityFunction.DOT_PRODUCT,\n",
        "    truncate_dim=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get embeddings"
      ],
      "metadata": {
        "id": "KzFEJ0VxFGTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(texts, model, cache_name, ignore_cache=False):\n",
        "  cache_file_name = f\"data/outdoors/{cache_name}.pickle\"\n",
        "  if ignore_cache or not os.path.isfile(cache_file_name):\n",
        "    embeddings = model.encode(texts, normalize_embeddings=True)\n",
        "    os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
        "    with open(cache_file_name, \"wb\") as cache_file:\n",
        "      pickle.dump(embeddings, cache_file)\n",
        "  else:\n",
        "    with open(cache_file_name, \"rb\") as cache_file:\n",
        "      embeddings = pickle.load(cache_file)\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "WipDDFrAFdsl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(scores, ids, data):\n",
        "    results = generate_search_results(scores, ids, data)\n",
        "    display(results)\n",
        "    return results\n",
        "\n",
        "def get_outdoors_data():\n",
        "    outdoors_dataframe = pd.read_csv(\"data/outdoors/posts.csv\")\n",
        "    outdoors_data = list(outdoors_dataframe.to_dict())\n",
        "    return outdoors_data\n",
        "\n",
        "def display_statistics(search_results, baseline_search_results=None, start_message=\"Recall\"):\n",
        "    index_name = search_results[\"index_name\"]\n",
        "    time_taken = search_results[\"time_taken\"]\n",
        "    index_size = search_results[\"size\"]\n",
        "    improvement_ms = \"\"\n",
        "    improvement_size = \"\"\n",
        "    recall = 1.0\n",
        "    if baseline_search_results:\n",
        "        full_search_time = baseline_search_results[\"time_taken\"]\n",
        "        time_imp = round((full_search_time - time_taken) * 100 / full_search_time, 2)\n",
        "        improvement_ms = f\" ({time_imp}% improvement)\"\n",
        "        improvement_size = f\" ({round((baseline_search_results['size'] - index_size) * 100 / baseline_search_results['size'], 2)}% improvement)\"\n",
        "        recall = calculate_recall(baseline_search_results[\"results\"], search_results[\"results\"])\n",
        "\n",
        "    print(f\"{index_name} search took: {time_taken:.3f} ms{improvement_ms}\")\n",
        "    print(f\"{index_name} index size: {round(index_size / 1000000, 2)} MB{improvement_size}\")\n",
        "    print(f\"{start_message}: {round(recall, 4)}\")\n",
        "\n",
        "def calculate_recall(scored_full_results, scored_quantized_results):\n",
        "    recalls = []\n",
        "    for i in range(len(scored_full_results)):\n",
        "        full_ids = [r[\"id\"] for r in scored_full_results[i]]\n",
        "        quantized_ids = [r[\"id\"] for r in scored_quantized_results[i]]\n",
        "        recalls.append((len(set(full_ids).intersection(set(quantized_ids))) /\n",
        "                       len(set(quantized_ids))))\n",
        "    return sum(recalls) / len(recalls)\n",
        "\n",
        "def generate_search_results(faiss_scores, faiss_ids):\n",
        "    outdoors_data = get_outdoors_data()\n",
        "    faiss_results = []\n",
        "    for i in range(len(faiss_scores)):\n",
        "        results = []\n",
        "        for j, id in enumerate(faiss_ids[i]):\n",
        "            id = int(id)\n",
        "            result = {\"score\": faiss_scores[i][j],\n",
        "                      \"title\": outdoors_data[id][\"title\"],\n",
        "                      \"body\": outdoors_data[id][\"body\"],\n",
        "                      \"id\": id}\n",
        "            results.append(result)\n",
        "        faiss_results.append(results)\n",
        "    return faiss_results\n",
        "\n",
        "def time_and_execute_search(index, index_name, query_embeddings, k=25, num_runs=100):\n",
        "    search_times = []\n",
        "    faiss_scores = None\n",
        "    faiss_ids = None\n",
        "\n",
        "    for i in range(num_runs):\n",
        "        start_time = time.time()\n",
        "        faiss_scores, faiss_ids = index.search(query_embeddings, k=k)\n",
        "        time_taken = ((time.time() - start_time) * 1000)\n",
        "        search_times.append(time_taken)\n",
        "\n",
        "    results = {\"results\": generate_search_results(faiss_scores, faiss_ids),\n",
        "               \"time_taken\": np.average(search_times),\n",
        "               \"faiss_scores\": faiss_scores, \"faiss_ids\": faiss_ids}\n",
        "    index_stats = {}\n",
        "    if index_name:\n",
        "        index_stats ={\n",
        "            \"index_name\": index_name,\n",
        "            \"size\": os.path.getsize(index_name)\n",
        "        }\n",
        "    return results | index_stats"
      ],
      "metadata": {
        "id": "Z05FCJIODT-9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Scalar quantization"
      ],
      "metadata": {
        "id": "Zbjb6yEHPscY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's index full-precision embeddings using FAISS\n",
        "def index_full_precision_embeddings(doc_embeddings, name):\n",
        "  # IndexFlatIP is a simple, unoptimized index supporting different embedding formats\n",
        "  index = faiss.IndexFlatIP(doc_embeddings.shape[1])\n",
        "  index.add(doc_embeddings)      # Adds documents to the index\n",
        "  faiss.write_index(index, name) # Writes the index to disk\n",
        "  return index\n",
        "\n",
        "def get_outdoors_embeddings(model):\n",
        "  outdoors_dataframe = pd.read_csv(\"data/outdoors/posts.csv\")\n",
        "  post_texts = [\n",
        "      post[\"title\"] + \" \" + post[\"body\"]\n",
        "      for post in outdoors_dataframe.to_dict()\n",
        "  ]\n",
        "  return np.array(get_embeddings(post_texts, model, \"outdoors_mrl_normed\"))\n",
        "\n",
        "# Generates embeddings for the outdoors dataset\n",
        "outdoors_embeddings = get_outdoors_embeddings(model)\n",
        "# Creates a full-precision(Float32) FAISS index\n",
        "full_index = index_full_precision_embeddings(outdoors_embeddings, \"full_embeddings\")"
      ],
      "metadata": {
        "id": "sNWZ9u50OifI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "GDKLy9PWoxyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_search(\"mountain hike\", titles, log=True)"
      ],
      "metadata": {
        "id": "9MzyzbqTrjl4",
        "outputId": "70718473-7ec6-47c3-e7dc-7f69c58efa40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4>Results for: <em>mountain hike</em></h4>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.723 | How is elevation gain and change measured for hiking trails?\n",
            "0.715 | How do I Plan a Hiking Trip to Rocky Mountain National Park, CO\n",
            "0.698 | Hints for hiking the west highland way\n",
            "0.694 | New Hampshire A.T. Section Hike in May? Logistics and Trail Conditions\n",
            "0.678 | Long distance hiking trail markings in North America or parts thereof\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_search(\"dehyd\", titles, log=True)"
      ],
      "metadata": {
        "id": "GOqBwlcwrnwc",
        "outputId": "b88b9a23-c667-49f3-d988-6d35c9c24079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4>Results for: <em>dehyd</em></h4>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.633 | The re-hydration time for deydrated foods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_search(\"polar bear\", titles, log=True)"
      ],
      "metadata": {
        "id": "-Tiwj_NIr3wi",
        "outputId": "9f4997c3-58b6-4ad2-da46-e49471dff8db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4>Results for: <em>polar bear</em></h4>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.611 | Bear spray vs. rifles against polar bears?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_search(\"bear\", titles, log=True)"
      ],
      "metadata": {
        "id": "mpwq95wBr_YE",
        "outputId": "f9acfd8f-d31d-47cd-b437-76af4321846b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4>Results for: <em>bear</em></h4>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.63 | Running in bear country\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}