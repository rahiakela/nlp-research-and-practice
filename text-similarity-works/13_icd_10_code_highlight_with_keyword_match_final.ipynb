{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0hK4nU35JVaA",
        "N4dDTs-rJL_h",
        "TycHgKTZJ6a6"
      ],
      "authorship_tag": "ABX9TyMn15B42naUBgxuP9r0Skrf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/text-similarity-works/13_icd_10_code_highlight_with_keyword_match_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "u6vazPC0Ja4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install -U pdftotext\n",
        "!pip install PyPDF2\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "gdwgVvXuJdz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "id": "4QPcnYT5AKpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import difflib\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "import fitz\n",
        "import pdftotext\n",
        "from PyPDF2 import PdfFileReader, PdfReader, PdfFileWriter, PdfWriter\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.lang.en import English\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ],
      "metadata": {
        "id": "gKbd7WsfyYX3",
        "outputId": "1e0df1be-449d-49f9-8971-55f4997b6891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "/usr/local/lib/python3.8/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Imv6fB5gPBe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "vcyPFuUZgdRV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p input_files"
      ],
      "metadata": {
        "id": "2dfljcHuOVw3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(233/255,150/255,122/255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkJRL5RWXE00",
        "outputId": "00cda66f-819f-4ab1-9909-0cbcb5658590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9137254901960784, 0.5882352941176471, 0.47843137254901963)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Classes"
      ],
      "metadata": {
        "id": "9oNqjgIsRpNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_common_word_coords_nearby(page_obj, code_coord, keyword, match_sent):\n",
        "  is_closest_coord = False\n",
        "  # get common word list\n",
        "  common_words = get_common_words(keyword, match_sent)\n",
        "  if len(common_words) > 0:\n",
        "    # get common word coordinate\n",
        "    highlight_list = page_obj.search_for(common_words[0])\n",
        "    y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "    # find closet y coordinate value\n",
        "    closet_y_coords = find_nearest(y_coords_list, value=code_coord)\n",
        "    # check, common word coordinate within range of code coordinate\n",
        "    # if (code_coord-10) <= highlight_list[0][1] <= (code_coord + 10):\n",
        "    if (code_coord-10) <= closet_y_coords <= (code_coord + 10):\n",
        "      is_closest_coord = True\n",
        "  return is_closest_coord"
      ],
      "metadata": {
        "id": "NNpXZPLJnFGg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"page-36.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  #content_of_page = pdf_file.get_page_text(page) #Get page content\n",
        "  match_word = \"Z00.00\" \n",
        "  content_of_page = page_obj.get_text(\"blocks\", sort=False)  #get rect for all words\n",
        "\n",
        "  coords_array = []\n",
        "  y_coords_array = []\n",
        "  for content in content_of_page:\n",
        "    print(content)\n",
        "    if content[4].replace(\"(\", \"\").replace(\")\", \"\") == match_word:\n",
        "      rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "      print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")"
      ],
      "metadata": {
        "id": "5fMNK-lYGmne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Highlighter:\n",
        "  def __init__(self, code_df):\n",
        "    # loading and updating patterns for ICD-10 code\n",
        "    self.nlp_code10 = English()\n",
        "    self.nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"icd10_code_patterns-v5.jsonl\")\n",
        "\n",
        "    # define icd-10 code dataset\n",
        "    self.code_df = code_df\n",
        "    self.text_list = None\n",
        "\n",
        "    # define required directory path\n",
        "    self.PDF_FILES_PATH = \"pdf-files\"\n",
        "    self.TXT_FILES_PATH = \"txt-files\"\n",
        "    self.OUTPUT_FILES_PATH = \"output\"\n",
        "    create_directory(self.PDF_FILES_PATH)\n",
        "    create_directory(self.TXT_FILES_PATH)\n",
        "    create_directory(self.OUTPUT_FILES_PATH)\n",
        "\n",
        "  def split_pdf(self, pdf_path):\n",
        "      pdf_in_file = open(pdf_path, \"rb\")\n",
        "      pdf = PdfReader(pdf_in_file)\n",
        "      pdf_list = []\n",
        "      for page in range(len(pdf.pages)):\n",
        "          input_pdf = PdfReader(pdf_in_file)\n",
        "          output = PdfWriter()\n",
        "          #output.addPage(input_pdf.getPage(page))\n",
        "          output.add_page(input_pdf.pages[page])\n",
        "          with open(f\"{self.PDF_FILES_PATH}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "              output.write(outputStream)\n",
        "              pdf_list.append(f\"page-{page}.pdf\")\n",
        "      return pdf_list\n",
        "\n",
        "  def extract_text_from_pdf(self, pdf_list):\n",
        "    txt_file_list = []\n",
        "    i = 0\n",
        "    for pdf_file in pdf_list:\n",
        "      with open(os.path.join(self.PDF_FILES_PATH, pdf_file), \"rb\") as f:\n",
        "        pdf = pdftotext.PDF(f)\n",
        "\n",
        "      # Read all the text into one string\n",
        "      pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "      # write text into file\n",
        "      with open(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\", \"a\") as f:\n",
        "        f.write(pdf_text)\n",
        "      txt_file_list.append(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\")\n",
        "      i += 1\n",
        "    self.text_list = txt_file_list\n",
        "    return txt_file_list\n",
        "\n",
        "  def highlight_icd_code(self, icd10_code_dict, match_threshold=30, coordinate=False, pdf_file_name=None, cords_file_name=None):\n",
        "      pdf_file = fitz.open(pdf_file_name)\n",
        "      # create file to write coordinate\n",
        "      txt_output_file_name = open(f\"{self.OUTPUT_FILES_PATH}/{cords_file_name}\", \"a\")\n",
        "      # add file header \n",
        "      txt_output_file_name.write(\"| Page | Found Code | Actual ICD10-Code | Code Line # | ICD 10 description | Matched Line | Common Words | Matched Line # | confidence |\\n \")\n",
        "\n",
        "      def highlight_code(p_highlight, icd10_code, num_page, page_obj, code_coords):\n",
        "        match_found = None\n",
        "        sentence_list = []\n",
        "        keyword = \"\"\n",
        "\n",
        "        # do the color coding\n",
        "        keyword = self.get_keyword(icd10_code)\n",
        "        match_found_list, sentence_list = self.get_best_token_match(icd10_code, num_page, page_obj, code_coords, match_threshold)\n",
        "        # highlight code if threshold is more than match threshold and common word coordinate is within range of code coordinate\n",
        "        if match_found_list is not None:\n",
        "          print(f\"match_found_list: {match_found_list}\")\n",
        "          if match_found_list[0][1] >= match_threshold and len(keyword) > 0 and is_common_word_coords_nearby(page_obj, code_coords, keyword, match_found[0][0]):\n",
        "            page_highlight = page.add_highlight_annot(p_highlight)\n",
        "            page_highlight.set_colors(stroke=[0.66, 1, 0.07])  # light green\n",
        "            page_highlight.update()\n",
        "          else: # set color coding for keyword mismatch and lower match score\n",
        "            page_highlight = page.add_highlight_annot(p_highlight)\n",
        "            page_highlight.set_colors(stroke=[0.92, 0.59, 0.48]) # dark salmon\n",
        "            page_highlight.update()\n",
        "        return match_found, sentence_list, keyword\n",
        "\n",
        "      def highlight_common_words(page_obj, y_coords_array, curr_y_coord, common_word_list):\n",
        "        highlight_coords_dict = {}\n",
        "        highlighted_word_list = []\n",
        "        #get rect for all words\n",
        "        page_content = page_obj.get_text(\"words\", sort=False)  \n",
        "        # find closet y coordinate value\n",
        "        closet_y_coords = find_nearest(y_coords_array, value=curr_y_coord)\n",
        "        for content in page_content:\n",
        "          for common_word in common_word_list:\n",
        "            curr_word = clean_text(content[4])[0] if len(clean_text(content[4])) > 0 else \"\"\n",
        "            print(f\"closet_y_coords-{closet_y_coords}, Y-{content[1]}\")\n",
        "            if curr_word.lower() == common_word.lower() and (closet_y_coords-20) <= content[1] <= (closet_y_coords + 20):\n",
        "              rect_comp = fitz.Rect(content[0], content[1], content[2], content[3])\n",
        "              print(f\"closet_y_coords-{closet_y_coords}, Y-{content[1]}, Coords: {rect_comp}\")\n",
        "              #print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")\n",
        "              highlight = page_obj.add_highlight_annot(rect_comp)\n",
        "              highlight.update()\n",
        "              highlight_coords_dict[common_word] = rect_comp\n",
        "              highlighted_word_list.append(common_word)\n",
        "        return highlight_coords_dict, highlighted_word_list\n",
        "              \n",
        "      for page_num, page in enumerate(pdf_file):\n",
        "        # highlight ICD-10 code\n",
        "        if page_num in icd10_code_dict:\n",
        "          for code in icd10_code_dict[page_num]:\n",
        "            highlight_list = page.search_for(code)\n",
        "            # print(f\"Page-{page_num}, Code: {code}, Coordinate: {highlight_list}\")\n",
        "            # prepare list for y0 coord value\n",
        "            y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "            for highlight in highlight_list:\n",
        "              # highlight ICD-10 code  \n",
        "              match_found_list, sentence_list, keyword = highlight_code(highlight, code, page_num, page, highlight[1])\n",
        "              # write all info into text file\n",
        "              num_page = page_num + 1\n",
        "              #for idx, match_found in enumerate(match_list):\n",
        "              # match_found: ('Diagnosis: Encntr for general adult medical exam w/o abnormal findings (Z00.00)', 100)\n",
        "              max_match_sent = match_found_list[0][0] if match_found_list is not None else \"\"\n",
        "              max_match_score = match_found_list[0][1] if match_found_list is not None else 0\n",
        "              if max_match_score >= match_threshold and max_match_sent != 'NA':\n",
        "                common_words = []\n",
        "                for match_sent in match_found_list:\n",
        "                  common_words.extend(get_common_words(keyword, match_sent))\n",
        "                # print(f\"common_words: {common_words}\")\n",
        "                highlight_coords_dict, highlighted_word_list = highlight_common_words(page, y_coords_list, highlight[1], common_words)\n",
        "                #| Page | Found Code | Actual ICD10-Code | Code Line # | ICD 10 description | Matched Line| Common Words | Matched Line # | confidence | \n",
        "                code_cors_output = (f\"|Page-{num_page} | {code} | {reverse_code_pattern(code)} | {sentence_list.index(max_match_sent) + 1}\" \n",
        "                f\" | {keyword if keyword else 'No keyword found'} | {max_match_sent if len(highlighted_word_list) > 0 else 'No matched line'}\" \n",
        "                f\" | {common_words} | {sentence_list.index(max_match_sent) + 1} | {max_match_score} |\")\n",
        "                txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "              else:\n",
        "                code_cors_output = (f\"|Page-{num_page} | {code} | {reverse_code_pattern(code)} | 0 | {keyword if keyword else 'No keyword found'}\"\n",
        "                f\" | 'No matched line' | 'No common words' | 0 | {max_match_score} |\")\n",
        "                txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "              if coordinate and max_match_score >= match_threshold:\n",
        "                txt_output_file_name.write(\"%s\\n\" % f\"|{code}:{highlight}|\")\n",
        "                txt_output_file_name.write(\"%s\\n\" % f\"|{highlight_coords_dict}|\")\n",
        "                \n",
        "              txt_output_file_name.write(\"\\n\") # add extra line on every match code\n",
        "\n",
        "      txt_output_file_name.close()\n",
        "      pdf_output_file_name = f\"{self.OUTPUT_FILES_PATH}/{pdf_file_name.split('/')[1].split('.')[0]}_output.pdf\"\n",
        "      pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "      return pdf_output_file_name, cords_file_name\n",
        "\n",
        "  def search_icd_code(self, txt_list):\n",
        "    pdf_page_vocab = {}\n",
        "    for txt_file in txt_list:\n",
        "      with open(txt_file, \"r\") as f:\n",
        "        page_txt = f.read()\n",
        "\n",
        "        # check the page that have line number instead of code\n",
        "        index_page = False\n",
        "        if re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "          index_page = True\n",
        "\n",
        "        doc = self.nlp_code10(page_txt)\n",
        "        code_list = []\n",
        "        for ent in doc.ents:\n",
        "          if index_page:\n",
        "            # check the code contain letter \"L\"\n",
        "            if re.search(\"(L[0-9]+)\", ent.text):\n",
        "              continue\n",
        "            else:\n",
        "              code_list.append(ent.text)\n",
        "          else:\n",
        "            code_list.append(ent.text)\n",
        "\n",
        "        #code_list = [ent.text for ent in doc.ents if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", ent.text)]\n",
        "        if len(code_list) != 0:\n",
        "          page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "          pdf_page_vocab[page_number] = list(set(code_list)) \n",
        "          # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "    return pdf_page_vocab\n",
        "\n",
        "  def get_keyword(self, p_code):\n",
        "    keyword = \"\"\n",
        "    # reverse code if required\n",
        "    code = reverse_code_pattern(p_code)\n",
        "    # get keyword from dataset\n",
        "    keyword_list = list(self.code_df.loc[self.code_df[\"Code\"] == code][\"Keyword\"])\n",
        "    if len(keyword_list) > 0:\n",
        "      keyword = keyword_list[0]\n",
        "    return keyword\n",
        "\n",
        "  def get_best_token_match(self, p_code, num_page, page_obj, code_coords, match_threshold):\n",
        "    # Step 1: reverse code pattern\n",
        "    reversed_icd_code = reverse_code_pattern(p_code)\n",
        "    # Step 2: fetch keyword based on code \n",
        "    keyword = self.get_keyword(reversed_icd_code)\n",
        "    # Step 3: prepare sentence list \n",
        "    sentence_list = get_sentence_list(self.text_list, num_page)\n",
        "    # Step 4: get best token match ratio \n",
        "    match_list = [\n",
        "      (sentence, fuzz.token_set_ratio(keyword, sentence)) \n",
        "      for sentence in sentence_list if fuzz.token_set_ratio(keyword, sentence) > match_threshold\n",
        "    ]\n",
        "    match_found_list = []\n",
        "    num_page = num_page + 1\n",
        "    for match_f in match_list:\n",
        "      highlight_list = page_obj.search_for(match_f[0])\n",
        "      # prepare list for y0 coord value\n",
        "      y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "      # find closet y coordinate value\n",
        "      if len(y_coords_list) > 0:\n",
        "        closet_y_coords = find_nearest(y_coords_list, value=code_coords)\n",
        "        # print(f\"Code: {code_coords}, Y: {y_coords}\")\n",
        "        if (code_coords-20) <= closet_y_coords <= (code_coords + 20):\n",
        "          match_found_list.append(match_f)\n",
        "          print(f\"Page-{num_page}, Code: ({p_code})-{code_coords}, closet_y_coords:{closet_y_coords} Keyword: {keyword}, Match: {match_f}\")\n",
        "    return match_found_list, sentence_list\n",
        "    \n",
        "  def get_best_token_match2(self, p_code, num_page, match_threshold):\n",
        "    # Step 1: reverse code pattern\n",
        "    reversed_icd_code = reverse_code_pattern(p_code)\n",
        "    # Step 2: fetch keyword based on code \n",
        "    keyword = self.get_keyword(reversed_icd_code)\n",
        "    # Step 3: prepare sentence list \n",
        "    sentence_list = get_sentence_list(self.text_list, num_page)\n",
        "    # Step 4: get best match token ratio or wratio\n",
        "    match_list = [\n",
        "      (sentence, fuzz.token_set_ratio(keyword, sentence)) \n",
        "      for sentence in sentence_list if fuzz.token_set_ratio(keyword, sentence) > match_threshold\n",
        "    ]\n",
        "    match_found = sort_tuple(match_list)[0] if len(sort_tuple(match_list)) > 0 else (\"NA\", 0)\n",
        "    return match_found, sentence_list,\n",
        "\n",
        "def is_common_word_coords_nearby(page_obj, code_coord, keyword, match_sent):\n",
        "  is_closest_coord = False\n",
        "  # get common word list\n",
        "  common_words = get_common_words(keyword, match_sent)\n",
        "  if len(common_words) > 0:\n",
        "    # get common word coordinate\n",
        "    highlight_list = page_obj.search_for(common_words[0])\n",
        "    y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "    # find closet y coordinate value\n",
        "    closet_y_coords = find_nearest(y_coords_list, value=code_coord)\n",
        "    # check, common word coordinate within range of code coordinate\n",
        "    # if (code_coord-10) <= highlight_list[0][1] <= (code_coord + 10):\n",
        "    if (code_coord-10) <= closet_y_coords <= (code_coord + 10):\n",
        "      is_closest_coord = True\n",
        "  return is_closest_coord\n",
        "\n",
        "def find_nearest(array, value):\n",
        "  array = np.asarray(array)\n",
        "  idx = (np.abs(array - value)).argmin()\n",
        "  return array[idx]\n",
        "\n",
        "def get_common_words(sent1, sent2):\n",
        "  clean_token1 = clean_text(sent1)\n",
        "  clean_token2 = clean_text(sent2)\n",
        "  token_set1 = set(clean_token1)\n",
        "  token_set2 = set(clean_token2)\n",
        "\n",
        "  common_word_set = set()\n",
        "  def get_common(token_set1, token_set2):\n",
        "    for w1 in token_set1:\n",
        "      for w2 in token_set2:\n",
        "        if w1.lower() == w2.lower():\n",
        "          common_word_set.add(w1)\n",
        "  get_common(token_set1, token_set2)\n",
        "  get_common(token_set2, token_set1)\n",
        "  return list(common_word_set)\n",
        "\n",
        "def clean_text(sent):\n",
        "  # tokenize sentence\n",
        "  sent1 = word_tokenize(sent)\n",
        "  # filter stop words\n",
        "  filtered_sent = [w for w in sent1 if not w.lower() in stop_words]\n",
        "  filtered_sent = [w for w in filtered_sent if re.sub(re.compile('\\W'), '', w)]\n",
        "  clean_tokens = []\n",
        "  for token in filtered_sent:\n",
        "    if token.find(\"-\"):\n",
        "      tokens = token.split(\"-\")\n",
        "      clean_tokens.extend(tokens)\n",
        "    else:\n",
        "      clean_tokens.append(token)\n",
        "  return clean_tokens\n",
        "\n",
        "def get_sentence_line(p_code, sentence_list):\n",
        "  line_list = [(line + 1) for line, sent in enumerate(sentence_list) if p_code in sent]\n",
        "  return line_list\n",
        "\n",
        "def get_sentence_list(text_list, num_page):\n",
        "  with open(f\"{text_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "  return sentence_list\n",
        "\n",
        "def reverse_code_pattern(p_code):\n",
        "  orig_code = p_code\n",
        "\n",
        "  # check for code contains space(\" \")\n",
        "  tmp_code = orig_code.split(\" \")\n",
        "  if len(tmp_code) > 1:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "\n",
        "  # check for code contains dot(\".\")\n",
        "  tmp_code = p_code.split(\".\")\n",
        "  if len(tmp_code) > 1:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "  \n",
        "  # check for code contains comma(\",\")\n",
        "  tmp_code = p_code.split(\",\")\n",
        "  if len(tmp_code) == 2:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "  elif len(tmp_code) == 2:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[2].strip()}\"\n",
        "\n",
        "  # handle if the first char of code is missing\n",
        "  alphabats = {\"Z\": \"2\", \"B\": \"8\", \"O\": \"0\", \"S\": \"5\", \"l\": \"1\", \"G\": \"6\", \"o\": \"9\", \"i\": \"1\"}\n",
        "  for key, val in alphabats.items():\n",
        "    # replcae char on 0 index\n",
        "    if orig_code.find(val) == 0:\n",
        "      #orig_code = orig_code.replace(val, key)\n",
        "      orig_code = replacer(orig_code, key, 0)\n",
        "    # replcae char on 1 index\n",
        "    if orig_code.find(key) == 1:\n",
        "      orig_code = replacer(orig_code, val, 1)\n",
        "      # replcae char on 2 index\n",
        "      if orig_code.find(key) == 2:\n",
        "        orig_code = replacer(orig_code, val, 2)\n",
        "      break\n",
        "\n",
        "  return orig_code\n",
        "\n",
        "def replacer(s, newstring, index, nofail=False):\n",
        "  # raise an error if index is outside of the string\n",
        "  if not nofail and index not in range(len(s)):\n",
        "      raise ValueError(\"index outside given string\")\n",
        "\n",
        "  # if not erroring, but the index is still not in the correct range..\n",
        "  if index < 0:  # add it to the beginning\n",
        "      return newstring + s\n",
        "  if index > len(s):  # add it to the end\n",
        "      return s + newstring\n",
        "\n",
        "  # insert the new string between \"slices\" of the original\n",
        "  return s[:index] + newstring + s[index + 1:]\n",
        "\n",
        "def sort_tuple(p_tup):\n",
        "  return (sorted(p_tup, key = lambda x: x[1], reverse=True)) \n",
        "\n",
        "def create_directory(dir_name):\n",
        "  if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)"
      ],
      "metadata": {
        "id": "jRYlndgDUtds"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(120.63995361328125) <= 360.1600036621094 <= (120.63995361328125 + 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gACp2qd_9WSU",
        "outputId": "600c8289-c33d-4f42-805a-99265cf479a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Keyword Matching & Highlighting "
      ],
      "metadata": {
        "id": "7s7ZxYMUBAol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Step 1 - Z87.5\n",
        "- Step 2 - Personal history of complications of pregnancy, childbirth and the puerperium\n",
        "- Step 3 - Page keyword\n",
        "- Step 4 - calculate cosine similirity\n",
        "- Step 5 - \"Green\" > 60% otherwise \"Yellow\""
      ],
      "metadata": {
        "id": "9KDyJlx9bIH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input_files\n",
        "!mkdir -p input_files\n",
        "!rm -rf output\n",
        "!mkdir -p output"
      ],
      "metadata": {
        "id": "wfJwndx9vcTP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "32V_ohLAgvLg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: create highlighter instance\n",
        "INPUT_PDF_FILES_PATH = \"input_files\"\n",
        "code_df = pd.read_csv(\"icd_10_code_and_keywords_v2.csv\")\n",
        "\n",
        "highlighter = Highlighter(code_df)"
      ],
      "metadata": {
        "id": "leBmw505CQUl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for pdf_file in os.listdir(INPUT_PDF_FILES_PATH):\n",
        "  pdf_file_name = f\"{INPUT_PDF_FILES_PATH}/{pdf_file}\"\n",
        "  cords_file_name = f\"{pdf_file_name.split('/')[1].split('.')[0]}_cords.txt\"\n",
        "\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = highlighter.split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = highlighter.extract_text_from_pdf(pdf_list)\n",
        "\n",
        "  # Step-3: Searching ICD-10 code\n",
        "  icd10_code_dict = highlighter.search_icd_code(txt_list)\n",
        "\n",
        "  # Step-4: Highlighting ICD-10 code into pdf\n",
        "  pdf_output_file, txt_output_file = highlighter.highlight_icd_code(icd10_code_dict,\n",
        "                                                                    match_threshold=40,\n",
        "                                                                    coordinate=True,\n",
        "                                                                    pdf_file_name=pdf_file_name,\n",
        "                                                                    cords_file_name=cords_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "id": "hiOT-aTfedMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "JlOdZaO9IL5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip output/*.*"
      ],
      "metadata": {
        "id": "MeS8LHhjjfzU",
        "outputId": "d408efb9-e9f9-41d7-fe3c-d284d526756e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output/36page_cords.txt (deflated 59%)\n",
            "  adding: output/36page_output.pdf (deflated 1%)\n",
            "  adding: output/38page_cords.txt (deflated 57%)\n",
            "  adding: output/38page_output.pdf (deflated 3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip pdf_text_output.zip pdf-files/*.* txt-files/*.*"
      ],
      "metadata": {
        "id": "AsPhCIH-h1Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: spliting pdf file\n",
        "pdf_file_name = \"36page.pdf\"\n",
        "pdf_list = highlighter.split_pdf(pdf_file_name)\n",
        "\n",
        "# Step-2: Extracting text from pdf\n",
        "txt_list = highlighter.extract_text_from_pdf(pdf_list)"
      ],
      "metadata": {
        "id": "GJrJ862VBKhE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Searching ICD-10 code\n",
        "page_code10_dict = highlighter.search_icd_code(txt_list)"
      ],
      "metadata": {
        "id": "wTFQkZtHBiLO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_df = pd.read_csv(\"icd_10_code_and_keywords_v2.csv\")"
      ],
      "metadata": {
        "id": "1cqncdV0Lpj7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text clean up"
      ],
      "metadata": {
        "id": "tCMut1zqMm76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[7]}\", \"r\") as f:\n",
        "  my_text = f.read()"
      ],
      "metadata": {
        "id": "qaQ1wb0PMyMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(my_text)\n",
        "sentences = [sentence.text for sentence in doc.sents]"
      ],
      "metadata": {
        "id": "nwcAI5BnMuzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "id": "E5SUHuvrPRn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocess(text_file):\n",
        "  sentence_list = []\n",
        "  stopwords = [\"is\", \"a\"]\n",
        "  doc = nlp(my_text)\n",
        "  sentences = [sentence.text for sentence in doc.sents]\n",
        "  for sent in sentences:\n",
        "    clean_text = \" \".join(sent.split())  # Remove extra spaces, tabs, and line breaks\n",
        "    clean_text = re.sub(f\"[{re.escape(punctuation)}]\", \"\", clean_text) # Remove punctuation\n",
        "    clean_text = re.sub(r\"\\b[0-9]+\\b\\s*\", \"\", clean_text)     # Remove numbers\n",
        "    clean_text = \" \".join([w for w in clean_text.split() if not w.isdigit()]) # Remove digits= Side effect: removes extra spaces\n",
        "    clean_text = \" \".join([w for w in clean_text.split() if w.isalpha()]) # Remove non-alphabetic characters= Side effect: removes extra spaces\n",
        "    clean_text = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", clean_text) # Remove all special characters and punctuation\n",
        "    # Remove stopwords from a list\n",
        "    tokens = clean_text.split()\n",
        "    clean_tokens = [t for t in tokens if not t in stopwords]\n",
        "    clean_text = \" \".join(clean_tokens)\n",
        "    # Remove short tokens\n",
        "    tokens = clean_text.split()\n",
        "    clean_tokens = [t for t in tokens if len(t) > 3]\n",
        "    clean_text = \" \".join(clean_tokens)\n",
        "    # Remove repeated characters\n",
        "    clean_text = re.sub(r'(.)\\1{3,}',r'\\1', clean_text)\n",
        "    if len(clean_text) > 0:\n",
        "      sentence_list.append(clean_text)\n",
        "  return sentence_list"
      ],
      "metadata": {
        "id": "QnlOii79PXSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = text_preprocess(my_text)\n",
        "sentence_list"
      ],
      "metadata": {
        "id": "anIOSkxxQzwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[7]}\", \"r\") as f:\n",
        "  lines = [line.rstrip('\\n') for line in f]\n",
        "  sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "sentence_list"
      ],
      "metadata": {
        "id": "7jG4M79MLz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_match(sentence_list, keyword):\n",
        "  print(\"#\"*10)\n",
        "  print(f\"Matching for : {keyword}\")\n",
        "  print()\n",
        "  ratios = [fuzz.ratio(keyword, sentence) for sentence in sentence_list]\n",
        "  best_match = sentence_list[ratios.index(max(ratios))]\n",
        "  print(f\"Best match: {fuzz.ratio(keyword, best_match)} | {best_match}\")\n",
        "  print(f\"Before Match: {fuzz.ratio(keyword, sentence_list[sentence_list.index(best_match) - 1])} | {sentence_list[sentence_list.index(best_match) - 1]}\")\n",
        "  print(f\"After Match: {fuzz.ratio(keyword, sentence_list[sentence_list.index(best_match) + 1])} | {sentence_list[sentence_list.index(best_match) + 1]}\")\n",
        "  print()\n",
        "\n",
        "  p_ratios = [fuzz.partial_ratio(keyword, sentence) for sentence in sentence_list]\n",
        "  p_best_match = sentence_list[p_ratios.index(max(p_ratios))]\n",
        "  print(f\"Partial Best match: {fuzz.partial_ratio(keyword, p_best_match)} | {p_best_match}\")\n",
        "  print(f\"Partial Before Match: {fuzz.partial_ratio(keyword, sentence_list[sentence_list.index(p_best_match) - 1])} | {sentence_list[sentence_list.index(p_best_match) - 1]}\")\n",
        "  print(f\"Partial After Match: {fuzz.partial_ratio(keyword, sentence_list[sentence_list.index(p_best_match) + 1])} | {sentence_list[sentence_list.index(p_best_match) + 1]}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "yRK1ILJFSZYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_list = [get_keyword(code) for code in clean_icd10_code]\n",
        "keyword_list"
      ],
      "metadata": {
        "id": "lpyTbAmGEkg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[get_best_match(sentence_list, keyword) for keyword in keyword_list]"
      ],
      "metadata": {
        "id": "zpQ1gCbVXNFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_match(sentence_list, keyword_list):\n",
        "  for keyword in keyword_list:\n",
        "    #for sentence in sentence_list:\n",
        "    print(\"#\"*10)\n",
        "    print(f\"Matching for : {keyword}\")\n",
        "    match_list = process.extract(keyword, sentence_list, scorer = fuzz.ratio, limit = 3)\n",
        "    for match_found in match_list:\n",
        "      print(f\"{match_found[0]} | {match_found[1]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "Tj28h6fOPXSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_match(sentence_list, keyword_list)\n",
        "#process.extract(query, choices, scorer = fuzz.partial_ratio, limit = 2)"
      ],
      "metadata": {
        "id": "Lpb7D5IOOk5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list.index(\"Moderate Obstructive Sleep Apnea .\")"
      ],
      "metadata": {
        "id": "7PF541tZWM00",
        "outputId": "5961f3d1-1f3b-4b1b-e55e-05c4f65d34c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sent in enumerate(sentence_list):\n",
        "  print(f\"{idx}>{sent}\")"
      ],
      "metadata": {
        "id": "_EsIKRI9WXpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##All Together"
      ],
      "metadata": {
        "id": "xnOyuVdwJf7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keyword(p_code):\n",
        "  keyword = \"\"\n",
        "   # reverse code if required\n",
        "  code = reverse_code_pattern(p_code)\n",
        "  # get keyword from dataset\n",
        "  keyword_list = list(code_df.loc[code_df[\"Code\"] == code][\"Keyword\"])\n",
        "  if len(keyword_list) > 0:\n",
        "    keyword = keyword_list[0]\n",
        "  return keyword"
      ],
      "metadata": {
        "id": "DmuQsrthJh24"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnosis: Hypertriglyceridemia, sporadic (E78.3)\n",
        "get_keyword(\"E78.3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2-9eyUV5a_1e",
        "outputId": "492ae939-6ea4-41b0-9e53-756f3d40e279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hyperchylomicronemia'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_keyword(\"R03.0\")\n",
        "# Hypertriglyceridemia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wN7PWTqmcsFK",
        "outputId": "15f909d1-661a-45a2-ff99-3cfcd7295e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Elevated blood-pressure reading, w/o diagnosis of htn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_icd10_code = [reverse_code_pattern(code) for code in page_code10_dict[7]]\n",
        "clean_icd10_code"
      ],
      "metadata": {
        "id": "XK9QcFYaUJvi",
        "outputId": "54aca573-1c94-45e8-e5c2-279a348c9e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Z20.822', 'E78.3', 'R05.9']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding for `Hypersomnia, unspecified`:\n",
        "44 > Hypoxemia\n",
        "65 > (central sleep apnea (G47.31) CoHypersomnia, unspecified (G47.10)"
      ],
      "metadata": {
        "id": "n_z8v-H0ra7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[39]}\", \"r\") as f:\n",
        "  lines = [line.rstrip('\\n') for line in f]\n",
        "  sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks"
      ],
      "metadata": {
        "id": "6OgZL7IBOPbf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_tuple(tup):\n",
        "  return(sorted(tup, key = lambda x: x[1], reverse=True)) "
      ],
      "metadata": {
        "id": "LZA1Oh-DVsvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[code for code in page_code10_dict[21]]"
      ],
      "metadata": {
        "id": "ptMIwrFBdfyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[(code, get_keyword(code)) for code in page_code10_dict[15]]"
      ],
      "metadata": {
        "id": "Jl8ONBJOjpqI",
        "outputId": "a21606cc-2d03-4faf-ce0c-01e9131d05b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Z00.00', 'Encntr for general adult medical exam w/o abnormal findings')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_token_match(p_code, num_page):\n",
        "  # Step 1: reverse code pattern\n",
        "  reversed_icd_code = reverse_code_pattern(p_code)\n",
        "  # Step 2: fetch keyword based on code \n",
        "  keyword = get_keyword(reversed_icd_code)\n",
        "  # Step 3: prepare sentence list \n",
        "  with open(f\"{txt_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "  # Step 4: get best token match ratio \n",
        "  match_list = [(sentence, fuzz.token_set_ratio(keyword, sentence)) for sentence in sentence_list if fuzz.token_set_ratio(keyword, sentence) > 40]\n",
        "  return sort_tuple(match_list)"
      ],
      "metadata": {
        "id": "jCgz8N-1ySsS"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_list = [get_best_token_match(code, 38) for code in page_code10_dict[38]]\n",
        "match_list"
      ],
      "metadata": {
        "id": "a8n55LWtWSFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d11a8c-74af-4883-e3f8-69ae8bbfa132"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [('General', 100),\n",
              "  ('General Lymphatics', 56),\n",
              "  ('Routine general medical examination at a health care facility (Z00.00)',\n",
              "   49),\n",
              "  ('Diagnosis: Routine general medical examination at a health care facility (Z00.00)',\n",
              "   42)]]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for code in page_code10_dict[38]:\n",
        "  print(f\"{code}-{get_best_token_match(code, 38)}\")"
      ],
      "metadata": {
        "id": "e3eWcMCedToP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46551785-94b9-4154-b249-cebfc8d5a521"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E78.3-[]\n",
            "Z00.00-[('General', 100), ('General Lymphatics', 56), ('Routine general medical examination at a health care facility (Z00.00)', 49), ('Diagnosis: Routine general medical examination at a health care facility (Z00.00)', 42)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_token_match(p_code, num_page, page_obj, code_coords):\n",
        "  # Step 1: reverse code pattern\n",
        "  reversed_icd_code = reverse_code_pattern(p_code)\n",
        "  # Step 2: fetch keyword based on code \n",
        "  keyword = get_keyword(reversed_icd_code)\n",
        "  # Step 3: prepare sentence list \n",
        "  with open(f\"{txt_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "  # Step 4: get best token match ratio \n",
        "  match_list = [(sentence, fuzz.token_set_ratio(keyword, sentence)) for sentence in sentence_list if fuzz.token_set_ratio(keyword, sentence) > 40]\n",
        "  match_found = (\"NA\", 0)\n",
        "  if len(match_list) > 0:\n",
        "    for match_found in match_list:\n",
        "      highlight_list = page.search_for(match_found[0])\n",
        "      # prepare list for y0 coord value\n",
        "      y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "      if len(y_coords_list) > 0:\n",
        "        if (code_coords-10) <= y_coords_list[1] <= (code_coords + 10):\n",
        "          match_found = match_found\n",
        "  return match_found"
      ],
      "metadata": {
        "id": "Pf1EqfwCTEIv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_coords = 54.60003662109375\n",
        "pdf_file = fitz.open(\"page-36.pdf\")  #Create pdf file object\n",
        "for page_num, page in enumerate(pdf_file):\n",
        "  for code in page_code10_dict[38]:\n",
        "    match_found = get_best_token_match(code, 38, page, code_coords)\n",
        "    print(f\"Code: {code}, {match_found}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwiIeTl0YYNV",
        "outputId": "6db13342-ceae-4d8f-d6cb-d9eabb4f11b4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: E78.3, ('NA', 0)\n",
            "Code: Z00.00, ('Diagnosis: Routine general medical examination at a health care facility (Z00.00)', 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_coords = 54.60003662109375\n",
        "pdf_file = fitz.open(\"page-36.pdf\")  #Create pdf file object\n",
        "for page_num, page in enumerate(pdf_file):\n",
        "  for code in page_code10_dict[38]:\n",
        "    match_found = get_best_token_match(code, 38)\n",
        "    if len(match_found) > 0:\n",
        "      for match_f in match_found:\n",
        "        print(f\"Text: {match_f[0]}\")\n",
        "        highlight_list = page.search_for(match_f[0])\n",
        "        # prepare list for y0 coord value\n",
        "        y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "        if len(y_coords_list) > 0:\n",
        "          #print(y_coords_list[1])\n",
        "          if (code_coords-10) <= y_coords_list[1] <= (code_coords + 10):\n",
        "            print(y_coords_list[1])\n",
        "            print(match_f)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTesKBn2Ru0-",
        "outputId": "b923b86f-840d-48c8-de32-a47cbdd12b70"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: General\n",
            "\n",
            "Text: General Lymphatics\n",
            "\n",
            "Text: Routine general medical examination at a health care facility (Z00.00)\n",
            "54.60003662109375\n",
            "('Routine general medical examination at a health care facility (Z00.00)', 49)\n",
            "\n",
            "Text: Diagnosis: Routine general medical examination at a health care facility (Z00.00)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuzz.token_set_ratio(\"\"\"History & Physical Report \n",
        "5/8/2020: Office Visit \n",
        "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
        "— _ \n",
        "Guevara, DO) \"\"\", \"Encntr for general adult medical exam w/o abnormal findings\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4HhibFxFMhF",
        "outputId": "0fbf4e19-5acb-4bff-e0d7-1fbc9099646c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_list(text_list, num_page):\n",
        "  with open(f\"{text_list[num_page]}\", \"r\") as f:\n",
        "    lines = [line.rstrip('\\n') for line in f]\n",
        "    sentence_list = [\" \".join(line.split()) for line in lines] # Remove extra spaces, tabs, and line breaks\n",
        "  return sentence_list"
      ],
      "metadata": {
        "id": "M2gDTBI9Dm7F"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_sentence_list(txt_list, 38)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fweScRT1D8n1",
        "outputId": "77730fe3-6271-4736-842c-72f9d2235a7a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Musculoskeletal',\n",
              " 'General',\n",
              " 'Movements - Full range of motion in all joints.',\n",
              " 'Lymphatic',\n",
              " 'General Lymphatics',\n",
              " 'Description - No Generalized lymphadenopathy.',\n",
              " 'Assessment & Plan (Lyndsey Pussehl CMA; 5/8/2020 9:45 AM)',\n",
              " 'Routine general medical examination at a health care facility (Z00.00)',\n",
              " 'CBC, Comp, TSH, FLP, PSA',\n",
              " 'Exercise 30-60 min most days of the week. Low fat diet encouraged to maintain good health. Discussed the options for colon and',\n",
              " 'prostate cancer screening. Calcium 1000-1500 mg and Vit D 1000 |U daily recommended.',\n",
              " 'Pt instructed to do aerobic cardiovascular exercise 4-5 times weekly for 30 minutes. Also, educated on healthy low fat, low sugar diet.',\n",
              " 'Pt Education - Patient Education - Exercise to Stay Healthy: Brief Version *: health maintenance',\n",
              " 'FOLLOW-UPIN 1 YEAR',\n",
              " 'Urinalysis (81002)',\n",
              " 'Electrocardiogram (ECG) (93000)',\n",
              " 'Hypertriglyceridemia, sporadic (E78.3)',\n",
              " 'Impression: stopped will restart and check labs',\n",
              " 'Signed electronically by Tristan Guevara, DO (5/8/2020 2:38 PM)',\n",
              " 'Urinalysis (81002) Ordered',\n",
              " 'Diagnosis: Routine general medical examination at a health care facility (Z00.00)',\n",
              " 'Procedures',\n",
              " 'Electrocardiogram (ECG) (93000) Performed: 05/08/2020 (Ordered)',\n",
              " '06/28/2022 12:27 pm l Page 19/144']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_list = get_best_token_match(\"E78.3\", 7)\n",
        "match_list"
      ],
      "metadata": {
        "id": "mVVptrS379Pw",
        "outputId": "fadae444-65b8-492e-fca0-6d2710841f4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_list[0]"
      ],
      "metadata": {
        "id": "zeVA6qkMz-xH",
        "outputId": "11389003-7ae5-48ed-cb52-93a3d15e27cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Diagnosis Fever (R50.9)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_list[1]"
      ],
      "metadata": {
        "id": "J_NcK_vK0I3G",
        "outputId": "3e1836f1-2cad-4c8d-88a2-41f6d11dc50a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(sent):\n",
        "  # tokenize sentence\n",
        "  sent1 = word_tokenize(sent)\n",
        "  # filter stop words\n",
        "  filtered_sent = [w for w in sent1 if not w.lower() in stop_words]\n",
        "  filtered_sent = [w for w in filtered_sent if re.sub(re.compile('\\W'), '', w)]\n",
        "  return filtered_sent"
      ],
      "metadata": {
        "id": "m2rTAnaEFHit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(sent):\n",
        "  # tokenize sentence\n",
        "  sent1 = word_tokenize(sent)\n",
        "  # filter stop words\n",
        "  filtered_sent = [w for w in sent1 if not w.lower() in stop_words]\n",
        "  filtered_sent = [w for w in filtered_sent if re.sub(re.compile('\\W'), '', w)]\n",
        "  clean_tokens = []\n",
        "  for token in filtered_sent:\n",
        "    if token.find(\"-\"):\n",
        "      tokens = token.split(\"-\")\n",
        "      clean_tokens.extend(tokens)\n",
        "    else:\n",
        "      clean_tokens.append(token)\n",
        "  return clean_tokens"
      ],
      "metadata": {
        "id": "mxtSsDGXs_hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnosis Sprain of calcaneofibular (ligament) of right ankle, initial encounter (S93.411A)\n",
        "clean_token = clean_text(\"Overweight (BMI 25.0 - 29.9) (E66.3)\")\n",
        "clean_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTBi9Rx9s6VP",
        "outputId": "9a227a7f-c16f-49b5-9526-fa1bf0c40df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Overweight', 'BMI', '25.0', '29.9', 'E66.3']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_words(sent1, sent2):\n",
        "  clean_token1 = clean_text(sent1)\n",
        "  clean_token2 = clean_text(sent2)\n",
        "  token_set1 = set(clean_token1)\n",
        "  token_set2 = set(clean_token2)\n",
        "\n",
        "  common_word_set = set()\n",
        "  def get_common(token_set1, token_set2):\n",
        "    for w1 in token_set1:\n",
        "      for w2 in token_set2:\n",
        "        if w1.lower() == w2.lower():\n",
        "          common_word_set.add(w1)\n",
        "  get_common(token_set1, token_set2)\n",
        "  get_common(token_set2, token_set1)\n",
        "  \n",
        "  return list(common_word_set)"
      ],
      "metadata": {
        "id": "jI53XqgHjwmS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_common_words(\n",
        "  \"Unspecified abdominal hernia without obstruction or gangrene\",\n",
        "  \"Diagnosis Left lower quadrant pain (R10.32), Non-smoker (Z78.9), Hernia (K46.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of\"\n",
        ")"
      ],
      "metadata": {
        "id": "ieIzT5npsPLo",
        "outputId": "3904f93c-d36b-408d-c25b-b03dc15b0930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hernia', 'hernia']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_words(sent1, sent2):\n",
        "  clean_token1 = clean_text(sent1)\n",
        "  clean_token2 = clean_text(sent2)\n",
        "  token_set1 = set(clean_token1)\n",
        "  token_set2 = set(clean_token2)\n",
        "  for token in token_set1\n",
        "  return list(token_set1 & token_set2)"
      ],
      "metadata": {
        "id": "0xdSCjqrvMg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_tokens = []\n",
        "for token in clean_token:\n",
        "  if token.find(\"-\"):\n",
        "    tokens = token.split(\"-\")\n",
        "    clean_tokens.extend(tokens)\n",
        "  else:\n",
        "    clean_tokens.append(token)\n",
        "clean_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tzQ-KezpAZN",
        "outputId": "a6b017de-caaf-48c9-833b-b2f6a51404a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Elevated', 'blood', 'pressure', 'reading', 'w/o', 'diagnosis', 'htn']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest(array, value):\n",
        "  array = np.asarray(array)\n",
        "  idx = (np.abs(array - value)).argmin()\n",
        "  return array[idx]"
      ],
      "metadata": {
        "id": "1J1L0ncbDYWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.random.random(10)\n",
        "print(array)"
      ],
      "metadata": {
        "id": "coA4aXDBX8qA",
        "outputId": "c63f3377-0d7a-4eac-cf55-78c7a5f896f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.93361323 0.10674056 0.81360362 0.26873547 0.7892294  0.36625687\n",
            " 0.48473053 0.43495106 0.68754387 0.28034082]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(find_nearest(array, value=0.35))"
      ],
      "metadata": {
        "id": "cL-TT9m-YBJB",
        "outputId": "df4917ab-8aba-4b18-d5aa-917e69a62918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3662568679192558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fitz"
      ],
      "metadata": {
        "id": "lUbkfe9gA8uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest(array, value):\n",
        "  array = np.asarray(array)\n",
        "  idx = (np.abs(array - value)).argmin()\n",
        "  return array[idx]"
      ],
      "metadata": {
        "id": "rcCQw9qgYXZa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"page-36.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  #content_of_page = pdf_file.get_page_text(page) #Get page content\n",
        "  match_word = \"Z00.00\" \n",
        "  content_of_page = page_obj.get_text(\"blocks\", sort=False)  #get rect for all words\n",
        "\n",
        "  coords_array = []\n",
        "  y_coords_array = []\n",
        "  for content in content_of_page:\n",
        "    print(content)\n",
        "    if content[4].replace(\"(\", \"\").replace(\")\", \"\") == match_word:\n",
        "      rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "      print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")\n",
        "      coords_array.append(rect_comp)\n",
        "      y_coords_array.append(content[1])\n",
        "      \n",
        "      #coord = fitz.Rect(content[1]).rect\n",
        "      print(rect_comp[1])\n",
        "\n",
        "      highlight = page_obj.add_highlight_annot(rect_comp)\n",
        "      highlight.set_colors(stroke=[0.2, 1, 0.8])\n",
        "      highlight.update()\n",
        "\n",
        "  # find closet y coordinate value\n",
        "  closet_y_coords = find_nearest(y_coords_array, value=74.320068359375)\n",
        "  match_word = \"Comprehensive\" \n",
        "  for content in content_of_page:\n",
        "    # print(word)\n",
        "    if content[4].replace(\"(\", \"\").replace(\")\", \"\") == match_word and (closet_y_coords-20) <= content[1] <= (closet_y_coords + 20):\n",
        "      rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "      print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")\n",
        "      highlight = page_obj.add_highlight_annot(rect_comp)\n",
        "      highlight.set_colors(stroke=[1, 1, 0])\n",
        "      highlight.update()\n",
        "\n",
        "pdf_output_file_name = f\"page_11_output.pdf\"\n",
        "pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)"
      ],
      "metadata": {
        "id": "uK6DLGv7bSar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [74.320068359375, 237.0400390625, 409.8399658203125, 572.5599975585938]\n",
        "curr_value = 74.320068359375 + 20\n",
        "find_nearest(list1, value=curr_value)"
      ],
      "metadata": {
        "id": "XT0I4MwTe6AR",
        "outputId": "499fecb6-9b44-4c56-96ac-7f4ad63f7d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.320068359375"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_value = 74.320068359375 - 20\n",
        "find_nearest(list1, value=curr_value)"
      ],
      "metadata": {
        "id": "BQ1lu6yjsj_z",
        "outputId": "826e7082-f6d2-4f6e-c852-0c514d02a1b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.320068359375"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_coordinate(page_obj, common_words):\n",
        "  word_coords = {}\n",
        "  content_of_page = page_obj.get_text(\"words\", sort=False)  #get rect for all words\n",
        "  for content in content_of_page:\n",
        "    # print(word)\n",
        "    for idx, common_word in enumerate(common_words):\n",
        "      word_coord = {}\n",
        "      curr_word = content[4].replace(\"(\", \"\").replace(\")\", \"\")\n",
        "      if curr_word == match_word:\n",
        "        rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "        word_coord[common_word] = rect_comp\n",
        "        word_coord[\"Line#\"] = content[6]\n",
        "        word_coords[idx] = word_coord\n",
        "  return word_coords"
      ],
      "metadata": {
        "id": "kS5_-wkwkvZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"pdf-files/page-11.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  print(get_word_coordinate(page_obj, [\"general\", \"adult\", \"medical\", \"exam\"]))"
      ],
      "metadata": {
        "id": "2qs3rb4umbmS",
        "outputId": "b42ff6a5-0721-4c17-d1da-c1a22151bcbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: {'general': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}, 1: {'adult': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}, 2: {'medical': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}, 3: {'exam': Rect(242.856689453125, 65.00006103515625, 274.8216857910156, 72.00347900390625), 'Line#': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def highlight_common_words(page_obj, y_coords_array, curr_y_coord, common_word_list):\n",
        "  page_content = page_obj.get_text(\"words\", sort=False)  #get rect for all words\n",
        "\n",
        "  # find closet y coordinate value\n",
        "  closet_y_coords = find_nearest(y_coords_array, value=curr_y_coord)\n",
        "  match_word = \"Comprehensive\" \n",
        "  for content in page_content:\n",
        "    for common_word in common_word_list:\n",
        "      if content[4].replace(\"(\", \"\").replace(\")\", \"\") == common_word and (closet_y_coords-20) <= content[1] <= (closet_y_coords + 20):\n",
        "        rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "        print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")\n",
        "        highlight = page_obj.add_highlight_annot(rect_comp)\n",
        "        highlight.set_colors(stroke=[1, 1, 0])\n",
        "        highlight.update()"
      ],
      "metadata": {
        "id": "7rvJixWFeJlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_common_word_coords_nearby(page_obj, code_coord, keyword, match_sent):\n",
        "  is_closest_coord = False\n",
        "  # get common word list\n",
        "  common_words = get_common_words(keyword, match_sent)\n",
        "  if len(common_words) > 0:\n",
        "    # get common word coordinate\n",
        "    highlight_list = page_obj.search_for(common_words[0])\n",
        "    y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "    # find closet y coordinate value\n",
        "    closet_y_coords = find_nearest(y_coords_list, value=code_coord)\n",
        "    # check, common word coordinate within range of code coordinate\n",
        "    # if (code_coord-10) <= highlight_list[0][1] <= (code_coord + 10):\n",
        "    if (code_coord-10) <= closet_y_coords <= (code_coord + 10):\n",
        "      is_closest_coord = True\n",
        "  return is_closest_coord"
      ],
      "metadata": {
        "id": "plvhK5UAuGpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(sent):\n",
        "  # tokenize sentence\n",
        "  sent1 = word_tokenize(sent)\n",
        "  # filter stop words\n",
        "  filtered_sent = [w for w in sent1 if not w.lower() in stop_words]\n",
        "  filtered_sent = [w for w in filtered_sent if re.sub(re.compile('\\W'), '', w)]\n",
        "  clean_tokens = []\n",
        "  for token in filtered_sent:\n",
        "    if token.find(\"-\"):\n",
        "      tokens = token.split(\"-\")\n",
        "      clean_tokens.extend(tokens)\n",
        "    else:\n",
        "      clean_tokens.append(token)\n",
        "  return clean_tokens"
      ],
      "metadata": {
        "id": "F0TidkGfxR3R"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_words(sent1, sent2):\n",
        "  clean_token1 = clean_text(sent1)\n",
        "  clean_token2 = clean_text(sent2)\n",
        "  token_set1 = set(clean_token1)\n",
        "  token_set2 = set(clean_token2)\n",
        "\n",
        "  common_word_set = set()\n",
        "  def get_common(token_set1, token_set2):\n",
        "    for w1 in token_set1:\n",
        "      for w2 in token_set2:\n",
        "        if w1.lower() == w2.lower():\n",
        "          common_word_set.add(w1)\n",
        "  get_common(token_set1, token_set2)\n",
        "  get_common(token_set2, token_set1)\n",
        "  \n",
        "  return list(common_word_set)"
      ],
      "metadata": {
        "id": "9Nk-LaG6x2Ra"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_words(page_obj, code_coords, keyword):\n",
        "  common_word_list = []\n",
        "  page_content = page_obj.get_text(\"blocks\", sort=False)\n",
        "  for content in page_content:\n",
        "    if (code_coords-10) <= content[1] <= (code_coords + 10):\n",
        "      if len(clean_text(content[4])) > 0:\n",
        "        common_word_list = get_common_words(keyword, content[4])\n",
        "        break\n",
        "  return common_word_list"
      ],
      "metadata": {
        "id": "at9I3XcS2X94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paragraph(page_obj, code_coords):\n",
        "  code_paragraph = None\n",
        "  page_content = page_obj.get_text(\"blocks\", sort=False)\n",
        "  for content in page_content:\n",
        "    if (code_coords-10) <= content[1] <= (code_coords + 10):\n",
        "      if len(clean_text(content[4])) > 0:\n",
        "        code_paragraph = content[4]\n",
        "        break\n",
        "  return code_paragraph"
      ],
      "metadata": {
        "id": "8vvA9I0_5VRa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_coords = 54.60003662109375\n",
        "pdf_file = fitz.open(\"36page.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  paragraph = get_paragraph(page_obj, code_coords)\n",
        "  print(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLrSm5L4h2IK",
        "outputId": "8993ed24-9ffe-44d3-a4c0-2b26b56936d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"36page.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  #content_of_page = pdf_file.get_page_text(page) #Get page content\n",
        "  code_coords = 54.60003662109375\n",
        "  sent1 = \"Encntr for general adult medical exam w/o abnormal findings\"\n",
        "\n",
        "  content_of_page = page_obj.get_text(\"blocks\", sort=False)  #get rect for all words\n",
        "\n",
        "  coords_array = []\n",
        "  y_coords_array = []\n",
        "  for content in content_of_page:\n",
        "    #print(content)\n",
        "    if (code_coords-10) <= content[1] <= (code_coords + 10):\n",
        "      if len(clean_text(content[4])) > 0:\n",
        "        rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "        print(f\"Paragraph: {content[4]}\")\n",
        "        print(f\"Commons: {get_common_words(sent1, content[4])}\")\n",
        "        print(f\"Line #{content[6]}\")\n",
        "        print(f\"Coords: {rect_comp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3vymWQ1q8kl",
        "outputId": "293df9cb-d1fa-465f-90a0-edaaeedc0c85"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paragraph: History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "Commons: ['general', 'medical']\n",
            "Line #0\n",
            "Coords: Rect(28.317279815673828, 46.96002197265625, 575.4642333984375, 72.00390625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"page-36.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  #content_of_page = pdf_file.get_page_text(page) #Get page content\n",
        "  match_word = \"Z00.00\" \n",
        "  content_of_page = page_obj.get_text(\"blocks\", sort=False)  #get rect for all words\n",
        "\n",
        "  coords_array = []\n",
        "  y_coords_array = []\n",
        "  for content in content_of_page:\n",
        "    print(content)\n",
        "    if content[4].replace(\"(\", \"\").replace(\")\", \"\") == match_word:\n",
        "      rect_comp = fitz.Rect(content[0],content[1],content[2],content[3])\n",
        "      print(f\"Line #{content[6]}-{content[4]} > {rect_comp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBXTbFoiwnPU",
        "outputId": "7a788e42-5275-47e2-bbb3-fdf14b2f00bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28.5572566986084, 23.44000244140625, 98.15217590332031, 31.44390869140625, 'Encounter #12 \\n', 0, 0)\n",
            "(28.317279815673828, 46.96002197265625, 575.4642333984375, 72.00390625, 'History & Physical Report \\n5/8/2020: Office Visit \\n- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \\n— _ \\nGuevara, DO) \\n', 1, 0)\n",
            "(34.31671142578125, 81.280029296875, 151.66543579101562, 89.283935546875, 'ocumented. 5/8/2020 9:43 AM \\n', 2, 0)\n",
            "(28.5572566986084, 115.3599853515625, 189.58180236816406, 123.3638916015625, 'Marrie \\nanguage: English / Race: White \\n', 3, 0)\n",
            "(25.917510986328125, 61.96002197265625, 78.73212432861328, 78.96832275390625, '   \\n', 4, 0)\n",
            "(28.5572566986084, 124.0, 45.835601806640625, 132.00390625, 'Male \\n', 6, 0)\n",
            "(28.557254791259766, 144.15997314453125, 557.4664916992188, 168.96392822265625, 'History of Present \\n| Illness as Pussehl CMA; 5/8/2020 2:23 se3 \\nThe patient is a 40 year old male who presents today for a physical. \\nThe patient feels well with no complaints, has good energy level and \\nis \\nsleeping well. Nutrition: balanced diet and supplemental vitamins. Patient exercises weekly. Patient sleeps 7 hours per night. \\n', 7, 0)\n",
            "(28.557239532470703, 189.0, 312.4500427246094, 214.80389404296875, 'Problem List/Past Medical (Lyndsey Pussehl, CMA; 5/8/2020 2:23 PM) \\nElevated blood \\npressure reading \\nwithout diagnosis of hypertension (R03.0) \\nHypertriglyceridemia, sporadic \\n(E78. 3) \\n', 8, 0)\n",
            "(28.31728744506836, 223.84002685546875, 300.93109130859375, 282.9639892578125, 'Health Maintenance History (Lyndsey Pussehl, CMA; 5/8/2020 9:44 AM) \\nLast CPE \\ntOey O8 2020): \\nLast EKG \\n[05/08/2020]: \\nLast Fasting Lipid Panel \\n[02/05/2020]: \\nLast Stress Test \\nNot Done. \\nColonoscopy, Screening \\nNot Dene. \\nLast Flu Vaccine \\n[11/2019]: \\n', 9, 0)\n",
            "(28.077302932739258, 292.0, 263.0145263671875, 308.8839111328125, 'Allergies (Lyndsey Pussehl, CMA, 5/8/2020 2:23 PM) \\nNo Known Drug Allergies \\n[05/02/2012]: No Known Allergies. \\n', 10, 0)\n",
            "(28.317272186279297, 316.44000244140625, 250.53594970703125, 359.52392578125, 'Family History (Lyndsey \\nPussehl, CMA; 5/8/2020 2:23 PM) \\nFather \\nIn stable health, Hypertension, Atrial Fibrillation. \\nBrother \\n1 \\n|n good health. \\nSister \\n1 \\nIn good health. \\nMother \\nInstable health. \\n', 11, 0)\n",
            "(28.077251434326172, 368.55999755859375, 271.1739807128906, 427.9234313964844, 'Social History (Lyndsey Pussehl, CMA; 5/8/2020 2:23 PM) \\nAlcohol Use \\nModerate alcohol use, 1-2 drinks per week or less. \\nLiving Situation \\nMarried, Lives with spouse. \\nCurrent Work/Study Status \\nFull-time. \\nTobacco/Smoke Exposure \\nNone. \\nTobacco Use \\nNon Smoker / Tobacco User. \\nSeat Belt Use \\nAlways uses seat belts. \\n', 12, 0)\n",
            "(28.5572566986084, 436.9599914550781, 293.4917907714844, 462.00390625, 'Medication History (Lyndsey Pussehl, CMA; 5/8/2020 2:23 PM) \\nMedications Reconciled \\nLopid \\n(600MG Tablet, \\n1 Cral BID, Taken starting 11/25/2019) Active. \\n', 13, 0)\n",
            "(28.557193756103516, 471.5199890136719, 577.6244506835938, 633.6038818359375, 'Review of Systems (Tristan Guevara DO; 5/8/2020 2:34 PM) \\nGeneral Not Present- Anorexia, Fatigue, Fever and Night Sweats. \\nSkin Not Present- Dryness, Excessive Sweating, Nail Changes, New Lesions, Rash and Skin Color Changes. \\nHEENT Not Present- Decreased Hearing, Diplopia, Earache, Eye Pain, Frequent Colds, Headache, Hoarseness, Rhinitis, Sinus Pain, Sore Throat, \\nTinnitus, Vertigo, Visual Disturbances, Visual Loss and Voice Changes. \\nNeck Not Present- Neck Pain, Neck Stiffness and Swollen Glands. \\nRespiratory Not Present- Chronic Cough, Cough and Dyspnea. \\nBreast Not Present- Gynecomastia, \\nCardiovascular Not Present- Chest Pain, Edema, Palpitations and Shortness of Breath. \\nGastrointestinal Not Present- Abdominal Pain, Change in Bowel Habits, Diarrhea, Dysphagia, Food Intolerance, Jaundice, Melena, Nausea, \\nRectal Bleeding and Vomiting. \\nMale Genitourinary Not Present- Change in Urinary Stream, Discharge, Dysuria, Frequency, Hematuria, |mpotence, Nocturia, Penile Lesions, \\nTesticular Mass, Testicular Pain and Urethral Discharge. \\nMusculoskeletal Not Present- Decreased Range of Motion, Joint Pain, Muscle Cramps, Muscle Weakness and Myalgia. \\nNeurological Not Present- Decreased Memory, Dizziness, Headaches, \\n| ncoordination, Loss of Consciousness, Faresthesias, Visual Changes and \\nWeakness. \\nPsychiatric Not Present- Depression, \\nI nability to Concentrate and Suicidal |deation. \\nEndocrine Not Present- Hair Changes and Libido Change. \\nHe matology Not Present- Easy Bruising, Enlarged Lymph Nodes and Prolonged Bleeding. \\n', 14, 0)\n",
            "(28.077302932739258, 645.280029296875, 213.81944274902344, 653.283935546875, 'Vitals (Lyndsey Pussehl CMA; 5/8/2020 2:25 PM) \\n', 15, 0)\n",
            "(27.837326049804688, 662.3200073242188, 285.5726013183594, 696.00390625, 'Weight: 174 lb \\nHeight: 70 in \\nBody Surface Area: 1.97 m? \\nBody Mass |ndex: 24.97 kgf m? \\nPulse: 60 (Regular) \\nBP: 118/68(Sitting, Left Arm, Standard) \\n', 16, 0)\n",
            "(24.717626571655273, 734.5999755859375, 587.4635620117188, 755.52392578125, 'Physical Exam (Tristan Guevara DO; 5/8/2020 2:35 PM) \\nGeneral \\n  \\n  \\n', 17, 0)\n",
            "(26.877418518066406, 752.9199829101562, 585.0636596679688, 763.9253540039062, '06/28/2022 12:27 pm \\nl \\nPage 17/144\\n', 18, 0)\n",
            "(0.0, 0.0, 612.0, 792.0, '<image: Indexed(240,DeviceRGB), width: 1224, height: 1584, bpc: 8>', 19, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_token_match(p_code, num_page, page_obj, code_coords, match_threshold):\n",
        "    # Step 1: reverse code pattern\n",
        "    reversed_icd_code = reverse_code_pattern(p_code)\n",
        "    # Step 2: fetch keyword based on code \n",
        "    keyword = get_keyword(reversed_icd_code)\n",
        "    # Step 3: prepare sentence list \n",
        "    sentence_list = get_sentence_list(txt_list, num_page)\n",
        "    # Step 4: get best token match ratio \n",
        "    match_list = [\n",
        "      (sentence, fuzz.token_set_ratio(keyword, sentence)) \n",
        "      for sentence in sentence_list if fuzz.token_set_ratio(keyword, sentence) > match_threshold\n",
        "    ]\n",
        "\n",
        "    match_found_list = []\n",
        "    num_page = num_page + 1\n",
        "    for match_f in match_list:\n",
        "      highlight_list = page_obj.search_for(match_f[0])\n",
        "      # prepare list for y0 coord value\n",
        "      y_coords_list = [highlight[1] for highlight in highlight_list]\n",
        "      #print(y_coords_list)\n",
        "      # find closet y coordinate value\n",
        "      if len(y_coords_list) > 0:\n",
        "        closet_y_coords = find_nearest(y_coords_list, value=code_coords)\n",
        "        # print(f\"Code: {code_coords}, Y: {y_coords}\")\n",
        "        if (closet_y_coords-20) <= code_coords <= (closet_y_coords + 20):\n",
        "          paragraph = get_paragraph(page_obj, code_coords)\n",
        "          print(paragraph)\n",
        "          print(\"#\" * 10)\n",
        "          match_found_list.append(match_f)\n",
        "          #print(f\"Page-{num_page}, Code: ({p_code})-{code_coords}, closet_y_coords:{closet_y_coords} Keyword: {keyword}, Match: {match_f}\")\n",
        "    return match_found_list, sentence_list"
      ],
      "metadata": {
        "id": "mw8Mw9G-fHg5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = fitz.open(\"36page.pdf\")  #Create pdf file object\n",
        "pdf_page_count = pdf_file.page_count   #var to hold page count\n",
        "for page in range(pdf_page_count):  #notice that page starts with index 0\n",
        "  page_obj = pdf_file[page] #Create page object\n",
        "  match_found_list, sentence_list = get_best_token_match(\"Z00.00\", 0, page_obj, 54.60003662109375, 40)\n",
        "  #print(match_found_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L344DZcfmQq",
        "outputId": "70d6a4f7-b7f3-426f-ce3d-9203b8f5832b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n",
            "History & Physical Report \n",
            "5/8/2020: Office Visit \n",
            "- Routine general medical examination at a health care facility (Z00.00), Hypertriglyceridemia, sporadic \n",
            "— _ \n",
            "Guevara, DO) \n",
            "\n",
            "##########\n"
          ]
        }
      ]
    }
  ]
}