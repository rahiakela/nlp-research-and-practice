{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/llms-notebooks/03_abstractive_summarization_with_bart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3RlgaFQcLZ3"
      },
      "source": [
        "# Abstractive Text Summarization with BART\n",
        "\n",
        "**Author:** [Abheesht Sharma](https://github.com/abheesht17/)<br>\n",
        "**Date created:** 2023/07/08<br>\n",
        "**Last modified:** 2023/07/08<br>\n",
        "**Description:** Use KerasNLP to fine-tune BART on the abstractive summarization task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92TMs1Q-cLZ9"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In the era of information overload, it has become crucial to extract the crux\n",
        "of a long document or a conversation and express it in a few sentences. Owing\n",
        "to the fact that summarization has widespread applications in different domains,\n",
        "it has become a key, well-studied NLP task in recent years.\n",
        "\n",
        "[Bidirectional Autoregressive Transformer (BART)](https://arxiv.org/abs/1910.13461)\n",
        "is a Transformer-based encoder-decoder model, often used for\n",
        "sequence-to-sequence tasks like summarization and neural machine translation.\n",
        "BART is pre-trained in a self-supervised fashion on a large text corpus. During\n",
        "pre-training, the text is corrupted and BART is trained to reconstruct the\n",
        "original text (hence called a \"denoising autoencoder\"). Some pre-training tasks\n",
        "include token masking, token deletion, sentence permutation (shuffle sentences\n",
        "and train BART to fix the order), etc.\n",
        "\n",
        "In this example, we will demonstrate how to fine-tune BART on the abstractive\n",
        "summarization task (on conversations!) using KerasNLP, and generate summaries\n",
        "using the fine-tuned model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWcgv8vmcLaB"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Before we start implementing the pipeline, let's install and import all the\n",
        "libraries we need. We'll be using the KerasNLP library. We will also need a\n",
        "couple of utility libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b3ajS2mcLaC"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/keras-team/keras-nlp.git py7zr -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "metadata": {
        "id": "883O2fK3d0AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkiGellecLaF"
      },
      "source": [
        "This examples uses [Keras Core](https://keras.io/keras_core/) to work in any of\n",
        "`\"tensorflow\"`, `\"jax\"` or `\"torch\"`. Support for Keras Core is baked into\n",
        "KerasNLP, simply change the `\"KERAS_BACKEND\"` environment variable to select\n",
        "the backend of your choice. We select the JAX backend below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehOfejiMcLaG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4wYVS5GcLaH"
      },
      "source": [
        "Import all necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ0oCxEbcLaH",
        "outputId": "2de89da2-6af9-450f-88ef-1932035e8e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import py7zr\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import keras_core as keras\n",
        "import keras_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPrZppXpcLaI"
      },
      "source": [
        "Let's also define our hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJtLkUYGcLaJ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "NUM_BATCHES = 600\n",
        "EPOCHS = 1  # Can be set to a higher value for better results\n",
        "MAX_ENCODER_SEQUENCE_LENGTH = 512\n",
        "MAX_DECODER_SEQUENCE_LENGTH = 128\n",
        "MAX_GENERATION_LENGTH = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ecei4hUcLaK"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Let's load the [SAMSum dataset](https://arxiv.org/abs/1911.12237). This dataset\n",
        "contains around 15,000 pairs of conversations/dialogues and summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSbfFnRBcLaM"
      },
      "outputs": [],
      "source": [
        "# Download the dataset.\n",
        "filename = keras.utils.get_file(\n",
        "    \"corpus.7z\",\n",
        "    origin=\"https://huggingface.co/datasets/samsum/resolve/main/data/corpus.7z\",\n",
        ")\n",
        "\n",
        "# Extract the `.7z` file.\n",
        "with py7zr.SevenZipFile(filename, mode=\"r\") as z:\n",
        "    z.extractall(path=\"/root/tensorflow_datasets/downloads/manual\")\n",
        "\n",
        "# Load data using TFDS.\n",
        "samsum_ds = tfds.load(\"samsum\", split=\"train\", as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gquXKvrIcLaN"
      },
      "source": [
        "The dataset has two fields: `dialogue` and `summary`. Let's see a sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce6rIcv3cLaO",
        "outputId": "0dd56252-bd84-4f1b-dece-a81c9b448933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"Carter: Hey Alexis, I just wanted to let you know that I had a really nice time with you tonight. \\r\\nAlexis: Thanks Carter. Yeah, I really enjoyed myself as well. \\r\\nCarter: If you are up for it, I would really like to see you again soon.\\r\\nAlexis: Thanks Carter, I'm flattered. But I have a really busy week coming up.\\r\\nCarter: Yeah, no worries. I totally understand. But if you ever want to go grab dinner again, just let me know. \\r\\nAlexis: Yeah of course. Thanks again for tonight. \\r\\nCarter: Sure. Have a great night. \"\n",
            "b'Alexis and Carter met tonight. Carter would like to meet again, but Alexis is busy.'\n"
          ]
        }
      ],
      "source": [
        "for dialogue, summary in samsum_ds:\n",
        "    print(dialogue.numpy())\n",
        "    print(summary.numpy())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4KJYDQhcLaP"
      },
      "source": [
        "We'll now batch the dataset and retain only a subset of the dataset for the\n",
        "purpose of this example. The dialogue is fed to the encoder, and the\n",
        "corresponding summary serves as input to the decoder. We will, therefore, change\n",
        "the format of the dataset to a dictionary having two keys: `\"encoder_text\"` and\n",
        "`\"decoder_text\"`.This is how `keras_nlp.models.BartSeq2SeqLMPreprocessor`\n",
        "expects the input format to be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT5j3Hz2cLaP"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    samsum_ds.map(\n",
        "        lambda dialogue, summary: {\"encoder_text\": dialogue, \"decoder_text\": summary}\n",
        "    )\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        ")\n",
        "train_ds = train_ds.take(NUM_BATCHES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LxNFKNTcLaQ"
      },
      "source": [
        "## Fine-tune BART\n",
        "\n",
        "Let's load the model and preprocessor first. We use sequence lengths of 512\n",
        "and 128 for the encoder and decoder, respectively, instead of 1024 (which is the\n",
        "default sequence length). This will allow us to run this example quickly\n",
        "on Colab.\n",
        "\n",
        "If you observe carefully, the preprocessor is attached to the model. What this\n",
        "means is that we don't have to worry about preprocessing the text inputs;\n",
        "everything will be done internally. The preprocessor tokenizes the encoder text\n",
        "and the decoder text, adds special tokens and pads them. To generate labels\n",
        "for auto-regressive training, the preprocessor shifts the decoder text one\n",
        "position to the right. This is done because at every timestep, the model is\n",
        "trained to predict the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EqOUTEgcLaW",
        "outputId": "f5aba88f-140a-4a4d-e77d-90afee5a3127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/bart_base_en/v1/model.h5\n",
            "557969120/557969120 [==============================] - 26s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"bart_seq2_seq_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"bart_seq2_seq_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ bart_tokenizer (\u001b[38;5;33mBartTokenizer\u001b[0m)                     │                                              \u001b[38;5;34m50,265\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ bart_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BartTokenizer</span>)                     │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">50,265</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"bart_seq2_seq_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bart_seq2_seq_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ decoder_token_ids (\u001b[38;5;33mInputLayer\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ encoder_padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ encoder_token_ids (\u001b[38;5;33mInputLayer\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ bart_backbone (\u001b[38;5;33mBartBackbone\u001b[0m)                  │ {encoder_sequence_output: (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, │     \u001b[38;5;34m139,417,344\u001b[0m │\n",
              "│                                               │ \u001b[38;5;34m768\u001b[0m), decoder_sequence_output: (\u001b[38;5;45mNone\u001b[0m,  │                 │\n",
              "│                                               │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)}                            │                 │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ token_embedding (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50265\u001b[0m)                    │      \u001b[38;5;34m38,603,520\u001b[0m │\n",
              "└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                  </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ decoder_token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ encoder_padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ encoder_token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ bart_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BartBackbone</span>)                  │ {encoder_sequence_output: (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │     <span style=\"color: #00af00; text-decoration-color: #00af00\">139,417,344</span> │\n",
              "│                                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>), decoder_sequence_output: (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │                 │\n",
              "│                                               │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)}                            │                 │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n",
              "│ token_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50265</span>)                    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">38,603,520</span> │\n",
              "└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,417,344\u001b[0m (531.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,417,344</span> (531.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,417,344\u001b[0m (531.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,417,344</span> (531.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "preprocessor = keras_nlp.models.BartSeq2SeqLMPreprocessor.from_preset(\n",
        "    \"bart_base_en\",\n",
        "    encoder_sequence_length=MAX_ENCODER_SEQUENCE_LENGTH,\n",
        "    decoder_sequence_length=MAX_DECODER_SEQUENCE_LENGTH,\n",
        ")\n",
        "bart_lm = keras_nlp.models.BartSeq2SeqLM.from_preset(\n",
        "    \"bart_base_en\", preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "bart_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PBjvl0DcLaX"
      },
      "source": [
        "Define the optimizer and loss. We use the Adam optimizer with a linearly\n",
        "decaying learning rate. Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPnP5LzxcLaX"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    epsilon=1e-6,\n",
        "    global_clipnorm=1.0,  # Gradient clipping.\n",
        ")\n",
        "# Exclude layernorm and bias terms from weight decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\"])\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"gamma\"])\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"beta\"])\n",
        "\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "bart_lm.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llM0D4uTcLaY"
      },
      "source": [
        "Let's train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgHXqP8ZcLaZ",
        "outputId": "4ee9364c-92a0-4a7b-da1f-16bbf37afd5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600/600 [==============================] - 480s 651ms/step - loss: 0.1898 - accuracy: 0.5586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7da4f04fb130>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "bart_lm.fit(train_ds, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtuECyD8cLaa"
      },
      "source": [
        "## Generate summaries and evaluate them!\n",
        "\n",
        "Now that the model has been trained, let's get to the fun part - actually\n",
        "generating summaries! Let's pick the first 100 samples from the validation set\n",
        "and generate summaries for them. We will use the default decoding strategy, i.e.,\n",
        "greedy search.\n",
        "\n",
        "Generation in KerasNLP is highly optimized. It is backed by the power of XLA.\n",
        "Secondly, key/value tensors in the self-attention layer and cross-attention layer\n",
        "in the decoder are cached to avoid recomputation at every timestep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gzfokOtcLab",
        "outputId": "d14cca7c-9625-4cb8-d268-31827f292758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Time Elapsed: 15.77s\n",
            "Total Time Elapsed: 35.82s\n"
          ]
        }
      ],
      "source": [
        "def generate_text(model, input_text, max_length=200, print_time_taken=False):\n",
        "    start = time.time()\n",
        "    output = model.generate(input_text, max_length=max_length)\n",
        "    end = time.time()\n",
        "    print(f\"Total Time Elapsed: {end - start:.2f}s\")\n",
        "    return output\n",
        "\n",
        "\n",
        "# Load the dataset.\n",
        "val_ds = tfds.load(\"samsum\", split=\"validation\", as_supervised=True)\n",
        "val_ds = val_ds.take(100)\n",
        "\n",
        "dialogues = []\n",
        "ground_truth_summaries = []\n",
        "for dialogue, summary in val_ds:\n",
        "    dialogues.append(dialogue.numpy())\n",
        "    ground_truth_summaries.append(summary.numpy())\n",
        "\n",
        "# Let's make a dummy call - the first call to XLA generally takes a bit longer.\n",
        "_ = generate_text(bart_lm, \"sample text\", max_length=MAX_GENERATION_LENGTH)\n",
        "\n",
        "# Generate summaries.\n",
        "generated_summaries = generate_text(\n",
        "    bart_lm,\n",
        "    val_ds.map(lambda dialogue, _: dialogue).batch(8),\n",
        "    max_length=MAX_GENERATION_LENGTH,\n",
        "    print_time_taken=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9kW8P31cLab"
      },
      "source": [
        "Let's see some of the summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU4ym4uocLac",
        "outputId": "fd328f80-7faa-441f-f4a1-789c9296ba4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue: b'Tony: Is the boss in?\\r\\nClaire: Not yet.\\r\\nTony: Could let me know when he comes, please? \\r\\nClaire: Of course.\\r\\nTony: Thank you.'\n",
            "Generated Summary: Marily, er er er er er er er er er er er er er er er er er er er er erredded into theses arewolves have autely represented by accident\n",
            "Ground Truth Summary: b\"The boss isn't in yet. Claire will let Tony know when he comes.\"\n",
            "=============================\n",
            "Dialogue: b\"James: What shouldl I get her?\\r\\nTim: who?\\r\\nJames: gees Mary my girlfirend\\r\\nTim: Am I really the person you should be asking?\\r\\nJames: oh come on it's her birthday on Sat\\r\\nTim: ask Sandy\\r\\nTim: I honestly am not the right person to ask this\\r\\nJames: ugh fine!\"\n",
            "Generated Summary: There washeshesheshellenic originateshipbuilding project with no more than 1/out partygoers arewolves have issues withstanding withdrawing autefulness of course ofcourse\n",
            "Ground Truth Summary: b\"Mary's birthday is on Saturday. Her boyfriend, James, is looking for gift ideas. Tim suggests that he ask Sandy.\"\n",
            "=============================\n",
            "Dialogue: b\"Mary: So, how's Israel? Have you been on the beach?\\r\\nKate: It's so expensive! But they say, it's Tel Aviv... Tomorrow we are going to Jerusalem.\\r\\nMary: I've heard Israel is expensive, Monica was there on vacation last year, she complained about how pricey it is. Are you going to the Dead Sea before it dies? ahahahha\\r\\nKate: ahahhaha yup, in few days.\"\n",
            "Generated Summary: There are expected reaction toototchchchucking machines arepas have toasty, asymaidaidaids are about aintintintalkalkalkalkalkalkalkalk\n",
            "Ground Truth Summary: b'Mary and Kate discuss how expensive Israel is. Kate is in Tel Aviv now, planning to travel to Jerusalem tomorrow, and to the Dead Sea few days later.'\n",
            "=============================\n",
            "Dialogue: b\"Giny: do we have rice?\\r\\nRiley: nope, it's finished\\r\\nGiny: fuck!\\r\\nGiny: ok, I'll buy\"\n",
            "Generated Summary: The issue withdrawer will probably won't find fault in between 1///outrageousness of course of course, in- Advertisement AdvertisementAfternoon snackage forfefe file\n",
            "Ground Truth Summary: b\"Giny and Riley don't have any rice left. Giny will buy some.\"\n",
            "=============================\n",
            "Dialogue: b\"Jude: i'll be in warsaw at the beginning of december so we could meet again\\r\\nLeon: !!!\\r\\nLeon: at the beginning means...?\\r\\nLeon: cuz I won't be here during the first weekend\\r\\nJude: 10\\r\\nJude: but i think it's a monday, so never mind i guess :D\\r\\nLeon: yeah monday doesn't really work for me :D\\r\\nLeon: :<\\r\\nJude: oh well next time :d\\r\\nLeon: yeah...!\"\n",
            "Generated Summary: Matter will also has been added dimension difference between 8thirtysomething specialties between 2ndedicatedicatedicatedicatedicatedicatedicated onetime anchorage- Advertisement AdvertisementTopics in aint\n",
            "Ground Truth Summary: b'Jude is coming to Warsaw on the 10th of December and wants to see Leon. Leon has no time.'\n",
            "=============================\n"
          ]
        }
      ],
      "source": [
        "for dialogue, generated_summary, ground_truth_summary in zip(\n",
        "    dialogues[:5], generated_summaries[:5], ground_truth_summaries[:5]\n",
        "):\n",
        "    print(\"Dialogue:\", dialogue)\n",
        "    print(\"Generated Summary:\", generated_summary)\n",
        "    print(\"Ground Truth Summary:\", ground_truth_summary)\n",
        "    print(\"=============================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw-80GeQcLac"
      },
      "source": [
        "The generated summaries look awesome! Not bad for a model trained only for 1\n",
        "epoch and on 5000 examples :)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}