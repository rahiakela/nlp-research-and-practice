{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0hK4nU35JVaA",
        "N4dDTs-rJL_h",
        "TycHgKTZJ6a6"
      ],
      "authorship_tag": "ABX9TyNce44sW8oqFx2+UMEe6En1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/text-similarity-works/13_icd_10_code_highlight_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "u6vazPC0Ja4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install -U pdftotext\n",
        "!pip install PyPDF2\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "gdwgVvXuJdz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import difflib\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import fitz\n",
        "import pdftotext\n",
        "from PyPDF2 import PdfFileReader, PdfReader, PdfFileWriter, PdfWriter\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.lang.en import English"
      ],
      "metadata": {
        "id": "gKbd7WsfyYX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p pdf-files\n",
        "!mkdir -p txt-files\n",
        "!mkdir -p output_pdf_files_path"
      ],
      "metadata": {
        "id": "WyuzUOer0FFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p input_pdf_files_path"
      ],
      "metadata": {
        "id": "2dfljcHuOVw3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define directory path after creating it\n",
        "pdf_files_path = \"pdf-files\"\n",
        "txt_files_path = \"txt-files\"\n",
        "ocr_pdf_files_path = \"ocr-pdf-files\"\n",
        "\n",
        "MAX_WORKERS = 20"
      ],
      "metadata": {
        "id": "6RzBfwkuyfv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Functions"
      ],
      "metadata": {
        "id": "0hK4nU35JVaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pdf(pdf_path):\n",
        "  pdf_in_file = open(pdf_path, \"rb\")\n",
        "  pdf = PdfFileReader(pdf_in_file)\n",
        "  pdf_list = []\n",
        "  for page in range(pdf.numPages):\n",
        "      inputpdf = PdfFileReader(pdf_in_file)\n",
        "      output = PdfFileWriter()\n",
        "      output.addPage(inputpdf.getPage(page))\n",
        "      with open(f\"{pdf_files_path}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "          output.write(outputStream)\n",
        "          pdf_list.append(f\"page-{page}.pdf\")\n",
        "  return pdf_list\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_list):\n",
        "    txt_file_list = []\n",
        "    i = 0\n",
        "    for pdf_file in pdf_list:\n",
        "        with open(os.path.join(pdf_files_path, pdf_file), \"rb\") as f:\n",
        "            pdf = pdftotext.PDF(f)\n",
        "\n",
        "        # Read all the text into one string\n",
        "        pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "        # write text into file\n",
        "        with open(f\"{txt_files_path}/page-{str(i)}.txt\", \"a\") as f:\n",
        "            f.write(pdf_text)\n",
        "        txt_file_list.append(f\"{txt_files_path}/page-{str(i)}.txt\")\n",
        "        i += 1\n",
        "    return txt_file_list\n",
        "\n",
        "\n",
        "def get_opt_pattern(icd_10_code):\n",
        "  # create alternate pattern\n",
        "  code_arr = icd_10_code.split(\".\")\n",
        "  if len(code_arr) > 1:\n",
        "    code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "    code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "    code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "    return [code1, code2, code3]\n",
        "  else:\n",
        "    return icd_10_code\n",
        "\n",
        "\n",
        "def isExactMatch(page, term, clip, fullMatch=False, caseSensitive=False):\n",
        "  # clip is an item from page.search_for(term, quads=True)\n",
        "  termLen = len(term)\n",
        "  termBboxLen = max(clip.height, clip.width)\n",
        "  termfontSize = termBboxLen/termLen\n",
        "  f = termfontSize*2\n",
        "\n",
        "  #clip = clip.rect\n",
        "\n",
        "  validate = page.get_text(\"blocks\", clip = clip + (-f, -f, f, f), flags=0)[0][4]\n",
        "  flag = 0\n",
        "  if not caseSensitive:\n",
        "      flag = re.IGNORECASE\n",
        "\n",
        "  matches = len(re.findall(f'{term}', validate, flags=flag)) > 0\n",
        "  if fullMatch:\n",
        "      matches = len(re.findall(f'\\\\b{term}\\\\b', validate))>0\n",
        "  return matches\n",
        "\n",
        "def highlight_icd_code_and_keyword(icd10_code_dict, \n",
        "                                   icd_keywords_dict=None, \n",
        "                                   pdf_file_name=None, \n",
        "                                   cords_file_name=None):\n",
        "  pdf_file = fitz.open(pdf_file_name)\n",
        "  already_highlighted_list = []\n",
        "\n",
        "  def highlight_pdf(highlight, icd10_code, code_type):\n",
        "    cords_list = []\n",
        "    for inst in highlight:\n",
        "      highlight = page.add_highlight_annot(inst)\n",
        "      if code_type == \"ICD-9\":\n",
        "        highlight.set_colors(stroke=[1, 0.5, 0.8]) # light red color (r, g, b)\n",
        "      highlight.update()\n",
        "      highlight = page.search_for(icd10_code)\n",
        "      cords_list.append(highlight)\n",
        "\n",
        "    if cords_list:\n",
        "      num_page = page_num + 1\n",
        "      code_cors_output = f\"Page-{num_page} | {icd10_code}\"\n",
        "      txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "\n",
        "  # create file to write cordinate \n",
        "  txt_output_file_name = open(cords_file_name, \"a\")\n",
        "\n",
        "  for page_num, page in enumerate(pdf_file):\n",
        "    # highlight ICD-10 code\n",
        "    if page_num in icd10_code_dict:\n",
        "      for code in icd10_code_dict[page_num]:\n",
        "        highlight = page.search_for(code)\n",
        "        if len(highlight) == 0:\n",
        "          alternate_code_list = get_opt_pattern(code)\n",
        "          for alt_code in alternate_code_list:\n",
        "            highlight = page.search_for(alt_code)\n",
        "            # highlight pdf for option pattern\n",
        "            highlight_pdf(highlight, alt_code, code_type=\"ICD-10\")\n",
        "        # highlight pdf for main pattern   \n",
        "        highlight_pdf(highlight, code, code_type=\"ICD-10\")\n",
        "\n",
        "    # highlight ICD key phrase\n",
        "    if page_num in icd_keywords_dict:\n",
        "      icd_keyword_dict = icd_keywords_dict[page_num]\n",
        "      for key_phrase, key_phrase_sents in icd_keyword_dict.items():\n",
        "        for key_phrase_sent in key_phrase_sents:\n",
        "          coordinates = page.search_for(key_phrase_sent)\n",
        "          #print(f\"Keyword: {keyword}, Length: {len(coordinates)}\")\n",
        "          cords_list = []\n",
        "          keyword_cors_output = \"\"\n",
        "          for inst in coordinates:\n",
        "            #print(f\"Keyword: {keyword}, inst: {inst}\")\n",
        "            # if isExactMatch(page, key_phrase, inst, fullMatch=True, caseSensitive=True):\n",
        "            highlight = page.add_highlight_annot(inst)\n",
        "            highlight.set_colors(stroke=[1, 0.8, 0.8])\n",
        "            highlight.update()\n",
        "            highlight = page.search_for(key_phrase_sent)\n",
        "            cords_list.append(highlight)\n",
        "            num_page = page_num + 1\n",
        "            keyword_cors_output = f\"Page-{num_page} | {key_phrase} | {key_phrase_sent}\"\n",
        "\n",
        "          if cords_list:\n",
        "            txt_output_file_name.write(\"%s\\n\" % keyword_cors_output)\n",
        "            #print(f\"Page-{page_num}: \", highlight, end='\\n')\n",
        "\n",
        "  txt_output_file_name.close()\n",
        "\n",
        "  pdf_output_file_name = f\"{pdf_file_name.split('.')[0]}_output.pdf\"\n",
        "  pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "  return pdf_output_file_name, cords_file_name\n",
        "\n",
        "\n",
        "def filter_unwanted_code(code_list, page_text):\n",
        "    filtered_code_list = []\n",
        "    # if re.search(\"ICD\", page_text):\n",
        "    # match_list = re.findall(\"(ICD-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "    match_list = re.findall(\"(IC[(A-z)]-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "    # print(\"Match list:\\n\", match_list)\n",
        "    for found_code in match_list:\n",
        "        for code in code_list:\n",
        "            if code in found_code:\n",
        "                filtered_code_list.append(code)\n",
        "    return filtered_code_list\n",
        "\n",
        "\n",
        "def search_icd_code(txt_list, nlp, code_type):\n",
        "    pdf_page_vocab = {}\n",
        "    for txt_file in txt_list:\n",
        "        with open(txt_file, \"r\") as f:\n",
        "            page_txt = f.read()\n",
        "            # filter the page that have line number instead of code\n",
        "            if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "                doc = nlp(page_txt)\n",
        "                code_list = [ent.text for ent in doc.ents]\n",
        "                page_number = 0\n",
        "                if len(code_list) != 0:\n",
        "                    page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "                    pdf_page_vocab[page_number] = code_list\n",
        "                    # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "\n",
        "                # filter the page that dont have ICD string into it\n",
        "                if code_type == \"ICD-9\":\n",
        "                    filtered_code_list = filter_unwanted_code(code_list, page_txt)\n",
        "                    pdf_page_vocab[page_number] = filtered_code_list\n",
        "                    # print(f\"Page[{txt_file.split('/')[1]}]: {filtered_code_list}\")\n",
        "\n",
        "    return pdf_page_vocab\n",
        "\n",
        "\n",
        "def get_json_array_list(text_path):\n",
        "  json_arr = None\n",
        "  try:\n",
        "    #print(f\"Running '{text_path}'\")\n",
        "    json_arr = call(text_path)\n",
        "    #print(f\"Got json for '{text_path}'\")\n",
        "  except Exception as err:\n",
        "    print(f\"Error for file[{text_path}] is:\\n{err}\")\n",
        "  return json_arr\n",
        "\n",
        "\n",
        "def get_wrong_keyword_dict2(text_path_list):\n",
        "  wrong_keyword_dict = {}\n",
        "  json_arr_list = list(map(get_json_array_list, text_path_list))\n",
        "  wrong_keyword_dict = {\n",
        "    idx: set([list(element.values())[0] for element in json_arr if json_arr is not None]) \n",
        "    for idx, json_arr in enumerate(json_arr_list)\n",
        "  }\n",
        "  return wrong_keyword_dict\n",
        "\n",
        "\n",
        "def get_wrong_keyword_dict(text_files_list, with_thread=False, with_process=False):\n",
        "\n",
        "    def get_sorted_dict(json_arr_list):\n",
        "      wrong_keyword_dict = {\n",
        "        idx: set([list(element.values())[0] for element in json_arr if json_arr]) \n",
        "        for idx, json_arr in enumerate(json_arr_list)\n",
        "      }\n",
        "      return dict(sorted(wrong_keyword_dict.items(), key=lambda item: item[0]))\n",
        "\n",
        "    if with_thread:\n",
        "        # take care so that unnecessary thread should not be created\n",
        "        workers = min(MAX_WORKERS, len(text_files_list))\n",
        "        with futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "            json_arr_list = executor.map(get_json_array_list, text_files_list)\n",
        "        return get_sorted_dict(json_arr_list)\n",
        "    if with_process:\n",
        "        with futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "            json_arr_list = executor.map(get_json_array_list, text_files_list)\n",
        "        return get_sorted_dict(json_arr_list)\n",
        "    else:\n",
        "      json_arr_list = list(map(get_json_array_list, text_files_list))\n",
        "      wrong_keyword_dict = {\n",
        "        idx: set([list(element.values())[0] for element in json_arr if json_arr is not None]) \n",
        "        for idx, json_arr in enumerate(json_arr_list)\n",
        "      }\n",
        "      return wrong_keyword_dict\n",
        "\n",
        "\n",
        "def extract_sentence(wrong_kerword_list, sample_text_list):\n",
        "  match_keyword_dict = {}\n",
        "  # create file to write cordinate \n",
        "  #icd_keyword_found_filename = open(\"icd_keyword_found.txt\", \"w\")\n",
        "  #icd_keyword_found_filename2 = open(\"icd_keyword_match.txt\", \"w\")\n",
        "  for key, kerword_set in wrong_kerword_list.items():\n",
        "    match_dicts = {}\n",
        "    for key_phrase in kerword_set:\n",
        "      #print(key, key_phrase)\n",
        "      keyword_found_output2 = f\"Page-{key} | {key_phrase} |\\n\"\n",
        "      #icd_keyword_found_filename2.write(\"%s\\n\" % keyword_found_output2)\n",
        "\n",
        "      with open(sample_text_list[key], \"r\") as f:\n",
        "        file_txt = f.read()\n",
        "      # match_list = re.findall(f\"([^\\n]*?(?i){key_phrase}[^.]*\\.)\", file_txt)\n",
        "      match_list = re.findall(f\"([^\\n]*{key_phrase}[^\\n]*\\n)\", file_txt)\n",
        "      if match_list:\n",
        "        match_dicts[key_phrase] = [match.replace(\"\\n\", \"\") for match in match_list]\n",
        "    match_keyword_dict[key] = match_dicts\n",
        "    #keyword_found_output = f\"Page-{key} | {key_phrase} | {match_dicts}|\\n\"\n",
        "    #icd_keyword_found_filename.write(\"%s\\n\" % keyword_found_output)\n",
        "\n",
        "  #icd_keyword_found_filename.close()\n",
        "  #icd_keyword_found_filename2.close()\n",
        "  return match_keyword_dict\n",
        "\n",
        "\n",
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "qB-XpoweygN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Classes"
      ],
      "metadata": {
        "id": "9oNqjgIsRpNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Highlighter:\n",
        "  def __init__(self):\n",
        "      # loading and updating patterns for ICD-10 code\n",
        "      self.nlp_code10 = English()\n",
        "      self.nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"icd10_code_patterns-v3.jsonl\")\n",
        "\n",
        "      # define required directory path\n",
        "      self.PDF_FILES_PATH = \"pdf-files\"\n",
        "      self.TXT_FILES_PATH = \"txt-files\"\n",
        "      self.OUTPUT_FILES_PATH = \"output_pdf_files_path\"\n",
        "      self.create_directory(self.PDF_FILES_PATH)\n",
        "      self.create_directory(self.TXT_FILES_PATH)\n",
        "\n",
        "  def create_directory(self, dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "      os.makedirs(dir_name)\n",
        "\n",
        "  def split_pdf(self, pdf_path):\n",
        "      pdf_in_file = open(pdf_path, \"rb\")\n",
        "      pdf = PdfReader(pdf_in_file)\n",
        "      pdf_list = []\n",
        "      for page in range(len(pdf.pages)):\n",
        "          input_pdf = PdfReader(pdf_in_file)\n",
        "          output = PdfWriter()\n",
        "          #output.addPage(input_pdf.getPage(page))\n",
        "          output.add_page(input_pdf.pages[page])\n",
        "          with open(f\"{self.PDF_FILES_PATH}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "              output.write(outputStream)\n",
        "              pdf_list.append(f\"page-{page}.pdf\")\n",
        "      return pdf_list\n",
        "\n",
        "  def extract_text_from_pdf(self, pdf_list):\n",
        "      txt_file_list = []\n",
        "      i = 0\n",
        "      for pdf_file in pdf_list:\n",
        "          with open(os.path.join(self.PDF_FILES_PATH, pdf_file), \"rb\") as f:\n",
        "              pdf = pdftotext.PDF(f)\n",
        "\n",
        "          # Read all the text into one string\n",
        "          pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "          # write text into file\n",
        "          with open(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\", \"a\") as f:\n",
        "              f.write(pdf_text)\n",
        "          txt_file_list.append(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\")\n",
        "          i += 1\n",
        "      return txt_file_list\n",
        "\n",
        "  def highlight_icd_code(self, icd10_code_dict, pdf_file_name=None, cords_file_name=None):\n",
        "      pdf_file = fitz.open(pdf_file_name)\n",
        "      # create file to write coordinate\n",
        "      txt_output_file_name = open(cords_file_name, \"a\")\n",
        "\n",
        "      def highlight_pdf(highlight, icd10_code):\n",
        "          cords_list = []\n",
        "          for inst in highlight:\n",
        "              highlight = page.add_highlight_annot(inst)\n",
        "              highlight.update()\n",
        "              highlight = page.search_for(icd10_code)\n",
        "              cords_list.append(highlight)\n",
        "\n",
        "          if cords_list:\n",
        "              num_page = page_num + 1\n",
        "              code_cors_output = f\"Page-{num_page} | {icd10_code}\"\n",
        "              txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "\n",
        "      for page_num, page in enumerate(pdf_file):\n",
        "          # highlight ICD-10 code\n",
        "          if page_num in icd10_code_dict:\n",
        "              for code in icd10_code_dict[page_num]:\n",
        "                  highlight = page.search_for(code)\n",
        "                  if len(highlight) == 0:\n",
        "                      alternate_code_list = self.get_opt_pattern(code)\n",
        "                      for alt_code in alternate_code_list:\n",
        "                          highlight = page.search_for(alt_code)\n",
        "                          # highlight pdf for option pattern\n",
        "                          highlight_pdf(highlight, alt_code)\n",
        "                  # highlight pdf for main pattern\n",
        "                  highlight_pdf(highlight, code)\n",
        "\n",
        "      txt_output_file_name.close()\n",
        "\n",
        "      pdf_output_file_name = f\"{self.OUTPUT_FILES_PATH}/{pdf_file_name.split('/')[1].split('.')[0]}_output.pdf\"\n",
        "      pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "      return pdf_output_file_name, cords_file_name\n",
        "\n",
        "  def get_opt_pattern(self, icd_10_code):\n",
        "      # create alternate pattern\n",
        "      code_arr = icd_10_code.split(\".\")\n",
        "      if len(code_arr) > 1:\n",
        "          code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "          code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "          code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "          return [code1, code2, code3]\n",
        "      else:\n",
        "          return icd_10_code\n",
        "\n",
        "  def search_icd_code(self, txt_list):\n",
        "      pdf_page_vocab = {}\n",
        "      for txt_file in txt_list:\n",
        "          with open(txt_file, \"r\") as f:\n",
        "              page_txt = f.read()\n",
        "              # filter the page that have line number instead of code\n",
        "              if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "                  doc = self.nlp_code10(page_txt)\n",
        "                  code_list = [ent.text for ent in doc.ents]\n",
        "                  if len(code_list) != 0:\n",
        "                      page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "                      pdf_page_vocab[page_number] = code_list\n",
        "                      # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "      return pdf_page_vocab"
      ],
      "metadata": {
        "id": "W0oEZzP_RrlP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Single Searching & Highlighting"
      ],
      "metadata": {
        "id": "N4dDTs-rJL_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v3.jsonl\")\n",
        "\n",
        "# loading and updating patterns for ICD-9 code\n",
        "#nlp_code9 = English()\n",
        "#nlp_code9.add_pipe(\"entity_ruler\").from_disk(\"./icd9_code_patterns-v1.jsonl\")"
      ],
      "metadata": {
        "id": "y8UcOwHpJnpd",
        "outputId": "a077a0ab-27f6-4935-addc-cf41f6d89293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x7f0ddf861c40>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "5i_7mtx2e56B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: spliting pdf file\n",
        "pdf_file_name = \"APS386.pdf\"\n",
        "pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "# Step-2: Extracting text from pdf\n",
        "txt_list = extract_text_from_pdf(pdf_list)"
      ],
      "metadata": {
        "id": "qw22evt02aRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Searching ICD-10 code\n",
        "page_code10_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")"
      ],
      "metadata": {
        "id": "flLgpUfg2ghi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Step-4: Get coloset match of ICD-10 keyword\n",
        "wrong_keyword_dict = get_wrong_keyword_dict(txt_list)\n",
        "# wrong_keyword_dict = get_wrong_keyword_dict(txt_list, with_thread=True)\n",
        "# wrong_keyword_dict = get_wrong_keyword_dict(txt_list, with_process=False)\n",
        "# wrong_keyword_dict = get_wrong_keyword_dict2(txt_list)"
      ],
      "metadata": {
        "id": "f7C3J8jbnzPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953f079e-37e0-437a-b6a9-7a609e3a253f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5min 35s, sys: 13.5 s, total: 5min 49s\n",
            "Wall time: 5min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict[21]"
      ],
      "metadata": {
        "id": "X9swFK9Jsizl",
        "outputId": "2a22c1cf-efaf-49d1-f372-396f26644e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Acute maxillary sinusitis',\n",
              " 'Back Pain',\n",
              " 'Body mass index [BMI]',\n",
              " 'Contact with and (suspected) exposure to COVID-19',\n",
              " 'Cough',\n",
              " 'Dietary counseling and surveillance',\n",
              " 'Elevated blood-pressure reading, without diagnosis of hypertension',\n",
              " 'Hernia',\n",
              " 'Hypertension',\n",
              " 'Hypertriglyceridemia',\n",
              " 'Left lower quadrant pain',\n",
              " 'Low back pain',\n",
              " 'Overweight',\n",
              " 'Prostate Cancer',\n",
              " 'Sciatica',\n",
              " 'Sprain of calcaneofibular ligament',\n",
              " 'Sprain of calcaneofibular ligament of right ankle',\n",
              " 'Sprain of calcaneofibular ligament of right ankle, initial encounter',\n",
              " 'Thrombocytopenia',\n",
              " 'sprain'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Step-5: Extract sentence of ICD-10 keyword\n",
        "icd_keywords_dict = extract_sentence(wrong_keyword_dict, txt_list)"
      ],
      "metadata": {
        "id": "5OaO5U4PnR6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0937f2-70ce-424f-c65e-5b188e5449c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 550 ms, sys: 20.9 ms, total: 571 ms\n",
            "Wall time: 577 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "icd_keywords_dict[21]"
      ],
      "metadata": {
        "id": "DGnsLSzCmh3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-6: Highlighting ICD-10 code and keyword into pdf\n",
        "pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(page_code10_dict, \n",
        "                                                                  icd_keywords_dict=icd_keywords_dict,\n",
        "                                                                  pdf_file_name=\"APS386.pdf\", \n",
        "                                                                  cords_file_name=\"APS386_cords.txt\")\n",
        "print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")"
      ],
      "metadata": {
        "id": "IsgIgN1hB528",
        "outputId": "208aec6b-8156-47cb-b27d-f03cc56362fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File[APS386_output.pdf] is saved after highlighting ICD-10 code and keyword\n",
            "Highlighted coordinates are saved into [APS386_cords.txt] file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Searching & Highlighting"
      ],
      "metadata": {
        "id": "TycHgKTZJ6a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v3.jsonl\")"
      ],
      "metadata": {
        "id": "TWMPYgIJJ8xG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd53111e-94f0-4660-f5f0-6d6f00151c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x7fd29c418640>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for pdf_file in os.listdir(ocr_pdf_files_path):\n",
        "  pdf_file_name = f\"{ocr_pdf_files_path}/{pdf_file}\"\n",
        "  cords_file_name = f\"{pdf_file_name.split('.')[0]}_cords.txt\"\n",
        "\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = extract_text_from_pdf(pdf_list)\n",
        "\n",
        "  # Step-3: Searching ICD-10 code\n",
        "  icd10_code_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")\n",
        "\n",
        "  # Step-4: Get coloset match of ICD-10 keyword\n",
        "  wrong_keyword_dict = get_wrong_keyword_dict(txt_list)\n",
        "\n",
        "  # Step-5: Extract sentence of ICD-10 keyword\n",
        "  icd_keywords_dict = extract_sentence(wrong_keyword_dict, txt_list)\n",
        "\n",
        "  # Step-6: Highlighting ICD-10 code and keyword into pdf\n",
        "  pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(icd10_code_dict, \n",
        "                                                                    icd_keywords_dict=icd_keywords_dict,\n",
        "                                                                    pdf_file_name=pdf_file_name, \n",
        "                                                                    cords_file_name=cords_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "id": "AA7AygDDy06C",
        "outputId": "93cea076-04d5-4189-d0da-ea59d008a81a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File[ocr-pdf-files/APS_38600000R_final_output.pdf] is saved after highlighting ICD-10 code and keyword\n",
            "Highlighted coordinates are saved into [ocr-pdf-files/APS_38600000R_final_cords.txt] file.\n",
            "CPU times: user 5min 46s, sys: 3.74 s, total: 5min 50s\n",
            "Wall time: 5min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ocr-pdf-files ocr-pdf-files2"
      ],
      "metadata": {
        "id": "mdUVrpzCOsOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ocr-pdf-files\n",
        "!mkdir -p ocr-pdf-files"
      ],
      "metadata": {
        "id": "kbTuptfC1xrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ocr-pdf-files2/*.pdf ocr-pdf-files/"
      ],
      "metadata": {
        "id": "Cfh3F3DmOzvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ocr-pdf-files2"
      ],
      "metadata": {
        "id": "gTuKanyTTUjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"ocr-pdf-files/*.txt\")\n",
        "purge(\"ocr-pdf-files/*_output.pdf\")\n",
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "l06JNkJQ1yGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip ocr-pdf-files/*_cords.txt ocr-pdf-files/*_output.pdf"
      ],
      "metadata": {
        "id": "rZI3lkYT1zxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Class-based Searching & Highlighting"
      ],
      "metadata": {
        "id": "k14TfaJgX-y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"input_pdf_files_path/Redacted_Sample.pdf\".split(\"/\")[1].split(\".\")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QIHrfvqMdYFr",
        "outputId": "ca59350b-012c-462a-99c1-067cef135d6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Redacted_Sample'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def create_directory(dir_name):\n",
        "  if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)\n",
        "    \n",
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # Step-0: Define prerequisite instance\n",
        "  INPUT_PDF_FILES_PATH = \"input_pdf_files_path\"\n",
        "  create_directory(\"output_pdf_files_path\")\n",
        "\n",
        "  highlighter = Highlighter()\n",
        "\n",
        "  for pdf_file in os.listdir(INPUT_PDF_FILES_PATH):\n",
        "    pdf_file_name = f\"{INPUT_PDF_FILES_PATH}/{pdf_file}\"\n",
        "    cords_file_name = f\"output_pdf_files_path/{pdf_file_name.split('/')[1].split('.')[0]}_cords.txt\"\n",
        "\n",
        "    # Step-1: splitting pdf file\n",
        "    pdf_list = highlighter.split_pdf(pdf_file_name)\n",
        "\n",
        "    # Step-2: Extracting text from pdf\n",
        "    txt_list = highlighter.extract_text_from_pdf(pdf_list)\n",
        "\n",
        "    # Step-3: Searching ICD-10 cod\n",
        "    icd10_code_dict = highlighter.search_icd_code(txt_list)\n",
        "\n",
        "    # Step-4: Highlighting ICD-10 code into pdf\n",
        "    pdf_output_file, txt_output_file = highlighter.highlight_icd_code(icd10_code_dict,\n",
        "                                                                      pdf_file_name=pdf_file_name,\n",
        "                                                                      cords_file_name=cords_file_name)\n",
        "    print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code\")\n",
        "    print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "    # remove all pdf and text files\n",
        "    purge(\"pdf-files/*.pdf\")\n",
        "    purge(\"txt-files/*.txt\")\n",
        "    pdf_list = []\n",
        "    txt_list = []"
      ],
      "metadata": {
        "id": "8Jebcbz4YChR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315525ab-a7cc-49c1-cf2a-b6fd3191bed9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File[output_pdf_files_path/Redacted_Sample_output.pdf] is saved after highlighting ICD-10 code\n",
            "Highlighted coordinates are saved into [output_pdf_files_path/Redacted_Sample_cords.txt] file.\n",
            "CPU times: user 1min 6s, sys: 9.57 s, total: 1min 16s\n",
            "Wall time: 1min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input_pdf_files_path\n",
        "!mkdir -p input_pdf_files_path"
      ],
      "metadata": {
        "id": "gsxg17J0kLdT"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}