{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQSK4VWxSj2JxqGZA4ZEm3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/text-similarity-works/13_code_keyword_sentence_extraction_and_highlight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "u6vazPC0Ja4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install -U pdftotext\n",
        "!pip install PyPDF2\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "gdwgVvXuJdz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import difflib\n",
        "import pickle\n",
        "\n",
        "import fitz\n",
        "import pdftotext\n",
        "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.lang.en import English\n",
        "\n",
        "from keyword_extractor import *\n",
        "from concurrent import futures"
      ],
      "metadata": {
        "id": "gKbd7WsfyYX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "b58uBfgEaBMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "EXXUuXUwaJvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p pdf-files\n",
        "!mkdir -p txt-files\n",
        "!mkdir -p ocr-pdf-files"
      ],
      "metadata": {
        "id": "WyuzUOer0FFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define directory path after creating it\n",
        "pdf_files_path = \"pdf-files\"\n",
        "txt_files_path = \"txt-files\"\n",
        "ocr_pdf_files_path = \"ocr-pdf-files\"\n",
        "\n",
        "MAX_WORKERS = 20"
      ],
      "metadata": {
        "id": "6RzBfwkuyfv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Functions"
      ],
      "metadata": {
        "id": "0hK4nU35JVaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pdf(pdf_path):\n",
        "  pdf_in_file = open(pdf_path, \"rb\")\n",
        "  pdf = PdfFileReader(pdf_in_file)\n",
        "  pdf_list = []\n",
        "  for page in range(pdf.numPages):\n",
        "      inputpdf = PdfFileReader(pdf_in_file)\n",
        "      output = PdfFileWriter()\n",
        "      output.addPage(inputpdf.getPage(page))\n",
        "      with open(f\"{pdf_files_path}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "          output.write(outputStream)\n",
        "          pdf_list.append(f\"page-{page}.pdf\")\n",
        "  return pdf_list\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_list):\n",
        "    txt_file_list = []\n",
        "    i = 0\n",
        "    for pdf_file in pdf_list:\n",
        "        with open(os.path.join(pdf_files_path, pdf_file), \"rb\") as f:\n",
        "            pdf = pdftotext.PDF(f)\n",
        "\n",
        "        # Read all the text into one string\n",
        "        pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "        # write text into file\n",
        "        with open(f\"{txt_files_path}/page-{str(i)}.txt\", \"a\") as f:\n",
        "            f.write(pdf_text)\n",
        "        txt_file_list.append(f\"{txt_files_path}/page-{str(i)}.txt\")\n",
        "        i += 1\n",
        "    return txt_file_list\n",
        "\n",
        "\n",
        "def get_opt_pattern(icd_10_code):\n",
        "  # create alternate pattern\n",
        "  code_arr = icd_10_code.split(\".\")\n",
        "  if len(code_arr) > 1:\n",
        "    code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "    code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "    code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "    return [code1, code2, code3]\n",
        "  else:\n",
        "    return icd_10_code\n",
        "\n",
        "\n",
        "def isExactMatch(page, term, clip, fullMatch=False, caseSensitive=False):\n",
        "  # clip is an item from page.search_for(term, quads=True)\n",
        "  termLen = len(term)\n",
        "  termBboxLen = max(clip.height, clip.width)\n",
        "  termfontSize = termBboxLen/termLen\n",
        "  f = termfontSize*2\n",
        "\n",
        "  #clip = clip.rect\n",
        "\n",
        "  validate = page.get_text(\"blocks\", clip = clip + (-f, -f, f, f), flags=0)[0][4]\n",
        "  flag = 0\n",
        "  if not caseSensitive:\n",
        "      flag = re.IGNORECASE\n",
        "\n",
        "  matches = len(re.findall(f'{term}', validate, flags=flag)) > 0\n",
        "  if fullMatch:\n",
        "      matches = len(re.findall(f'\\\\b{term}\\\\b', validate))>0\n",
        "  return matches\n",
        "\n",
        "def highlight_icd_code_and_keyword(icd10_code_dict, \n",
        "                                   icd9_code_dict=None, \n",
        "                                   icd_keywords_dict=None, \n",
        "                                   pdf_file_name=None, \n",
        "                                   cords_file_name=None):\n",
        "  pdf_file = fitz.open(pdf_file_name)\n",
        "\n",
        "  def highlight_pdf(highlight, icd10_code, code_type):\n",
        "    cords_list = []\n",
        "    for inst in highlight:\n",
        "      highlight = page.add_highlight_annot(inst)\n",
        "      if code_type == \"ICD-9\":\n",
        "        highlight.set_colors(stroke=[1, 0.5, 0.8]) # light red color (r, g, b)\n",
        "      highlight.update()\n",
        "      highlight = page.search_for(icd10_code)\n",
        "      cords_list.append(highlight)\n",
        "\n",
        "    if cords_list:\n",
        "      code_cors_output = f\"Page-{page_num} | {icd10_code} | {cords_list}\"\n",
        "      txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "\n",
        "  # create file to write cordinate \n",
        "  txt_output_file_name = open(cords_file_name, \"a\")\n",
        "\n",
        "  for page_num, page in enumerate(pdf_file):\n",
        "\n",
        "    # highlight ICD-10 code\n",
        "    if page_num in icd10_code_dict:\n",
        "      for code in icd10_code_dict[page_num]:\n",
        "        highlight = page.search_for(code)\n",
        "        if len(highlight) == 0:\n",
        "          alternate_code_list = get_opt_pattern(code)\n",
        "          for alt_code in alternate_code_list:\n",
        "            highlight = page.search_for(alt_code)\n",
        "            # highlight pdf for option pattern\n",
        "            highlight_pdf(highlight, alt_code, code_type=\"ICD-10\")\n",
        "        # highlight pdf for main pattern   \n",
        "        highlight_pdf(highlight, code, code_type=\"ICD-10\")\n",
        "\n",
        "    # highlight ICD-9 code\n",
        "    if icd9_code_dict is not None:\n",
        "      if page_num in icd9_code_dict:\n",
        "        for code in icd9_code_dict[page_num]:\n",
        "          highlight = page.search_for(code)\n",
        "          if len(highlight) == 0:\n",
        "            alternate_code_list = get_opt_pattern(code)\n",
        "            for alt_code in alternate_code_list:\n",
        "              highlight = page.search_for(alt_code)\n",
        "              # highlight pdf for option pattern\n",
        "              highlight_pdf(highlight, alt_code, code_type=\"ICD-9\")\n",
        "          # highlight pdf for main pattern   \n",
        "          highlight_pdf(highlight, code, code_type=\"ICD-9\")\n",
        "\n",
        "  # highlight ICD key phrase\n",
        "  for key_phrase, key_phrase_sents in icd_keywords_dict.items():\n",
        "    cords_list = []\n",
        "    # search key phrase for every page\n",
        "    for page in pdf_file:\n",
        "      coordinates = page.search_for(key_phrase_sents[0])\n",
        "      #print(f\"Keyword: {keyword}, Length: {len(coordinates)}\")\n",
        "      \n",
        "      for inst in coordinates:\n",
        "        #print(f\"Keyword: {keyword}, inst: {inst}\")\n",
        "        if isExactMatch(page, key_phrase, inst, fullMatch=True, caseSensitive=True):\n",
        "          highlight = page.add_highlight_annot(inst)\n",
        "          highlight.set_colors(stroke=[1, 0.8, 0.8])\n",
        "          highlight.update()\n",
        "          highlight = page.search_for(key_phrase_sents[0])\n",
        "          cords_list.append(highlight)\n",
        "\n",
        "    if cords_list:\n",
        "      keyword_cors_output = f\"Page-{page_num} | {key_phrase} | {key_phrase_sents[0]} | {cords_list}\"\n",
        "      txt_output_file_name.write(\"%s\\n\" % keyword_cors_output)\n",
        "      #print(f\"Page-{page_num}: \", highlight, end='\\n')\n",
        "\n",
        "  txt_output_file_name.close()\n",
        "\n",
        "  pdf_output_file_name = f\"{pdf_file_name.split('.')[0]}_output.pdf\"\n",
        "  pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "  return pdf_output_file_name, cords_file_name\n",
        "\n",
        "def highlight_icd_code_and_keyword2(icd10_code_dict, icd9_code_dict, page_keyword_dict=None, pdf_file_name=None, cords_file_name=None):\n",
        "  pdf_file = fitz.open(pdf_file_name)\n",
        "\n",
        "  def highlight_pdf(highlight, icd10_code, code_type):\n",
        "    cords_list = []\n",
        "    for inst in highlight:\n",
        "      highlight = page.add_highlight_annot(inst)\n",
        "      if code_type == \"ICD-9\":\n",
        "        highlight.set_colors(stroke=[1, 0.5, 0.8]) # light red color (r, g, b)\n",
        "      highlight.update()\n",
        "      highlight = page.search_for(icd10_code)\n",
        "      cords_list.append(highlight)\n",
        "\n",
        "    if cords_list:\n",
        "      code_cors_output = f\"Page-{page_num}: {icd10_code} : {cords_list}\"\n",
        "      txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "\n",
        "  # create file to write cordinate \n",
        "  txt_output_file_name = open(cords_file_name, \"a\")\n",
        "\n",
        "  for page_num, page in enumerate(pdf_file):\n",
        "\n",
        "    # highlight ICD-10 code\n",
        "    if page_num in icd10_code_dict:\n",
        "      for code in icd10_code_dict[page_num]:\n",
        "        highlight = page.search_for(code)\n",
        "        if len(highlight) == 0:\n",
        "          alternate_code_list = get_opt_pattern(code)\n",
        "          for alt_code in alternate_code_list:\n",
        "            highlight = page.search_for(alt_code)\n",
        "            # highlight pdf for option pattern\n",
        "            highlight_pdf(highlight, alt_code, code_type=\"ICD-10\")\n",
        "        # highlight pdf for main pattern   \n",
        "        highlight_pdf(highlight, code, code_type=\"ICD-10\")\n",
        "\n",
        "    # highlight ICD-9 code\n",
        "    if icd9_code_dict is not None:\n",
        "      if page_num in icd9_code_dict:\n",
        "        for code in icd9_code_dict[page_num]:\n",
        "          highlight = page.search_for(code)\n",
        "          if len(highlight) == 0:\n",
        "            alternate_code_list = get_opt_pattern(code)\n",
        "            for alt_code in alternate_code_list:\n",
        "              highlight = page.search_for(alt_code)\n",
        "              # highlight pdf for option pattern\n",
        "              highlight_pdf(highlight, alt_code, code_type=\"ICD-9\")\n",
        "          # highlight pdf for main pattern   \n",
        "          highlight_pdf(highlight, code, code_type=\"ICD-9\")\n",
        "\n",
        "    # highlight ICD-10 keyword\n",
        "    if page_keyword_dict is not None:\n",
        "      if page_num in page_keyword_dict:\n",
        "        for keyword in page_keyword_dict[page_num]:\n",
        "          coordinates = page.search_for(keyword)\n",
        "          #print(f\"Keyword: {keyword}, Length: {len(coordinates)}\")\n",
        "          cords_list = []\n",
        "          for inst in coordinates:\n",
        "            #print(f\"Keyword: {keyword}, inst: {inst}\")\n",
        "            #if isExactMatch(page, keyword, inst, fullMatch=True, caseSensitive=False):\n",
        "            highlight = page.add_highlight_annot(inst)\n",
        "            highlight.set_colors(stroke=[1, 0.8, 0.8])\n",
        "            highlight.update()\n",
        "            highlight = page.search_for(keyword)\n",
        "            cords_list.append(highlight)\n",
        "\n",
        "          if cords_list:\n",
        "            keyword_cors_output = f\"Page-{page_num}: {keyword} : {cords_list}\"\n",
        "            txt_output_file_name.write(\"%s\\n\" % keyword_cors_output)\n",
        "            #print(f\"Page-{page_num}: \", highlight, end='\\n')\n",
        "\n",
        "  txt_output_file_name.close()\n",
        "\n",
        "  pdf_output_file_name = f\"{pdf_file_name.split('.')[0]}_output.pdf\"\n",
        "  pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "  return pdf_output_file_name, cords_file_name\n",
        "\n",
        "\n",
        "def filter_unwanted_code(code_list, page_text):\n",
        "    filtered_code_list = []\n",
        "    # if re.search(\"ICD\", page_text):\n",
        "    # match_list = re.findall(\"(ICD-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "    match_list = re.findall(\"(IC[(A-z)]-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "    # print(\"Match list:\\n\", match_list)\n",
        "    for found_code in match_list:\n",
        "        for code in code_list:\n",
        "            if code in found_code:\n",
        "                filtered_code_list.append(code)\n",
        "    return filtered_code_list\n",
        "\n",
        "\n",
        "def search_icd_code(txt_list, nlp, code_type):\n",
        "    pdf_page_vocab = {}\n",
        "    for txt_file in txt_list:\n",
        "        with open(txt_file, \"r\") as f:\n",
        "            page_txt = f.read()\n",
        "            # filter the page that have line number instead of code\n",
        "            if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "                doc = nlp(page_txt)\n",
        "                code_list = [ent.text for ent in doc.ents]\n",
        "                page_number = 0\n",
        "                if len(code_list) != 0:\n",
        "                    page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "                    pdf_page_vocab[page_number] = code_list\n",
        "                    # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "\n",
        "                # filter the page that dont have ICD string into it\n",
        "                if code_type == \"ICD-9\":\n",
        "                    filtered_code_list = filter_unwanted_code(code_list, page_txt)\n",
        "                    pdf_page_vocab[page_number] = filtered_code_list\n",
        "                    # print(f\"Page[{txt_file.split('/')[1]}]: {filtered_code_list}\")\n",
        "\n",
        "    return pdf_page_vocab\n",
        "\n",
        "\n",
        "def get_json_array_list(text_path):\n",
        "  print(f\"Running '{text_path}'\")\n",
        "  json_arr = call(text_path)\n",
        "  print(f\"Got json for '{text_path}'\")\n",
        "  return json_arr\n",
        "\n",
        "\n",
        "def get_wrong_keyword_dict_with_thread(text_path_list):\n",
        "  wrong_keyword_dict = {}\n",
        "\n",
        "  # take care so that unnecessary thread should not be created\n",
        "  workers = min(MAX_WORKERS, len(text_path_list))\n",
        "  with futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "    json_arr_list = executor.map(get_json_array_list, sorted(text_path_list))\n",
        "\n",
        "  for idx, json_arr in enumerate(json_arr_list):\n",
        "    wrong_keyword_list = [list(element.values())[0] for element in json_arr]\n",
        "    if wrong_keyword_list: \n",
        "      wrong_keyword_dict[idx] = set(wrong_keyword_list)\n",
        "  return dict(sorted(wrong_keyword_dict.items(), key=lambda item: item[0]))\n",
        "\n",
        "def get_wrong_keyword_dict_with_process(text_path_list):\n",
        "  wrong_keyword_dict = {}\n",
        "\n",
        "  # take care so that unnecessary thread should not be created\n",
        "  workers = min(MAX_WORKERS, len(text_path_list))\n",
        "  with futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "    json_arr_list = executor.map(get_json_array_list, sorted(text_path_list))\n",
        "\n",
        "  for idx, json_arr in enumerate(json_arr_list):\n",
        "    wrong_keyword_list = [list(element.values())[0] for element in json_arr]\n",
        "    if wrong_keyword_list: \n",
        "      wrong_keyword_dict[idx] = set(wrong_keyword_list)\n",
        "  return dict(sorted(wrong_keyword_dict.items(), key=lambda item: item[0]))\n",
        "\n",
        "\n",
        "def get_wrong_keyword_dict(text_path_list):\n",
        "  wrong_keyword_dict = {}\n",
        "  for idx, file_path in enumerate(text_path_list):\n",
        "    print(idx, file_path)\n",
        "    json_arr = get_json_array_list(file_path)\n",
        "    wrong_keyword_list = [list(element.values())[0] for element in json_arr]\n",
        "    if wrong_keyword_list:\n",
        "      wrong_keyword_dict[idx] = set(wrong_keyword_list)\n",
        "  return wrong_keyword_dict\n",
        "\n",
        "\n",
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "qB-XpoweygN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare keyword/phrase"
      ],
      "metadata": {
        "id": "N4dDTs-rJL_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v3.jsonl\")\n",
        "\n",
        "# loading and updating patterns for ICD-9 code\n",
        "nlp_code9 = English()\n",
        "nlp_code9.add_pipe(\"entity_ruler\").from_disk(\"./icd9_code_patterns-v1.jsonl\")"
      ],
      "metadata": {
        "id": "y8UcOwHpJnpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "5i_7mtx2e56B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: spliting pdf file\n",
        "pdf_file_name = \"APS_400000000R_final.pdf\"\n",
        "pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "# Step-2: Extracting text from pdf\n",
        "txt_list = extract_text_from_pdf(pdf_list)"
      ],
      "metadata": {
        "id": "qw22evt02aRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_list"
      ],
      "metadata": {
        "id": "JT82NIHincwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Searching ICD-10 code\n",
        "page_code10_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")\n",
        "page_code10_dict"
      ],
      "metadata": {
        "id": "flLgpUfg2ghi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-4: Searching ICD-9 code\n",
        "page_code9_dict = search_icd_code(txt_list, nlp_code9, code_type=\"ICD-9\")\n",
        "page_code9_dict"
      ],
      "metadata": {
        "id": "BKal0jMy2tCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd10_code_kerword_df = pd.read_csv(\"icd_10_code_and_keywords.csv\")\n",
        "icd10_code_kerword_df.head()"
      ],
      "metadata": {
        "id": "iS0gZdHA28SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd9_code_kerword_df = pd.read_csv(\"icd9_code_and_kerword.csv\")\n",
        "icd9_code_kerword_df.head()"
      ],
      "metadata": {
        "id": "WZ0EB0oHfN9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_dot(code, index):\n",
        "  if not \".\" in code:\n",
        "    if len(code) > 3:\n",
        "      return code[:index] + \".\" + code[index:]\n",
        "    else:\n",
        "      return code[:index] + \".\" + code[index:] + \"0\"\n",
        "  else:\n",
        "    return code\n",
        "\n",
        "print(insert_dot(\"G0439\", 3))"
      ],
      "metadata": {
        "id": "k4l153DBQwiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keyword_list(code_dict, data_df):\n",
        "  keyword_list = []\n",
        "  icd_kerword_list = []\n",
        "  # get code list\n",
        "  code_list = [value for key, value in code_dict.items()]\n",
        "  code_list = [[insert_dot(code, 3) for code in temp_list] for temp_list in code_list]\n",
        "  for t_list in code_list:\n",
        "    keyword_list.extend(t_list)\n",
        "  print(len(keyword_list))\n",
        "  #print(list(set(keyword_list)))\n",
        "  # filter dataframe based on code list\n",
        "  icd_kerword_df = data_df.loc[data_df['Code'].isin(list(set(keyword_list)))]\n",
        "  # create file to write cordinate \n",
        "  icd_keyword_found_filename = open(\"icd_keyword_found.txt\", \"a\")\n",
        "  for _, row in icd_kerword_df.iterrows():\n",
        "    icd_kerword_list.append(row[\"Keyword\"])\n",
        "    #icd_kerword_list.append(row[\"Keyword\"].lower())\n",
        "    keyword_found_output = f\"{row['Code']}: {row['Keyword']}\"\n",
        "    icd_keyword_found_filename.write(\"%s\\n\" % keyword_found_output)\n",
        "  icd_keyword_found_filename.close()\n",
        "  return icd_kerword_list"
      ],
      "metadata": {
        "id": "tmcZvgsSGjF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd10_kerword_list = get_keyword_list(page_code10_dict, icd10_code_kerword_df)\n",
        "len(icd10_kerword_list)"
      ],
      "metadata": {
        "id": "H2irST8F8BLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd10_kerword_list"
      ],
      "metadata": {
        "id": "1x02UQD3SCkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd9_kerword_list = get_keyword_list(page_code9_dict, icd9_code_kerword_df)\n",
        "len(icd9_kerword_list)"
      ],
      "metadata": {
        "id": "zwTtZlkKhYok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd9_kerword_list"
      ],
      "metadata": {
        "id": "y9RI4Ne4hj8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine both list\n",
        "icd_kerword_list = icd10_kerword_list + icd9_kerword_list\n",
        "len(icd_kerword_list)"
      ],
      "metadata": {
        "id": "zEh4YtcihvfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd_kerword_list[:5]"
      ],
      "metadata": {
        "id": "Rvu0sCoQimNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd_kerword_list[-5:]"
      ],
      "metadata": {
        "id": "x6YvlLUUiqXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "wrong_keyword_dict = get_wrong_keyword_dict(txt_list)"
      ],
      "metadata": {
        "id": "f7C3J8jbnzPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict"
      ],
      "metadata": {
        "id": "X9swFK9Jsizl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extract Sentence"
      ],
      "metadata": {
        "id": "Oi983bTESKct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your PDF\n",
        "with open(\"APS_38600000R_final.pdf\", \"rb\") as f:\n",
        "  pdf = pdftotext.PDF(f)\n",
        "\n",
        "pdf_text = \"\\n\\n\".join(pdf)\n",
        "# write text into file\n",
        "with open(\"ocr-extracted.txt\", \"w\") as f:\n",
        "  f.write(pdf_text)\n",
        "\n",
        "print(\"File is written\")"
      ],
      "metadata": {
        "id": "gcQ62vnxSM29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentence(key_phrase_list, sample_text):\n",
        "  match_lists = []\n",
        "\n",
        "  for key_phrase in key_phrase_list:\n",
        "    for word in key_phrase.split():\n",
        "      if not word.lower() in stop_words:\n",
        "        match_list = re.findall(f\"([^.\\n]*?{word}[^.]*\\.)\", sample_text)\n",
        "        match_lists.extend(match_list)\n",
        "  return list(set(match_lists))"
      ],
      "metadata": {
        "id": "yRKqXK-vZx1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentence(kerwords_list, sample_text):\n",
        "  match_lists = []\n",
        "\n",
        "  for key_phrase in kerwords_list:\n",
        "    match_list = re.findall(f\"([^\\n]*?(?i){key_phrase}[^.]*\\.)\", sample_text)\n",
        "    match_lists.extend(match_list)\n",
        "  return list(set(match_lists))"
      ],
      "metadata": {
        "id": "5Pl1xdkXbEOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "match_founds = extract_sentence(icd10_kerword_list, pdf_text)"
      ],
      "metadata": {
        "id": "znrLrf3KUShB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd_keywords_list = []\n",
        "for found in match_founds:\n",
        "  icd_keywords_list.append(found.replace(\"\\n\", \"\"))\n",
        "icd_keywords_list"
      ],
      "metadata": {
        "id": "ZbRBC9H9UQGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentence(wrong_kerword_list, sample_text_list):\n",
        "  match_dicts = {}\n",
        "  for key, kerword_set in wrong_kerword_list.items():\n",
        "    for key_phrase in kerword_set:\n",
        "      #print(key, key_phrase)\n",
        "      with open(sample_text_list[key], \"r\") as f:\n",
        "        file_txt = f.read()\n",
        "      match_list = re.findall(f\"([^\\n]*?(?i){key_phrase}[^.]*\\.)\", file_txt)\n",
        "      if match_list:\n",
        "        match_dicts[key_phrase] = [match.replace(\"\\n\", \"\") for match in match_list]\n",
        "  return match_dicts"
      ],
      "metadata": {
        "id": "_Z0A9v6rmis9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_list[7]"
      ],
      "metadata": {
        "id": "5y9gIAcGoNdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"txt-files/page-7.txt\", \"r\") as f:\n",
        "  file_txt = f.read()\n",
        "re.findall(f\"([^\\n]*?(?i)Contact with and (suspected) exposure to COVID-19[^.]*\\.)\", file_txt)"
      ],
      "metadata": {
        "id": "JREO435Wo2tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# txt-files/page-0.txt\n",
        "icd_keywords_dict = extract_sentence(wrong_keyword_dict, txt_list)"
      ],
      "metadata": {
        "id": "5OaO5U4PnR6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd_keywords_dict"
      ],
      "metadata": {
        "id": "LFYRJqtpojgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentence(kerwords_list, sample_text):\n",
        "  match_dicts = {}\n",
        "\n",
        "  for key_phrase in kerwords_list:\n",
        "    match_list = re.findall(f\"([^\\n]*?(?i){key_phrase}[^.]*\\.)\", sample_text)\n",
        "    if match_list:\n",
        "      match_dicts[key_phrase] = [match.replace(\"\\n\", \"\") for match in match_list]\n",
        "  return match_dicts"
      ],
      "metadata": {
        "id": "5gEjDV3mTlGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "icd_keywords_dict = extract_sentence(icd10_kerword_list, pdf_text)"
      ],
      "metadata": {
        "id": "jQT8Jb9kaQRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd_keywords_dict"
      ],
      "metadata": {
        "id": "qoA7ngPSUBtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-6: Highlighting ICD-10 code and keyword into pdf\n",
        "pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(page_code10_dict, \n",
        "                                                                  icd9_code_dict=None, \n",
        "                                                                  icd_keywords_dict=icd_keywords_dict,\n",
        "                                                                  pdf_file_name=\"APS_400000000R_final.pdf\", \n",
        "                                                                  cords_file_name=\"APS_400000000R_final_cords.txt\")\n",
        "print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")"
      ],
      "metadata": {
        "id": "IsgIgN1hB528"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-6: Highlighting ICD-10 code and keyword into pdf\n",
        "pdf_output_file, txt_output_file = highlight_icd_code_and_keyword2(page_code10_dict, \n",
        "                                                                  icd9_code_dict=None, \n",
        "                                                                  page_keyword_dict=wrong_keyword_dict,\n",
        "                                                                  pdf_file_name=\"APS_38600000R_final.pdf\", \n",
        "                                                                  cords_file_name=\"APS_38600000R_final_cords.txt\")\n",
        "print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")"
      ],
      "metadata": {
        "id": "YFJCGAd0jx0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Searching & Highlighting"
      ],
      "metadata": {
        "id": "TycHgKTZJ6a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v3.jsonl\")\n",
        "\n",
        "# loading and updating patterns for ICD-9 code\n",
        "nlp_code9 = English()\n",
        "nlp_code9.add_pipe(\"entity_ruler\").from_disk(\"./icd9_code_patterns-v1.jsonl\")"
      ],
      "metadata": {
        "id": "TWMPYgIJJ8xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for pdf_file in os.listdir(ocr_pdf_files_path):\n",
        "  pdf_file_name = f\"{ocr_pdf_files_path}/{pdf_file}\"\n",
        "  cords_file_name = f\"{pdf_file_name.split('.')[0]}_cords.txt\"\n",
        "\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = extract_text_from_pdf(pdf_list)\n",
        "\n",
        "  # Step-3: Searching ICD-10 code\n",
        "  icd10_code_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")\n",
        "\n",
        "  # Step-4: Searching ICD-9 code\n",
        "  page_code9_dict = search_icd_code(txt_list, nlp_code9, code_type=\"ICD-9\")\n",
        "\n",
        "  # Step-5: Searching ICD-10 keyword\n",
        "  wrong_keyword_dict = get_wrong_keyword_dict(txt_list)\n",
        "  # wrong_keyword_dict = get_wrong_keyword_dict_with_thread(txt_list)\n",
        "  # wrong_keyword_dict = get_wrong_keyword_dict_with_process(txt_list)\n",
        "  # print(\"After sorting:\\n\", wrong_keyword_dict)\n",
        "\n",
        "  # Step-6: Highlighting ICD-10 code and keyword into pdf\n",
        "  pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(icd10_code_dict, \n",
        "                                                                    page_code9_dict, \n",
        "                                                                    wrong_keyword_dict,\n",
        "                                                                    pdf_file_name, \n",
        "                                                                    cords_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "id": "AA7AygDDy06C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ocr-pdf-files\n",
        "!mkdir -p ocr-pdf-files"
      ],
      "metadata": {
        "id": "kbTuptfC1xrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"ocr-pdf-files/*.txt\")\n",
        "purge(\"ocr-pdf-files/*_output.pdf\")\n",
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "l06JNkJQ1yGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip ocr-pdf-files/*_output_cords.txt ocr-pdf-files/*_output_output.pdf"
      ],
      "metadata": {
        "id": "rZI3lkYT1zxq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}