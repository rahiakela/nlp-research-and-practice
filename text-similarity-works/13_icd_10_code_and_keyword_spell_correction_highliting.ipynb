{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4+Uk1lyd5mcrxTUFz+PwM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/text-similarity-works/13_icd_10_code_and_keyword_spell_correction_highliting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "73ORkeFzaRA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "[Rule-based entity recognition](https://spacy.io/usage/rule-based-matching#entityruler)\n",
        "\n",
        "[PDF-to-TEXT](https://pypi.org/project/pdftotext/)\n",
        "\n",
        "[Fitz Exact Match](https://stackoverflow.com/questions/64536027/selecting-the-exact-match-using-pymupdf-page-searchfor)"
      ],
      "metadata": {
        "id": "nAkX90V5vVML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install -U pdftotext\n",
        "!pip install PyPDF2\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "Ti6ZynbyaR9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just restart the colab environment."
      ],
      "metadata": {
        "id": "EIvuMvZfuhfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import pdb\n",
        "\n",
        "import fitz\n",
        "import cv2 \n",
        "import pdftotext\n",
        "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.lang.en import English\n",
        "from spacy.tokens import Span\n",
        "from spacy.language import Language\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "from concurrent import futures\n",
        "\n",
        "import nltk"
      ],
      "metadata": {
        "id": "fAcHTn0JaM2S"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p pdf-files\n",
        "!mkdir -p txt-files\n",
        "!mkdir -p ocr-pdf-files"
      ],
      "metadata": {
        "id": "IsoNvC1ibb6l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_files_path = \"pdf-files\"\n",
        "txt_files_path = \"txt-files\""
      ],
      "metadata": {
        "id": "YIUA8MJDbcg6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define some functions"
      ],
      "metadata": {
        "id": "v5Qy3RJN2VQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pdf(pdf_path):\n",
        "  pdf_in_file = open(pdf_path, \"rb\")\n",
        "  pdf = PdfFileReader(pdf_in_file)\n",
        "  pdf_list = []\n",
        "  for page in range(pdf.numPages):\n",
        "      inputpdf = PdfFileReader(pdf_in_file)\n",
        "      output = PdfFileWriter()\n",
        "      output.addPage(inputpdf.getPage(page))\n",
        "      with open(f\"{pdf_files_path}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "          output.write(outputStream)\n",
        "          pdf_list.append(f\"page-{page}.pdf\")\n",
        "  return pdf_list"
      ],
      "metadata": {
        "id": "YfTNt1mrbwy3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_list):\n",
        "  txt_file_list = []\n",
        "  i = 0\n",
        "  for pdf_file in pdf_list:\n",
        "    with open(os.path.join(pdf_files_path, pdf_file), \"rb\") as f:\n",
        "      pdf = pdftotext.PDF(f)\n",
        "    \n",
        "    # Read all the text into one string\n",
        "    pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "    # write text into file\n",
        "    with open(f\"{txt_files_path}/page-{str(i)}.txt\", \"a\") as f:\n",
        "      f.write(pdf_text)\n",
        "    txt_file_list.append(f\"{txt_files_path}/page-{str(i)}.txt\")\n",
        "    i += 1\n",
        "  return txt_file_list"
      ],
      "metadata": {
        "id": "XRSuNufIbxbr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_opt_pattern(icd_10_code):\n",
        "  # create alternate pattern\n",
        "  code_arr = icd_10_code.split(\".\")\n",
        "  if len(code_arr) > 1:\n",
        "    code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "    code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "    code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "    return [code1, code2, code3]\n",
        "  else:\n",
        "    return icd_10_code"
      ],
      "metadata": {
        "id": "VyvaUtt_dUiF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isExactMatch(page, term, clip, fullMatch=False, caseSensitive=False):\n",
        "  # clip is an item from page.search_for(term, quads=True)\n",
        "  termLen = len(term)\n",
        "  termBboxLen = max(clip.height, clip.width)\n",
        "  termfontSize = termBboxLen/termLen\n",
        "  f = termfontSize*2\n",
        "\n",
        "  #clip = clip.rect\n",
        "\n",
        "  validate = page.get_text(\"blocks\", clip = clip + (-f, -f, f, f), flags=0)[0][4]\n",
        "  flag = 0\n",
        "  if not caseSensitive:\n",
        "      flag = re.IGNORECASE\n",
        "\n",
        "  matches = len(re.findall(f'{term}', validate, flags=flag)) > 0\n",
        "  if fullMatch:\n",
        "      matches = len(re.findall(f'\\\\b{term}\\\\b', validate))>0\n",
        "  return matches\n",
        "\n",
        "def highlight_icd_code_and_keyword(pdf_code_dict, page_keyword_dict=None, pdf_file_name=None, cords_file_name=None, code_type=\"ICD-10\"):\n",
        "  pdf_file = fitz.open(pdf_file_name)\n",
        "\n",
        "  def highlight_pdf(highlight, icd10_code):\n",
        "    cords_list = []\n",
        "    for inst in highlight:\n",
        "      highlight = page.add_highlight_annot(inst)\n",
        "      if code_type == \"ICD-9\":\n",
        "        highlight.set_colors(stroke=[1, 0.5, 0.8]) # light red color (r, g, b)\n",
        "      highlight.update()\n",
        "      highlight = page.search_for(icd10_code)\n",
        "      cords_list.append(highlight)\n",
        "    code_cors_output = f\"Page-{page_num}: {icd10_code} : {cords_list}\"\n",
        "    txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "\n",
        "  # create file to write cordinate \n",
        "  txt_output_file_name = open(cords_file_name, \"a\")\n",
        "\n",
        "  for page_num, page in enumerate(pdf_file):\n",
        "\n",
        "    # highlight code\n",
        "    if page_num in pdf_code_dict:\n",
        "      for code in pdf_code_dict[page_num]:\n",
        "        highlight = page.search_for(code)\n",
        "        if len(highlight) == 0:\n",
        "          alternate_code_list = get_opt_pattern(code)\n",
        "          for alt_code in alternate_code_list:\n",
        "            highlight = page.search_for(alt_code)\n",
        "            # highlight pdf for option pattern\n",
        "            highlight_pdf(highlight, alt_code)\n",
        "        # highlight pdf for main pattern   \n",
        "        highlight_pdf(highlight, code)\n",
        "\n",
        "    # highlight keyword\n",
        "    if page_keyword_dict is not None:\n",
        "      if page_num in page_keyword_dict:\n",
        "        for keyword in page_keyword_dict[page_num]:\n",
        "          coordinates = page.search_for(keyword)\n",
        "          #print(f\"Keyword: {keyword}, Length: {len(coordinates)}\")\n",
        "          cords_list = []\n",
        "          for inst in coordinates:\n",
        "            #print(f\"Keyword: {keyword}, inst: {inst}\")\n",
        "            #if isExactMatch(page, keyword, inst, fullMatch=True, caseSensitive=False):\n",
        "            highlight = page.add_highlight_annot(inst)\n",
        "            highlight.set_colors(stroke=[1, 0.8, 0.8])\n",
        "            highlight.update()\n",
        "            highlight = page.search_for(keyword)\n",
        "            cords_list.append(highlight)\n",
        "          keyword_cors_output = f\"Page-{page_num}: {keyword} : {cords_list}\"\n",
        "          txt_output_file_name.write(\"%s\\n\" % keyword_cors_output)\n",
        "          #print(f\"Page-{page_num}: \", highlight, end='\\n')\n",
        "\n",
        "  txt_output_file_name.close()\n",
        "\n",
        "  pdf_output_file_name = f\"{pdf_file_name.split('.')[0]}_output.pdf\"\n",
        "  pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "  return pdf_output_file_name, cords_file_name"
      ],
      "metadata": {
        "id": "zq1uBcf5gVcm"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_speacial_chars(doc_str):\n",
        "  regex = re.compile('[,]')\n",
        "  if(regex.search(doc_str) != None):\n",
        "    updated_str = doc_str.replace(\",\", \".\")\n",
        "  return updated_str"
      ],
      "metadata": {
        "id": "kfyaQyYbWQIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "handle_speacial_chars(\"Decreased white blood cell count, unspecified\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8qmoC0PP3nYn",
        "outputId": "6c18c48d-4024-4b66-d95c-966f647d2c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Decreased white blood cell count. unspecified'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@Language.component(\"custom_comma_remover\")\n",
        "def remove_comma_from_keyword(doc):\n",
        "  token_list = []\n",
        "  for index, token in enumerate(doc):\n",
        "    # skip the loop if token contains \".\" or \",\"\n",
        "    if token.text == '.' or token.text == ',':\n",
        "      continue\n",
        "\n",
        "    # replace comma with space otherwise not\n",
        "    if \".\" in token.text:\n",
        "      token_list.append(token.text.replace(\".\", \"\"))\n",
        "    else:\n",
        "      token_list.append(token.text)\n",
        "\n",
        "  return Doc(doc.vocab, words=token_list)"
      ],
      "metadata": {
        "id": "DTcyvk_a_avZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_icd_keyword_pattern2(icd_10_keyword_df, nlp=None):\n",
        "\n",
        "  keywords = [row[\"Keyword\"] for _, row in icd_10_keyword_df.iterrows()]\n",
        "  \n",
        "  phrase_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "  patterns = list(nlp.tokenizer.pipe(keywords))\n",
        "  phrase_matcher.add('keywords', patterns)\n",
        "\n",
        "  nlp.add_pipe(\"custom_comma_remover\")\n",
        "\n",
        "  return phrase_matcher"
      ],
      "metadata": {
        "id": "zRrnUYBb-V71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_icd_keyword_pattern(icd_10_keyword_df, nlp=None):\n",
        "  keywords = []\n",
        "  for _, row in icd_10_keyword_df.iterrows():\n",
        "    keyword = row[\"Keyword\"]\n",
        "    keywords.append(keyword)\n",
        "    # replace comma(,) with dot(.) and space and add extra two keyword\n",
        "    regex = re.compile('[,]')\n",
        "    if(regex.search(keyword) != None):\n",
        "      keywords.append(keyword.replace(\",\", \".\"))\n",
        "      keywords.append(keyword.replace(\",\", \"\"))\n",
        "  \n",
        "  phrase_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\", )\n",
        "  patterns = list(nlp.tokenizer.pipe(keywords))\n",
        "  phrase_matcher.add('keywords', patterns)\n",
        "\n",
        "  regex = re.compile('[@_!#$%^&*()<>?/\\|}{~:.,]')\n",
        "  reg_patterns = [{\"TEXT\": {\"REGEX\": regex}}]\n",
        "  # phrase_matcher.add('reg_keywords', reg_patterns)\n",
        "  # phrase_matcher.add('keywords', patterns)\n",
        "  return phrase_matcher"
      ],
      "metadata": {
        "id": "QA_x9dTobXma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_unwanted_code(code_list, page_text):\n",
        "  filtered_code_list = []\n",
        "  #if re.search(\"ICD\", page_text):\n",
        "  #match_list = re.findall(\"(ICD-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "  match_list = re.findall(\"(IC[(A-z)]-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "  #print(\"Match list:\\n\", match_list)\n",
        "  for found_code in match_list:\n",
        "    for code in code_list:\n",
        "      if code in found_code:\n",
        "        filtered_code_list.append(code)\n",
        "  return filtered_code_list\n",
        "\n",
        "def search_icd_code(txt_list, nlp, code_type):\n",
        "  pdf_page_vocab = {}\n",
        "  for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "      page_txt = f.read()\n",
        "      # filter the page that have line number instead of code\n",
        "      if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "        doc = nlp(page_txt)\n",
        "        code_list = [ent.text for ent in doc.ents]\n",
        "        page_number = 0\n",
        "        if len(code_list) != 0:\n",
        "          page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "          pdf_page_vocab[page_number] = code_list\n",
        "          # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "        \n",
        "        # filter the page that dont have ICD string into it\n",
        "        if code_type == \"ICD-9\":\n",
        "          filtered_code_list = filter_unwanted_code(code_list, page_txt)\n",
        "          pdf_page_vocab[page_number] = filtered_code_list\n",
        "          # print(f\"Page[{txt_file.split('/')[1]}]: {filtered_code_list}\")\n",
        "\n",
        "  return pdf_page_vocab"
      ],
      "metadata": {
        "id": "TP8ku9QXFju1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_icd_keyword(txt_list, phrase_matcher, nlp=None):\n",
        "  page_keyword_dict = {}\n",
        "  # Step-4: Searching ICD-10 code\n",
        "  for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "      page_txt = f.read()\n",
        "      doc = nlp(page_txt)\n",
        "      matches = phrase_matcher(doc)\n",
        "\n",
        "      keyword_list = []\n",
        "      for match_id, start, end in matches:\n",
        "        span = doc[start: end]\n",
        "        keyword_list.append(f\"{span}\")\n",
        "\n",
        "      if len(keyword_list) != 0:\n",
        "        page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "        page_keyword_dict[page_number] = set(keyword_list)\n",
        "        # print(f\"Page[{txt_file.split('/')[1]}]: {set(keyword_list)}\")\n",
        "  return page_keyword_dict"
      ],
      "metadata": {
        "id": "r9rDVhCfGPiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "gY9YrfjBgr6b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spell Correction"
      ],
      "metadata": {
        "id": "W7ND6UCaFUfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import difflib\n",
        "import re, os\n",
        "import pickle\n",
        "\n",
        "# keyword_file_path = \"keyword_impairment_v1.txt\"\n",
        "keyword_file_path = \"icd_10_keywords.txt\"\n",
        "\n",
        "def spell_check(file_path, word_dict_, keywords_set):\n",
        "    \"\"\"Given file_path\n",
        "        Returns dictionary with\n",
        "        keys as incorrect word\n",
        "        and value as correct word\"\"\"\n",
        "\n",
        "    with open( file_path, encoding=\"utf8\") as f:\n",
        "        page = f.readlines()\n",
        "    # txt_words = list(map(lambda x:x.lower().strip() , page))\n",
        "\n",
        "    txt_words = []\n",
        "    for line in page:\n",
        "        line = re.sub(r'[^\\w\\s]', ' ', line)\n",
        "\n",
        "        # line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "        if len(line.strip()) > 3:\n",
        "            for word in line.split():\n",
        "                if len(word) > 3 and word.isalpha():\n",
        "                    txt_words.append(word.lower().strip())\n",
        "\n",
        "    unusual_words = []\n",
        "    for word in set(txt_words):\n",
        "        # res=dictionary.meaning(word, disable_errors=True)\n",
        "        # if res is None:\n",
        "        #    unusual_words.append(word)\n",
        "        if word in word_dict_:\n",
        "            pass\n",
        "        else:\n",
        "            unusual_words.append(word)\n",
        "    spell_change = {}\n",
        "    for word in set(unusual_words):\n",
        "        match = difflib.get_close_matches(word, keywords_set, cutoff=0.85)\n",
        "        if match != []:\n",
        "            if match[0] == word:  # or match[0][:-1] == word or match[0] == word[:-1] or match[0][1:] == word or match[0] == word[1:]:\n",
        "                pass\n",
        "                # print(word , 'spelling is correct')\n",
        "            else:\n",
        "                spell_change[word] = match[0]\n",
        "        #               print(word, '=='*8, match[0])\n",
        "        else:\n",
        "            pass\n",
        "            # print(word, 'no match found')\n",
        "\n",
        "    return spell_change\n",
        "\n",
        "\n",
        "def index_spell(page, spell_dict):\n",
        "    \"\"\"Returns index for lines where\n",
        "    spellings are found wrong \"\"\"\n",
        "\n",
        "    index_ = set()\n",
        "    for idx_ , p in enumerate(page):\n",
        "\n",
        "        for pp in p.split():\n",
        "            pp = pp.lower()\n",
        "            pp = re.sub(r'[^\\w\\s]', '', pp)\n",
        "            if pp in spell_dict.keys():\n",
        "                index_.add(idx_)\n",
        "    return index_\n",
        "\n",
        "def replace_spelling(pages, spell_dict):\n",
        "    \"\"\"Replaces spellings\n",
        "     given pages and spell_dict\"\"\"\n",
        "    new_pages = []\n",
        "    for page in pages:\n",
        "        page = page.lower()\n",
        "        for k,v in spell_dict.items():\n",
        "            page = re.sub(k, v, page, flags = re.I)\n",
        "        new_pages.append(page)\n",
        "    return new_pages\n",
        "\n",
        "\n",
        "def load_keywords(filepath=keyword_file_path):\n",
        "    \"\"\"loads keywords\"\"\"\n",
        "    with open(filepath) as f:\n",
        "        keywords = f.readlines()\n",
        "    return keywords\n",
        "\n",
        "\n",
        "def load_file(file_path):\n",
        "    \"\"\"load files\"\"\"\n",
        "    with open(file_path, encoding='utf-8') as f:\n",
        "        page = f.readlines()\n",
        "    return page\n",
        "\n",
        "\n",
        "def page_preprocess(page):\n",
        "    page_update = [\" \".join(p.split()) for p in page]\n",
        "    page_update = list(map(str.lower, page_update))\n",
        "    return page_update\n",
        "\n",
        "\n",
        "def print_matches(page_update, keywords, spell_dict):\n",
        "    matches = []\n",
        "    match_index = []\n",
        "    true_match = []\n",
        "    for j in range(len(page_update)):\n",
        "        pg_update = page_update[j]\n",
        "        page_update[j] = re.sub(r'[^\\w\\s]', ' ', page_update[j])\n",
        "        x = page_update[j].replace(',', '')\n",
        "        x = x.lower()\n",
        "        x = x.split()\n",
        "\n",
        "        for i, key in enumerate(keywords):\n",
        "            old = key\n",
        "            key = re.sub(r'[^\\w\\s]', ' ', key)\n",
        "            key = key.replace(',', '').lower()\n",
        "            key = key.split()\n",
        "            s = difflib.SequenceMatcher(None, x, key)\n",
        "            match = s.find_longest_match(0, len(x), 0, len(key))\n",
        "            if match.b == 0:\n",
        "                if match.size == len(key):\n",
        "                    #                     print('*'*50)\n",
        "                    #                     print(\"matched keyword ------\", old)\n",
        "                    #                     print('*'*50)\n",
        "                    match_index.append(j)\n",
        "                    matches.append(old.strip())\n",
        "                    true_match.append(pg_update)\n",
        "    return matches, match_index, true_match\n",
        "\n",
        "\n",
        "def true_file_match(match_phrase, match_index, index_spell_, spell_dict_reverse):\n",
        "    true_phrase = []\n",
        "    for idx_, mp in enumerate(match_phrase):\n",
        "        mp_old = mp\n",
        "\n",
        "        if match_index[idx_] in index_spell_:\n",
        "            for k, v in spell_dict_reverse.items():\n",
        "                mp = re.sub(k, v, mp, flags=re.I)\n",
        "            if mp_old == mp:\n",
        "                true_phrase.append('')\n",
        "            else:\n",
        "                true_phrase.append(mp)\n",
        "        else:\n",
        "            true_phrase.append(\"\")\n",
        "    return true_phrase\n",
        "\n",
        "def generate_json(org_match,phrases ):\n",
        "    json_array = []\n",
        "    for i, j in zip( org_match[0], phrases[0]):\n",
        "        if i == '':\n",
        "            n_dict = {j.lower():j}\n",
        "        else:\n",
        "            n_dict = {i.lower():j}\n",
        "        json_array.append(n_dict)\n",
        "    return json_array\n",
        "\n",
        "# Need to include this function in your call\n",
        "def call(txt_file_path):\n",
        "    \"\"\"Given txt_file_path\n",
        "      returns json array\n",
        "       {[\"org\":\"match\", \"org2\":\"match2\"]}\n",
        "       if match not found returns [] #empty list\n",
        "       \"\"\"\n",
        "    with open('dict_words.pkl', 'rb') as f:\n",
        "        word_dict_ = pickle.load(f)\n",
        "\n",
        "    # keywords file\n",
        "    with open(keyword_file_path) as f:\n",
        "        keywords = f.readlines()\n",
        "\n",
        "    # lower the keywords, replaces ',' with ''\n",
        "    key_full = list(map(lambda x: x.lower().strip(), keywords))\n",
        "    # key_full = list(map(lambda x: x.strip(), keywords))\n",
        "    keywords = []\n",
        "    for line in key_full:\n",
        "        line = line.replace(',', '')\n",
        "        keywords += line.split()\n",
        "\n",
        "    # filter words with length smaller the 3\n",
        "    keywords_set = list(filter(lambda x: len(x) > 3, set(keywords)))\n",
        "\n",
        "    phrases, total_dict, m_index, s_index, org_match = [], [], [], [], []\n",
        "    keywords_match = load_keywords()\n",
        "\n",
        "    #dir_ = \"input\"\n",
        "\n",
        "    names = [txt_file_path]\n",
        "\n",
        "    for enu, name in enumerate(names):\n",
        "\n",
        "        spell_dict = spell_check(name, word_dict_, keywords_set)\n",
        "        page = load_file(os.path.join(name))\n",
        "        new_pages = replace_spelling(page, spell_dict)\n",
        "        page_update = page_preprocess(new_pages)\n",
        "        spell_match = index_spell(page, spell_dict)\n",
        "\n",
        "        match_phrase, match_index, true_pg = print_matches(page_update, keywords_match, spell_dict)\n",
        "        spell_dict_reverse = {v: k for k, v in spell_dict.items()}\n",
        "        true_match = true_file_match(match_phrase, match_index, spell_match, spell_dict_reverse)\n",
        "        phrases.append(match_phrase)\n",
        "        total_dict.append(spell_dict)\n",
        "        m_index.append(match_index)\n",
        "        s_index.append(spell_match)\n",
        "        org_match.append(true_match)\n",
        "\n",
        "    file_names = []\n",
        "    phrases_df = []\n",
        "    org_match_df = []\n",
        "    for i in range(len(names)):\n",
        "        if phrases[i] != []:\n",
        "\n",
        "            for j in range(len(phrases[i])):\n",
        "                file_names.append(names[i])\n",
        "                phrases_df.append(phrases[i][j])\n",
        "                org_match_df.append(org_match[i][j])\n",
        "\n",
        "    return generate_json(org_match, phrases)"
      ],
      "metadata": {
        "id": "aTtKkckaFX1s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# txt-files/page-37.txt\n",
        "json_arr = call(\"txt-files/page-0.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9dHrrxIQV9g",
        "outputId": "ee228040-d096-41ec-9409-4f3b21698f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 7s, sys: 196 ms, total: 1min 7s\n",
            "Wall time: 1min 8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrdx9O6HSXAJ",
        "outputId": "d2008086-5508-41b5-dae8-02f3ab5ea7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'migraine with aura, not intractable, without status migrainosus': 'Migraine with aura, not intractable, without status migrainosus'},\n",
              " {'decreased white blood cell count, unspecified': 'Decreased white blood cell count, unspecified'},\n",
              " {'polpitations': 'Palpitations'},\n",
              " {'lower abdominal pain, unspecified': 'Lower abdominal pain, unspecified'},\n",
              " {'pain, unspecified': 'Pain, unspecified'},\n",
              " {'lipamatosis, not elsewhere classified': 'Lipomatosis, not elsewhere classified'},\n",
              " {'overweight': 'Overweight'},\n",
              " {'overweight': 'Overweight'}]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict = {}\n",
        "def get_wrong_keyword_dict(text_path_list):\n",
        "  \n",
        "  for idx, file_path in enumerate(text_path_list):\n",
        "    print(idx, file_path)\n",
        "    json_arr = call(file_path)\n",
        "    print(\"Got json\")\n",
        "    wrong_keyword_list = [list(element.keys())[0] for element in json_arr]\n",
        "    wrong_keyword_dict[idx] = set(wrong_keyword_list)\n",
        "  return wrong_keyword_dict"
      ],
      "metadata": {
        "id": "UMuIPXmuZ5gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "wrong_keyword_dict = get_wrong_keyword_dict([\"txt-files/page-37.txt\"])\n",
        "wrong_keyword_dict"
      ],
      "metadata": {
        "id": "u1FE74UmpkfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Code"
      ],
      "metadata": {
        "id": "24QfUFHN5WVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_json_array_list(text_path):\n",
        "  print(f\"Running '{text_path}'\")\n",
        "  json_arr = call(text_path)\n",
        "  print(f\"Got json for '{text_path}'\")\n",
        "  return json_arr"
      ],
      "metadata": {
        "id": "5dMOQbUbH2fF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORKERS = 4\n",
        "\n",
        "def get_wrong_keyword_list(text_path_list):\n",
        "  with futures.ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "    response = executor.map(get_json_array_list, sorted(text_path_list))\n",
        "  return list(response)"
      ],
      "metadata": {
        "id": "0t7wnsAfBa4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORKERS = 20\n",
        "\n",
        "def get_wrong_keyword_dict(text_path_list):\n",
        "  wrong_keyword_dict = {}\n",
        "\n",
        "  # take care so that unnecessary thread should not be created\n",
        "  workers = min(MAX_WORKERS, len(text_path_list))\n",
        "  with futures.ThreadPoolExecutor(workers) as executor:\n",
        "    wrong_keyword_dict_list = executor.map(get_json_array_list, sorted(text_path_list))\n",
        "\n",
        "  for idx, json_arr in enumerate(wrong_keyword_dict_list):\n",
        "    wrong_keyword_list = [list(element.values())[0] for element in json_arr]\n",
        "    if wrong_keyword_list: \n",
        "      wrong_keyword_dict[idx] = set(wrong_keyword_list)\n",
        "  print(\"Before sorting:\\n\", wrong_keyword_dict)\n",
        "  return dict(sorted(wrong_keyword_dict.items(), key=lambda item: item[0]))"
      ],
      "metadata": {
        "id": "pUQiO72MJnDr"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict2 = get_wrong_keyword_dict([\"txt-files/page-37.txt\", \"txt-files/page-38.txt\"])"
      ],
      "metadata": {
        "id": "Ia5FJQOfWuZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3442b75-29d5-4f54-f627-dced756de46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            " [[{'migraine with aura, not intractable, without status migrainosus': 'Migraine with aura, not intractable, without status migrainosus'}, {'decreased white blood cell count, unspecified': 'Decreased white blood cell count, unspecified'}, {'palpitations': 'Palpitations'}, {'lower abdominal pain, unspecified': 'Lower abdominal pain, unspecified'}, {'pain, unspecified': 'Pain, unspecified'}, {'lipomatosis, not elsewhere classified': 'Lipomatosis, not elsewhere classified'}, {'overweight': 'Overweight'}, {'overweight': 'Overweight'}], [{'palpitationsnot': 'Palpitations'}, {'palpitations': 'Palpitations'}, {'lipomatosis, not elsewhere classifiedyou': 'Lipomatosis, not elsewhere classified'}]]\n",
            "Before sorting:\n",
            " {0: {'Lipomatosis, not elsewhere classified', 'Lower abdominal pain, unspecified', 'Decreased white blood cell count, unspecified', 'Pain, unspecified', 'Migraine with aura, not intractable, without status migrainosus', 'Palpitations', 'Overweight'}, 1: {'Lipomatosis, not elsewhere classified', 'Palpitations'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict2"
      ],
      "metadata": {
        "id": "maLd6DS11YAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v3.jsonl\")\n",
        "\n",
        "# loading and updating patterns for ICD-9 code\n",
        "nlp_code9 = English()\n",
        "nlp_code9.add_pipe(\"entity_ruler\").from_disk(\"./icd9_code_patterns-v1.jsonl\")\n",
        "\n",
        "# Load icd_10_code_keywords.csv file\n",
        "# icd_code_kerword_df = pd.read_csv(\"icd_10_code_keywords.csv\")\n",
        "\n",
        "# Creating ICD-10 keyword pattern\n",
        "# phrase_matcher = make_icd_keyword_pattern(icd_code_kerword_df, nlp_keyword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNaGnJbrgI4s",
        "outputId": "92c8e595-9e3b-4431-cd39-fb2c8bcab897"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x7f65f72b5e60>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "ocr_pdf_files_path = \"ocr-pdf-files\"\n",
        "for pdf_file in os.listdir(ocr_pdf_files_path):\n",
        "  pdf_file_name = f\"{ocr_pdf_files_path}/{pdf_file}\"\n",
        "  cords_file_name = f\"{pdf_file_name.split('.')[0]}_cords.txt\"\n",
        "\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = extract_text_from_pdf(pdf_list)\n",
        "\n",
        "  # Step-3: Searching ICD-10 code\n",
        "  page_code_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")\n",
        "\n",
        "  # Step-4: Searching ICD-10 keyword\n",
        "  # page_keyword_dict = search_icd_keyword(txt_list, phrase_matcher, nlp_keyword)\n",
        "  # wrong_keyword_dict = get_wrong_keyword_dict(txt_list)\n",
        "  wrong_keyword_dict = get_wrong_keyword_dict(txt_list)\n",
        "  print(\"After sorting:\\n\", wrong_keyword_dict)\n",
        "\n",
        "  # Step-7: Highlighting ICD-10 code and keyword into pdf\n",
        "  pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(page_code_dict, wrong_keyword_dict, pdf_file_name, cords_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # Step-8: Searching ICD-9 code\n",
        "  page_code9_dict = search_icd_code(txt_list, nlp_code9, code_type=\"ICD-9\")\n",
        "\n",
        "  # Step-9: Highlighting ICD-9 code into pdf\n",
        "  output_file_name = highlight_icd_code_and_keyword(page_code9_dict, page_keyword_dict=None, pdf_file_name=pdf_output_file, cords_file_name=cords_file_name, code_type=\"ICD-9\")\n",
        "  print(f\"File[{output_file_name}] is saved after highlighting ICD-9 code\")\n",
        "  \n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVDsgB4-gJWp",
        "outputId": "5c1dfdfb-641b-41ba-bd85-ef38298dadc0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 'txt-files/page-0.txt'\n",
            "Running 'txt-files/page-1.txt'\n",
            "Running 'txt-files/page-10.txt'\n",
            "Running 'txt-files/page-100.txt'\n",
            "Running 'txt-files/page-101.txt'\n",
            "Running 'txt-files/page-102.txt'\n",
            "Running 'txt-files/page-103.txt'\n",
            "Running 'txt-files/page-104.txt'\n",
            "Running 'txt-files/page-105.txt'\n",
            "Running 'txt-files/page-106.txt'Running 'txt-files/page-107.txt'Running 'txt-files/page-108.txt'\n",
            "\n",
            "\n",
            "Running 'txt-files/page-109.txt'\n",
            "Running 'txt-files/page-11.txt'Running 'txt-files/page-110.txt'\n",
            "\n",
            "Running 'txt-files/page-111.txt'\n",
            "Running 'txt-files/page-112.txt'Running 'txt-files/page-113.txt'\n",
            "Running 'txt-files/page-114.txt'\n",
            "\n",
            "Running 'txt-files/page-115.txt'\n",
            "Got json for 'txt-files/page-1.txt'\n",
            "Running 'txt-files/page-116.txt'\n",
            "Got json for 'txt-files/page-108.txt'\n",
            "Running 'txt-files/page-117.txt'\n",
            "Got json for 'txt-files/page-105.txt'\n",
            "Running 'txt-files/page-118.txt'\n",
            "Got json for 'txt-files/page-113.txt'\n",
            "Running 'txt-files/page-119.txt'\n",
            "Got json for 'txt-files/page-106.txt'\n",
            "Running 'txt-files/page-12.txt'\n",
            "Got json for 'txt-files/page-100.txt'\n",
            "Running 'txt-files/page-120.txt'\n",
            "Got json for 'txt-files/page-10.txt'\n",
            "Running 'txt-files/page-121.txt'\n",
            "Got json for 'txt-files/page-102.txt'\n",
            "Running 'txt-files/page-122.txt'\n",
            "Got json for 'txt-files/page-109.txt'\n",
            "Running 'txt-files/page-123.txt'\n",
            "Got json for 'txt-files/page-114.txt'\n",
            "Running 'txt-files/page-124.txt'\n",
            "Got json for 'txt-files/page-0.txt'\n",
            "Running 'txt-files/page-125.txt'\n",
            "Got json for 'txt-files/page-107.txt'\n",
            "Running 'txt-files/page-126.txt'\n",
            "Got json for 'txt-files/page-112.txt'\n",
            "Running 'txt-files/page-127.txt'\n",
            "Got json for 'txt-files/page-104.txt'\n",
            "Running 'txt-files/page-128.txt'\n",
            "Got json for 'txt-files/page-11.txt'\n",
            "Running 'txt-files/page-129.txt'\n",
            "Got json for 'txt-files/page-103.txt'\n",
            "Running 'txt-files/page-13.txt'\n",
            "Got json for 'txt-files/page-111.txt'\n",
            "Running 'txt-files/page-130.txt'\n",
            "Got json for 'txt-files/page-101.txt'\n",
            "Running 'txt-files/page-131.txt'\n",
            "Got json for 'txt-files/page-115.txt'\n",
            "Running 'txt-files/page-132.txt'\n",
            "Got json for 'txt-files/page-110.txt'\n",
            "Running 'txt-files/page-133.txt'\n",
            "Got json for 'txt-files/page-128.txt'\n",
            "Running 'txt-files/page-134.txt'\n",
            "Got json for 'txt-files/page-130.txt'\n",
            "Running 'txt-files/page-135.txt'\n",
            "Got json for 'txt-files/page-116.txt'\n",
            "Running 'txt-files/page-136.txt'\n",
            "Got json for 'txt-files/page-129.txt'\n",
            "Running 'txt-files/page-14.txt'\n",
            "Got json for 'txt-files/page-131.txt'\n",
            "Running 'txt-files/page-15.txt'\n",
            "Got json for 'txt-files/page-132.txt'\n",
            "Running 'txt-files/page-16.txt'\n",
            "Got json for 'txt-files/page-117.txt'\n",
            "Running 'txt-files/page-17.txt'\n",
            "Got json for 'txt-files/page-118.txt'\n",
            "Running 'txt-files/page-18.txt'\n",
            "Got json for 'txt-files/page-119.txt'\n",
            "Running 'txt-files/page-19.txt'\n",
            "Got json for 'txt-files/page-126.txt'\n",
            "Running 'txt-files/page-2.txt'\n",
            "Got json for 'txt-files/page-135.txt'\n",
            "Running 'txt-files/page-20.txt'\n",
            "Got json for 'txt-files/page-12.txt'\n",
            "Running 'txt-files/page-21.txt'\n",
            "Got json for 'txt-files/page-13.txt'\n",
            "Running 'txt-files/page-22.txt'\n",
            "Got json for 'txt-files/page-127.txt'\n",
            "Running 'txt-files/page-23.txt'\n",
            "Got json for 'txt-files/page-121.txt'\n",
            "Running 'txt-files/page-24.txt'\n",
            "Got json for 'txt-files/page-125.txt'\n",
            "Running 'txt-files/page-25.txt'\n",
            "Got json for 'txt-files/page-123.txt'\n",
            "Running 'txt-files/page-26.txt'\n",
            "Got json for 'txt-files/page-133.txt'\n",
            "Running 'txt-files/page-27.txt'\n",
            "Got json for 'txt-files/page-17.txt'\n",
            "Running 'txt-files/page-28.txt'\n",
            "Got json for 'txt-files/page-120.txt'\n",
            "Running 'txt-files/page-29.txt'\n",
            "Got json for 'txt-files/page-122.txt'\n",
            "Running 'txt-files/page-3.txt'\n",
            "Got json for 'txt-files/page-124.txt'\n",
            "Running 'txt-files/page-30.txt'\n",
            "Got json for 'txt-files/page-134.txt'\n",
            "Running 'txt-files/page-31.txt'\n",
            "Got json for 'txt-files/page-14.txt'\n",
            "Running 'txt-files/page-32.txt'\n",
            "Got json for 'txt-files/page-27.txt'\n",
            "Running 'txt-files/page-33.txt'\n",
            "Got json for 'txt-files/page-19.txt'\n",
            "Running 'txt-files/page-34.txt'\n",
            "Got json for 'txt-files/page-23.txt'\n",
            "Running 'txt-files/page-35.txt'\n",
            "Got json for 'txt-files/page-136.txt'\n",
            "Running 'txt-files/page-36.txt'\n",
            "Got json for 'txt-files/page-21.txt'\n",
            "Running 'txt-files/page-37.txt'\n",
            "Got json for 'txt-files/page-2.txt'\n",
            "Running 'txt-files/page-38.txt'\n",
            "Got json for 'txt-files/page-31.txt'\n",
            "Running 'txt-files/page-39.txt'\n",
            "Got json for 'txt-files/page-16.txt'\n",
            "Running 'txt-files/page-4.txt'\n",
            "Got json for 'txt-files/page-20.txt'\n",
            "Running 'txt-files/page-40.txt'\n",
            "Got json for 'txt-files/page-30.txt'\n",
            "Running 'txt-files/page-41.txt'\n",
            "Got json for 'txt-files/page-24.txt'\n",
            "Running 'txt-files/page-42.txt'\n",
            "Got json for 'txt-files/page-32.txt'\n",
            "Running 'txt-files/page-43.txt'\n",
            "Got json for 'txt-files/page-22.txt'\n",
            "Running 'txt-files/page-44.txt'\n",
            "Got json for 'txt-files/page-28.txt'\n",
            "Running 'txt-files/page-45.txt'\n",
            "Got json for 'txt-files/page-18.txt'\n",
            "Running 'txt-files/page-46.txt'\n",
            "Got json for 'txt-files/page-29.txt'\n",
            "Running 'txt-files/page-47.txt'\n",
            "Got json for 'txt-files/page-26.txt'\n",
            "Running 'txt-files/page-48.txt'\n",
            "Got json for 'txt-files/page-3.txt'\n",
            "Running 'txt-files/page-49.txt'\n",
            "Got json for 'txt-files/page-25.txt'\n",
            "Running 'txt-files/page-5.txt'\n",
            "Got json for 'txt-files/page-39.txt'\n",
            "Running 'txt-files/page-50.txt'\n",
            "Got json for 'txt-files/page-15.txt'\n",
            "Running 'txt-files/page-51.txt'\n",
            "Got json for 'txt-files/page-42.txt'\n",
            "Running 'txt-files/page-52.txt'\n",
            "Got json for 'txt-files/page-35.txt'\n",
            "Running 'txt-files/page-53.txt'\n",
            "Got json for 'txt-files/page-50.txt'\n",
            "Running 'txt-files/page-54.txt'\n",
            "Got json for 'txt-files/page-48.txt'\n",
            "Running 'txt-files/page-55.txt'\n",
            "Got json for 'txt-files/page-33.txt'\n",
            "Running 'txt-files/page-56.txt'\n",
            "Got json for 'txt-files/page-41.txt'\n",
            "Running 'txt-files/page-57.txt'\n",
            "Got json for 'txt-files/page-34.txt'\n",
            "Running 'txt-files/page-58.txt'\n",
            "Got json for 'txt-files/page-37.txt'\n",
            "Running 'txt-files/page-59.txt'\n",
            "Got json for 'txt-files/page-40.txt'\n",
            "Running 'txt-files/page-6.txt'\n",
            "Got json for 'txt-files/page-46.txt'\n",
            "Running 'txt-files/page-60.txt'\n",
            "Got json for 'txt-files/page-44.txt'\n",
            "Running 'txt-files/page-61.txt'\n",
            "Got json for 'txt-files/page-38.txt'\n",
            "Running 'txt-files/page-62.txt'\n",
            "Got json for 'txt-files/page-4.txt'\n",
            "Running 'txt-files/page-63.txt'\n",
            "Got json for 'txt-files/page-36.txt'\n",
            "Running 'txt-files/page-64.txt'\n",
            "Got json for 'txt-files/page-47.txt'\n",
            "Running 'txt-files/page-65.txt'\n",
            "Got json for 'txt-files/page-52.txt'\n",
            "Running 'txt-files/page-66.txt'\n",
            "Got json for 'txt-files/page-43.txt'\n",
            "Running 'txt-files/page-67.txt'\n",
            "Got json for 'txt-files/page-45.txt'\n",
            "Running 'txt-files/page-68.txt'\n",
            "Got json for 'txt-files/page-49.txt'\n",
            "Running 'txt-files/page-69.txt'\n",
            "Got json for 'txt-files/page-5.txt'\n",
            "Running 'txt-files/page-7.txt'\n",
            "Got json for 'txt-files/page-51.txt'\n",
            "Running 'txt-files/page-70.txt'\n",
            "Got json for 'txt-files/page-54.txt'\n",
            "Running 'txt-files/page-71.txt'\n",
            "Got json for 'txt-files/page-63.txt'\n",
            "Running 'txt-files/page-72.txt'\n",
            "Got json for 'txt-files/page-55.txt'\n",
            "Running 'txt-files/page-73.txt'\n",
            "Got json for 'txt-files/page-58.txt'\n",
            "Running 'txt-files/page-74.txt'\n",
            "Got json for 'txt-files/page-56.txt'\n",
            "Running 'txt-files/page-75.txt'\n",
            "Got json for 'txt-files/page-53.txt'\n",
            "Running 'txt-files/page-76.txt'\n",
            "Got json for 'txt-files/page-59.txt'\n",
            "Running 'txt-files/page-77.txt'\n",
            "Got json for 'txt-files/page-67.txt'\n",
            "Running 'txt-files/page-78.txt'\n",
            "Got json for 'txt-files/page-64.txt'\n",
            "Running 'txt-files/page-79.txt'\n",
            "Got json for 'txt-files/page-57.txt'\n",
            "Running 'txt-files/page-8.txt'\n",
            "Got json for 'txt-files/page-60.txt'\n",
            "Running 'txt-files/page-80.txt'\n",
            "Got json for 'txt-files/page-61.txt'\n",
            "Running 'txt-files/page-81.txt'\n",
            "Got json for 'txt-files/page-62.txt'\n",
            "Running 'txt-files/page-82.txt'\n",
            "Got json for 'txt-files/page-69.txt'\n",
            "Running 'txt-files/page-83.txt'\n",
            "Got json for 'txt-files/page-77.txt'\n",
            "Running 'txt-files/page-84.txt'\n",
            "Got json for 'txt-files/page-65.txt'\n",
            "Running 'txt-files/page-85.txt'\n",
            "Got json for 'txt-files/page-6.txt'\n",
            "Running 'txt-files/page-86.txt'\n",
            "Got json for 'txt-files/page-68.txt'\n",
            "Running 'txt-files/page-87.txt'\n",
            "Got json for 'txt-files/page-66.txt'\n",
            "Running 'txt-files/page-88.txt'\n",
            "Got json for 'txt-files/page-72.txt'\n",
            "Running 'txt-files/page-89.txt'\n",
            "Got json for 'txt-files/page-7.txt'\n",
            "Running 'txt-files/page-9.txt'\n",
            "Got json for 'txt-files/page-75.txt'\n",
            "Running 'txt-files/page-90.txt'\n",
            "Got json for 'txt-files/page-85.txt'\n",
            "Running 'txt-files/page-91.txt'\n",
            "Got json for 'txt-files/page-71.txt'\n",
            "Running 'txt-files/page-92.txt'\n",
            "Got json for 'txt-files/page-70.txt'\n",
            "Running 'txt-files/page-93.txt'\n",
            "Got json for 'txt-files/page-74.txt'\n",
            "Running 'txt-files/page-94.txt'\n",
            "Got json for 'txt-files/page-88.txt'\n",
            "Running 'txt-files/page-95.txt'\n",
            "Got json for 'txt-files/page-94.txt'\n",
            "Running 'txt-files/page-96.txt'\n",
            "Got json for 'txt-files/page-78.txt'\n",
            "Running 'txt-files/page-97.txt'\n",
            "Got json for 'txt-files/page-80.txt'\n",
            "Running 'txt-files/page-98.txt'\n",
            "Got json for 'txt-files/page-8.txt'\n",
            "Running 'txt-files/page-99.txt'\n",
            "Got json for 'txt-files/page-73.txt'\n",
            "Got json for 'txt-files/page-89.txt'\n",
            "Got json for 'txt-files/page-84.txt'\n",
            "Got json for 'txt-files/page-79.txt'\n",
            "Got json for 'txt-files/page-82.txt'\n",
            "Got json for 'txt-files/page-81.txt'\n",
            "Got json for 'txt-files/page-76.txt'\n",
            "Got json for 'txt-files/page-93.txt'\n",
            "Got json for 'txt-files/page-83.txt'\n",
            "Got json for 'txt-files/page-9.txt'\n",
            "Got json for 'txt-files/page-96.txt'\n",
            "Got json for 'txt-files/page-86.txt'\n",
            "Got json for 'txt-files/page-95.txt'\n",
            "Got json for 'txt-files/page-92.txt'\n",
            "Got json for 'txt-files/page-91.txt'\n",
            "Got json for 'txt-files/page-90.txt'\n",
            "Got json for 'txt-files/page-87.txt'\n",
            "Got json for 'txt-files/page-98.txt'\n",
            "Got json for 'txt-files/page-97.txt'\n",
            "Got json for 'txt-files/page-99.txt'\n",
            "Before sorting:\n",
            " {0: {'Aphasia', 'Palpitations'}, 3: {'Tobacco use'}, 4: {'Cyanosis'}, 5: {'Dermatitis, unspecified', 'Overweight', 'Palpitations'}, 7: {'Dermatitis, unspecified', 'Palpitations'}, 8: {'Encounter for general adult medical examination without abnormal findings', 'Unspecified contact dermatitis, unspecified cause', 'Palpitations', 'Encounter for other general examination', 'Dermatitis, unspecified', 'Migraine with aura, not intractable, without status migrainosus'}, 10: {'Aphasia'}, 13: {'Aphasia'}, 20: {'Antiphospholipid syndrome'}, 24: {'Actinic keratosis'}, 45: {'Cyanosis'}, 47: {'Weakness', 'Palpitations'}, 48: {'Migraine with aura, not intractable, without status migrainosus'}, 54: {'Cervicogenic headache'}, 55: {'Palpitations'}, 56: {'Cyanosis'}, 58: {'Right lower quadrant pain'}, 60: {'Palpitations'}, 65: {'Weakness', 'Orthopnea', 'fever', 'Aphasia', 'Epistaxis', 'Palpitations', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Nausea', 'Heartburn', 'Anorexia', 'Polyphagia', 'Melena', 'Chronic cough', 'Hematemesis'}, 66: {'Tobacco use'}, 67: {'Cyanosis'}, 68: {'Decreased white blood cell count, unspecified', 'Palpitations', 'Lower abdominal pain, unspecified', 'Lipomatosis, not elsewhere classified', 'Overweight', 'Pain, unspecified', 'Migraine with aura, not intractable, without status migrainosus'}, 69: {'Lipomatosis, not elsewhere classified', 'Palpitations'}, 70: {'Decreased white blood cell count, unspecified', 'Palpitations', 'Lower abdominal pain, unspecified', 'Lipomatosis, not elsewhere classified', 'Pain, unspecified', 'Migraine with aura, not intractable, without status migrainosus'}, 71: {'Cervicogenic headache', 'Tobacco use', 'Aphasia', 'Lower abdominal pain, unspecified', 'Overweight', 'Pain, unspecified'}, 72: {'Weakness', 'Orthopnea', 'Dysuria', 'Aphasia', 'Epistaxis', 'Palpitations', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Nausea', 'Anorexia', 'Heartburn', 'Nocturia', 'Melena', 'Polyphagia', 'Chronic cough', 'Hematemesis'}, 73: {'Tobacco use'}, 74: {'Decreased white blood cell count, unspecified', 'Migraine with aura, not intractable, without status migrainosus', 'Palpitations'}, 84: {'Weakness'}, 92: {'Occipital neuralgia'}, 93: {'Aphasia', 'Occipital neuralgia', 'Multiple sclerosis'}, 94: {'Aphasia'}, 96: {'Aphasia', 'Cervicalgia'}, 99: {'Weakness', 'Sneezing'}, 102: {'Weakness'}, 114: {'fever', 'Aphasia', 'Epistaxis', 'Palpitations', 'Heartburn', 'Nocturia', 'Weakness', 'Melena', 'Nausea', 'Anorexia', 'Chronic cough', 'Hematemesis', 'Orthopnea', 'Dysuria', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Polyphagia'}, 116: {'Tobacco use'}, 117: {'Cyanosis'}, 118: {'Dermatitis, unspecified', 'Overweight', 'Palpitations'}, 120: {'Dermatitis, unspecified', 'Encounter for general adult medical examination without abnormal findings', 'Migraine with aura, not intractable, without status migrainosus', 'Palpitations'}, 121: {'Dermatitis, unspecified', 'Decreased white blood cell count, unspecified', 'Unspecified contact dermatitis, unspecified cause', 'Palpitations'}, 127: {'Reversible cerebrovascular vasoconstriction syndrome'}, 129: {'Worries'}, 136: {'Orthopnea', 'Dysuria', 'fever', 'Aphasia', 'Epistaxis', 'Palpitations', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Nausea', 'Heartburn', 'Anorexia', 'Nocturia', 'Melena', 'Polyphagia', 'Chronic cough', 'Hematemesis'}}\n",
            "After sorting:\n",
            " {0: {'Aphasia', 'Palpitations'}, 3: {'Tobacco use'}, 4: {'Cyanosis'}, 5: {'Dermatitis, unspecified', 'Overweight', 'Palpitations'}, 7: {'Dermatitis, unspecified', 'Palpitations'}, 8: {'Encounter for general adult medical examination without abnormal findings', 'Unspecified contact dermatitis, unspecified cause', 'Palpitations', 'Encounter for other general examination', 'Dermatitis, unspecified', 'Migraine with aura, not intractable, without status migrainosus'}, 10: {'Aphasia'}, 13: {'Aphasia'}, 20: {'Antiphospholipid syndrome'}, 24: {'Actinic keratosis'}, 45: {'Cyanosis'}, 47: {'Weakness', 'Palpitations'}, 48: {'Migraine with aura, not intractable, without status migrainosus'}, 54: {'Cervicogenic headache'}, 55: {'Palpitations'}, 56: {'Cyanosis'}, 58: {'Right lower quadrant pain'}, 60: {'Palpitations'}, 65: {'Weakness', 'Orthopnea', 'fever', 'Aphasia', 'Epistaxis', 'Palpitations', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Nausea', 'Heartburn', 'Anorexia', 'Polyphagia', 'Melena', 'Chronic cough', 'Hematemesis'}, 66: {'Tobacco use'}, 67: {'Cyanosis'}, 68: {'Decreased white blood cell count, unspecified', 'Palpitations', 'Lower abdominal pain, unspecified', 'Lipomatosis, not elsewhere classified', 'Overweight', 'Pain, unspecified', 'Migraine with aura, not intractable, without status migrainosus'}, 69: {'Lipomatosis, not elsewhere classified', 'Palpitations'}, 70: {'Decreased white blood cell count, unspecified', 'Palpitations', 'Lower abdominal pain, unspecified', 'Lipomatosis, not elsewhere classified', 'Pain, unspecified', 'Migraine with aura, not intractable, without status migrainosus'}, 71: {'Cervicogenic headache', 'Tobacco use', 'Aphasia', 'Lower abdominal pain, unspecified', 'Overweight', 'Pain, unspecified'}, 72: {'Weakness', 'Orthopnea', 'Dysuria', 'Aphasia', 'Epistaxis', 'Palpitations', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Nausea', 'Anorexia', 'Heartburn', 'Nocturia', 'Melena', 'Polyphagia', 'Chronic cough', 'Hematemesis'}, 73: {'Tobacco use'}, 74: {'Decreased white blood cell count, unspecified', 'Migraine with aura, not intractable, without status migrainosus', 'Palpitations'}, 84: {'Weakness'}, 92: {'Occipital neuralgia'}, 93: {'Aphasia', 'Occipital neuralgia', 'Multiple sclerosis'}, 94: {'Aphasia'}, 96: {'Aphasia', 'Cervicalgia'}, 99: {'Weakness', 'Sneezing'}, 102: {'Weakness'}, 114: {'fever', 'Aphasia', 'Epistaxis', 'Palpitations', 'Heartburn', 'Nocturia', 'Weakness', 'Melena', 'Nausea', 'Anorexia', 'Chronic cough', 'Hematemesis', 'Orthopnea', 'Dysuria', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Polyphagia'}, 116: {'Tobacco use'}, 117: {'Cyanosis'}, 118: {'Dermatitis, unspecified', 'Overweight', 'Palpitations'}, 120: {'Dermatitis, unspecified', 'Encounter for general adult medical examination without abnormal findings', 'Migraine with aura, not intractable, without status migrainosus', 'Palpitations'}, 121: {'Dermatitis, unspecified', 'Decreased white blood cell count, unspecified', 'Unspecified contact dermatitis, unspecified cause', 'Palpitations'}, 127: {'Reversible cerebrovascular vasoconstriction syndrome'}, 129: {'Worries'}, 136: {'Orthopnea', 'Dysuria', 'fever', 'Aphasia', 'Epistaxis', 'Palpitations', 'Wheezing', 'Nasal congestion', 'Polydipsia', 'Hemoptysis', 'Nausea', 'Heartburn', 'Anorexia', 'Nocturia', 'Melena', 'Polyphagia', 'Chronic cough', 'Hematemesis'}}\n",
            "File[ocr-pdf-files/Redacted_Sample_output.pdf] is saved after highlighting ICD-10 code and keyword\n",
            "Highlighted coordinates are saved into [ocr-pdf-files/Redacted_Sample_cords.txt] file.\n",
            "File[('ocr-pdf-files/Redacted_Sample_output_output.pdf', 'ocr-pdf-files/Redacted_Sample_cords.txt')] is saved after highlighting ICD-9 code\n",
            "CPU times: user 2h 1min 47s, sys: 2min 46s, total: 2h 4min 33s\n",
            "Wall time: 2h 2min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ocr-pdf-files\n",
        "!mkdir -p ocr-pdf-files"
      ],
      "metadata": {
        "id": "yod4O8Fa7cdt"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"ocr-pdf-files/*.txt\")\n",
        "purge(\"ocr-pdf-files/*_output.pdf\")\n",
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "emgFFHv-7e_t"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip ocr-pdf-files/*_output_cords.txt ocr-pdf-files/*_output_output.pdf"
      ],
      "metadata": {
        "id": "nDKi2p46JNFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"ocr-pdf-files\"\n",
        "file_name = os.path.basename(\"ocr-pdf-files/Redacted_Sample.pdf\")\n",
        "file = os.path.splitext(os.path.basename(\"ocr-pdf-files/Redacted_Sample.pdf\"))\n",
        "\n",
        "print(file_name)\n",
        "print(file[0])  # returns tuple of string\n",
        " \n",
        "print(file[0] + file[1])\n",
        "print(os.path.join(file_path, file_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37g-GtGzKnJM",
        "outputId": "b2a6f906-9091-431f-9007-c8067235d2d7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redacted_Sample.pdf\n",
            "Redacted_Sample\n",
            "Redacted_Sample.pdf\n",
            "ocr-pdf-files/Redacted_Sample.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data preprocessing"
      ],
      "metadata": {
        "id": "kRlokPzlatON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = []\n",
        "with open(\"icd_10_keywords.txt\", \"r\") as f:\n",
        "  txt_lines = f.readlines()\n",
        "  for line in txt_lines:\n",
        "    columns.append(line.strip(\"\\n\"))\n",
        "print(columns[:10])"
      ],
      "metadata": {
        "id": "ux519TA42C41",
        "outputId": "346ccea1-48c2-4c83-a254-6179a18dcdbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cholera due to Vibrio cholerae 01, biovar cholerae', 'Cholera due to Vibrio cholerae 01, biovar eltor', 'Cholera, unspecified', 'Typhoid fever, unspecified', 'Typhoid meningitis', 'Typhoid fever with heart involvement', 'Typhoid pneumonia', 'Typhoid arthritis', 'Typhoid osteomyelitis', 'Typhoid fever with other complications']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_keyword_df = pd.DataFrame(columns, columns=[\"Keyword\"])\n",
        "data_keyword_df.head()"
      ],
      "metadata": {
        "id": "RQPgHDgt26eV",
        "outputId": "ab159751-15a3-4203-d798-6879ea7a0156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Keyword\n",
              "0  Cholera due to Vibrio cholerae 01, biovar chol...\n",
              "1    Cholera due to Vibrio cholerae 01, biovar eltor\n",
              "2                               Cholera, unspecified\n",
              "3                         Typhoid fever, unspecified\n",
              "4                                 Typhoid meningitis"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e245a20-fc23-4fe0-b16a-fcb92730ba11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cholera, unspecified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Typhoid fever, unspecified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Typhoid meningitis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e245a20-fc23-4fe0-b16a-fcb92730ba11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e245a20-fc23-4fe0-b16a-fcb92730ba11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e245a20-fc23-4fe0-b16a-fcb92730ba11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_keyword_df.to_csv(\"icd_10_keywords.csv\", index=False)"
      ],
      "metadata": {
        "id": "-m47_CVP3HVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_code_df = pd.read_csv(\"icd_10_codes.csv\")\n",
        "data_code_df.head()"
      ],
      "metadata": {
        "id": "AUAqEAvPecP-",
        "outputId": "48206952-3c22-49cf-eb5c-d020addd2d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ICD-10\n",
              "0   A00.0\n",
              "1   A00.1\n",
              "2   A00.9\n",
              "3  A01.00\n",
              "4  A01.01"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39ae47b0-3992-48e6-8a94-2bb35002be06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ICD-10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A01.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A01.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39ae47b0-3992-48e6-8a94-2bb35002be06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39ae47b0-3992-48e6-8a94-2bb35002be06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39ae47b0-3992-48e6-8a94-2bb35002be06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_code_df[\"ICD-10\"].head()"
      ],
      "metadata": {
        "id": "grJmbceU8K3U",
        "outputId": "c27c0c48-b139-44a6-bbd3-0d89c5442500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     A00.0\n",
              "1     A00.1\n",
              "2     A00.9\n",
              "3    A01.00\n",
              "4    A01.01\n",
              "Name: ICD-10, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_keyword_df[\"Keyword\"].head()"
      ],
      "metadata": {
        "id": "06UIvEOc8P0o",
        "outputId": "b0bddab4-2cb7-4380-94fa-e085f78a4151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Cholera due to Vibrio cholerae 01, biovar chol...\n",
              "1      Cholera due to Vibrio cholerae 01, biovar eltor\n",
              "2                                 Cholera, unspecified\n",
              "3                           Typhoid fever, unspecified\n",
              "4                                   Typhoid meningitis\n",
              "Name: Keyword, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "icd_code_kerword_df = pd.DataFrame().assign(Code=data_code_df['ICD-10'], Keyword=data_keyword_df['Keyword'])\n",
        "icd_code_kerword_df.head()"
      ],
      "metadata": {
        "id": "B1oG5Eex87Px",
        "outputId": "526d56e4-0005-470c-994c-ccb9aff50090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Code                                            Keyword\n",
              "0   A00.0  Cholera due to Vibrio cholerae 01, biovar chol...\n",
              "1   A00.1    Cholera due to Vibrio cholerae 01, biovar eltor\n",
              "2   A00.9                               Cholera, unspecified\n",
              "3  A01.00                         Typhoid fever, unspecified\n",
              "4  A01.01                                 Typhoid meningitis"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a751550-b1f0-4466-9955-041a61f08a58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00.0</td>\n",
              "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00.1</td>\n",
              "      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00.9</td>\n",
              "      <td>Cholera, unspecified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A01.00</td>\n",
              "      <td>Typhoid fever, unspecified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A01.01</td>\n",
              "      <td>Typhoid meningitis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a751550-b1f0-4466-9955-041a61f08a58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a751550-b1f0-4466-9955-041a61f08a58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a751550-b1f0-4466-9955-041a61f08a58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "icd_code_kerword_df.to_csv(\"icd_10_code_keywords.csv\", index=False)"
      ],
      "metadata": {
        "id": "HqxszJQl5VSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd_code_kerword_df = pd.read_csv(\"icd_10_code_keywords.csv\")\n",
        "icd_code_kerword_df.head()"
      ],
      "metadata": {
        "id": "srh23ng57YkA",
        "outputId": "dac4e717-144a-4ba4-fbf0-1ea20d1e733c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Code                                            Keyword\n",
              "0   A00.0  Cholera due to Vibrio cholerae 01, biovar chol...\n",
              "1   A00.1    Cholera due to Vibrio cholerae 01, biovar eltor\n",
              "2   A00.9                               Cholera, unspecified\n",
              "3  A01.00                         Typhoid fever, unspecified\n",
              "4  A01.01                                 Typhoid meningitis"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-285db3b1-9f33-4536-97af-4ae0059dc733\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00.0</td>\n",
              "      <td>Cholera due to Vibrio cholerae 01, biovar chol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00.1</td>\n",
              "      <td>Cholera due to Vibrio cholerae 01, biovar eltor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00.9</td>\n",
              "      <td>Cholera, unspecified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A01.00</td>\n",
              "      <td>Typhoid fever, unspecified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A01.01</td>\n",
              "      <td>Typhoid meningitis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-285db3b1-9f33-4536-97af-4ae0059dc733')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-285db3b1-9f33-4536-97af-4ae0059dc733 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-285db3b1-9f33-4536-97af-4ae0059dc733');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_icd_code_pattern(icd_code_df, code_type=\"ICD-10\"):\n",
        "  patterns = []\n",
        "  for _, row in icd_code_df.iterrows():\n",
        "\n",
        "    # add default pattern\n",
        "    patterns.append({\"label\": code_type, \"pattern\": row[\"Code\"]})\n",
        "\n",
        "    # create alternate pattern\n",
        "    code_patterns = []\n",
        "    code_arr = row[\"Code\"].split(\".\")\n",
        "    if len(code_arr) > 1:\n",
        "      code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "      code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "      code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "      code4 = f\"{code_arr[0]} {code_arr[1]}\"\n",
        "      code_patterns.extend([code1, code2, code3, code4])\n",
        "      # handle if the first char of code is missing\n",
        "      alphabats = {\"Z\": \"2\", \"B\": \"8\", \"O\": \"0\", \"S\": \"5\", \"l\": \"1\", \"G\": \"6\"}\n",
        "      for key, val in alphabats.items():\n",
        "        if code4.split()[0].startswith(key):\n",
        "          code5 = code4.replace(key, val)\n",
        "          code6 = row[\"Code\"].replace(key, val)\n",
        "          code_patterns.extend([code5, code6])\n",
        "\n",
        "    # handle if the \".\" is missing\n",
        "    if code_type == \"ICD-9\":\n",
        "      code_arr = row[\"Code\"].split(\".\")\n",
        "      if len(code_arr) > 1:\n",
        "        code7 = row[\"Code\"].replace(\".\", \"\")\n",
        "        code_patterns.extend([code7])\n",
        "\n",
        "    for code_pattern in code_patterns:\n",
        "      if len(code_pattern) > 1:\n",
        "        patterns.append({\"label\": code_type, \"pattern\": code_pattern})\n",
        "  return patterns"
      ],
      "metadata": {
        "id": "yi05sg_1sQuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = English()"
      ],
      "metadata": {
        "id": "pVUZeARegXBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd_code_v2_df = pd.read_csv(\"icd_10_codes-v2.csv\")\n",
        "icd_code_v2_df = icd_code_v2_df.drop_duplicates()\n",
        "patterns = make_icd_code_pattern(icd_code_v2_df)\n",
        "\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "ruler.add_patterns(patterns)\n",
        "# save to json file\n",
        "ruler.to_disk(\"./icd10_code_patterns-v2.jsonl\")"
      ],
      "metadata": {
        "id": "C4wrU3gXZsM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.remove_pipe(\"entity_ruler\")"
      ],
      "metadata": {
        "id": "khxdVwhJhVw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "icd9_code_v1_df = pd.read_csv(\"icd_9_codes-v1.csv\")\n",
        "patterns = make_icd_code_pattern(icd9_code_v1_df, \"ICD-9\")\n",
        "\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "ruler.add_patterns(patterns)\n",
        "# save to json file\n",
        "ruler.to_disk(\"./icd9_code_patterns-v1.jsonl\")"
      ],
      "metadata": {
        "id": "3ytvPS3HZ6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##All Steps Together"
      ],
      "metadata": {
        "id": "E3AMzWcDwfYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf txt-files\n",
        "!rm -rf pdf-files"
      ],
      "metadata": {
        "id": "zMdyB9Sed2xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: spliting pdf file\n",
        "pdf_file_name = \"Redacted_Sample.pdf\"\n",
        "pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "# Step-2: Extracting text from pdf\n",
        "txt_list = extract_text_from_pdf(pdf_list)"
      ],
      "metadata": {
        "id": "DMQjPBMmmg6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_list[37]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FjK4LJvxQJVa",
        "outputId": "a6d7b12a-04a1-4509-a438-63be48820f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'txt-files/page-37.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_code = English()\n",
        "# Step-3: loading and updating patterns to Spacy\n",
        "nlp_code.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v2.jsonl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YIqjoZJFuN_",
        "outputId": "f4c06f66-43c8-40a8-c600-83a43ab68ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x7fc6e8554730>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-4: Searching ICD-10 code\n",
        "page_code10_dict = search_icd_code(txt_list, nlp_code)"
      ],
      "metadata": {
        "id": "kesXasexFyTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-5: Creating ICD-10 keyword pattern\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "icd_code_kerword_df = pd.read_csv(\"icd_10_code_keywords.csv\")\n",
        "phrase_matcher = make_icd_keyword_pattern(icd_code_kerword_df, nlp_keyword)"
      ],
      "metadata": {
        "id": "04ubQxu5H-af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-6: Searching ICD-10 keyword\n",
        "page_keyword_dict = search_icd_keyword([\"txt-files/page-37.txt\"], phrase_matcher, nlp_keyword)"
      ],
      "metadata": {
        "id": "pwcPyMofGq_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_keyword_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBCi_F_6TEWb",
        "outputId": "3eefbb1d-50e3-4da2-9475-1d53001b3093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{37: {'Decreased white blood cell count. unspecified',\n",
              "  'Migraine with aura, not intractable, without status migrainosus',\n",
              "  'Palpitations',\n",
              "  'lipomatosis, not elsewhere classified',\n",
              "  'lower abdominal pain, unspecified',\n",
              "  'overweight',\n",
              "  'pain, unspecified'}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_list = [list(element.keys())[0] for element in json_arr]"
      ],
      "metadata": {
        "id": "lTzbG-ffVxTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlwjj4swYNF2",
        "outputId": "d81bf805-bb1d-47a9-8a60-92c99c36ad0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['migraine with aura, not intractable, without status migrainosus',\n",
              " 'decreased white blood cell count, unspecified',\n",
              " 'polpitations',\n",
              " 'lower abdominal pain, unspecified',\n",
              " 'pain, unspecified',\n",
              " 'lipamatosis, not elsewhere classified',\n",
              " 'overweight',\n",
              " 'overweight']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page_keyword_dict2 = {\"37\": set(wrong_keyword_list)}\n",
        "page_keyword_dict2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzbiNX_8YaiG",
        "outputId": "075413a8-7d2e-4131-85b9-0bc9c7390d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'37': {'decreased white blood cell count, unspecified',\n",
              "  'lipamatosis, not elsewhere classified',\n",
              "  'lower abdominal pain, unspecified',\n",
              "  'migraine with aura, not intractable, without status migrainosus',\n",
              "  'overweight',\n",
              "  'pain, unspecified',\n",
              "  'polpitations'}}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-7: Highlighting ICD-10 code and keyword into pdf\n",
        "output_file_name = highlight_icd_code_and_keyword(page_code10_dict, page_keyword_dict, pdf_file_name, code_type=\"ICD-10\")\n",
        "print(f\"File[{output_file_name}] is saved after highlighting ICD-10 code and keyword\")"
      ],
      "metadata": {
        "id": "opP1NnZjG5c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908c7545-41de-4cda-e893-cc6f48b20768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File[('9929_final_output_output.pdf', '9929_final_output_cords.txt')] is saved after highlighting ICD-10 code and keyword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_code.remove_pipe(\"entity_ruler\")\n",
        "del icd_code_kerword_df\n",
        "del page_code10_dict"
      ],
      "metadata": {
        "id": "mX2qzs8MlE7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-8: loading and updating patterns to Spacy\n",
        "nlp_code.add_pipe(\"entity_ruler\").from_disk(\"./icd9_code_patterns-v1.jsonl\")"
      ],
      "metadata": {
        "id": "zF-X9z7DlFNX",
        "outputId": "74582e16-54a9-4797-ef64-3f425f0f05b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x7fc6de1db230>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-9: Searching ICD-9 code\n",
        "page_code9_dict = search_icd_code(txt_list, nlp_code, code_type=\"ICD-9\")\n",
        "\n",
        "# Step-10: Highlighting ICD-9 code into pdf\n",
        "output_file_name = highlight_icd_code_and_keyword(page_code9_dict, page_keyword_dict, output_file_name[0], code_type=\"ICD-9\")\n",
        "print(f\"File[{output_file_name}] is saved after highlighting ICD-9 code\")"
      ],
      "metadata": {
        "id": "J2TIZ3hGlyV4",
        "outputId": "aea23a98-2a05-48c7-81db-cbd8721bed49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File[('9929_final_output_output_output.pdf', '9929_final_output_output_cords.txt')] is saved after highlighting ICD-9 code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -czvf text_files.tar.gz txt-files/"
      ],
      "metadata": {
        "id": "nGVt78Lvo3eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Highlight Multiple Files"
      ],
      "metadata": {
        "id": "fm-TqEVY04Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Load icd_10_code_keywords.csv file\n",
        "icd_code_kerword_df = pd.read_csv(\"icd_10_code_keywords.csv\")\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v2.jsonl\")\n",
        "\n",
        "# loading and updating patterns for ICD-9 code\n",
        "nlp_code9 = English()\n",
        "nlp_code9.add_pipe(\"entity_ruler\").from_disk(\"./icd9_code_patterns-v1.jsonl\")\n",
        "\n",
        "# Creating ICD-10 keyword pattern\n",
        "phrase_matcher = make_icd_keyword_pattern(icd_code_kerword_df, nlp_keyword)"
      ],
      "metadata": {
        "id": "3LTzxEOwwEmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "ocr_pdf_files_path = \"ocr-pdf-files\"\n",
        "for pdf_file in os.listdir(ocr_pdf_files_path):\n",
        "  pdf_file_name = f\"{ocr_pdf_files_path}/{pdf_file}\"\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = extract_text_from_pdf(pdf_list)\n",
        "  print(txt_list[:5])\n",
        "\n",
        "  # Step-3: Searching ICD-10 code\n",
        "  page_code_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")\n",
        "\n",
        "  # Step-4: Searching ICD-10 keyword\n",
        "  page_keyword_dict = search_icd_keyword(txt_list, phrase_matcher, nlp_keyword)\n",
        "\n",
        "  # Step-7: Highlighting ICD-10 code and keyword into pdf\n",
        "  pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(page_code_dict, page_keyword_dict, pdf_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # Step-8: Searching ICD-9 code\n",
        "  page_code9_dict = search_icd_code(txt_list, nlp_code9, code_type=\"ICD-9\")\n",
        "\n",
        "  # Step-9: Highlighting ICD-9 code into pdf\n",
        "  output_file_name = highlight_icd_code_and_keyword(page_code9_dict, page_keyword_dict, pdf_output_file, code_type=\"ICD-9\")\n",
        "  print(f\"File[{output_file_name}] is saved after highlighting ICD-9 code\")\n",
        "\n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "id": "gFB8U-iuwHmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ocr-pdf-files"
      ],
      "metadata": {
        "id": "87XG3Zco6pgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ocr-pdf-files"
      ],
      "metadata": {
        "id": "xqPuHBu27A6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"ocr-pdf-files/*.txt\")\n",
        "purge(\"ocr-pdf-files/*_output.pdf\")\n",
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "MNX8Rr_3Iu8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip ocr-pdf-files/*_output_cords.txt ocr-pdf-files/*_output_output.pdf"
      ],
      "metadata": {
        "id": "FKU4QnzLI_yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output_txt_pdf_files.zip pdf-files/* txt-files/*"
      ],
      "metadata": {
        "id": "bOqazGWJaSXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Extraction"
      ],
      "metadata": {
        "id": "4jNiyAoTHd2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pdf(pdf_path, pdf_file_name):\n",
        "  pdf_in_file = open(pdf_path, \"rb\")\n",
        "  pdf = PdfFileReader(pdf_in_file)\n",
        "  pdf_list = []\n",
        "  for page in range(pdf.numPages):\n",
        "      inputpdf = PdfFileReader(pdf_in_file)\n",
        "      output = PdfFileWriter()\n",
        "      output.addPage(inputpdf.getPage(page))\n",
        "      with open(f\"{pdf_files_path}/{pdf_file_name}-{page}.pdf\", \"wb\") as outputStream:\n",
        "          output.write(outputStream)\n",
        "          pdf_list.append(f\"{pdf_file_name}-{page}.pdf\")\n",
        "  return pdf_list\n",
        "\n",
        "def extract_text_from_pdf(pdf_list, file_name):\n",
        "  txt_file_list = []\n",
        "  i = 0\n",
        "  for pdf_file in pdf_list:\n",
        "    with open(os.path.join(pdf_files_path, pdf_file), \"rb\") as f:\n",
        "      pdf = pdftotext.PDF(f)\n",
        "    \n",
        "    # Read all the text into one string\n",
        "    pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "    # write text into file\n",
        "    with open(f\"{txt_files_path}/{file_name}-{str(i)}.txt\", \"a\") as f:\n",
        "      f.write(pdf_text)\n",
        "    txt_file_list.append(f\"{txt_files_path}/{file_name}-{str(i)}.txt\")\n",
        "    i += 1\n",
        "  return txt_file_list"
      ],
      "metadata": {
        "id": "62ByvN_WDnyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ocr_pdf_files_path = \"ocr-pdf-files\"\n",
        "for pdf_file in os.listdir(ocr_pdf_files_path):\n",
        "  pdf_file_path = f\"{ocr_pdf_files_path}/{pdf_file}\"\n",
        "  file_name = pdf_file.split(\".\")[0]\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = split_pdf(pdf_file_path, file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = extract_text_from_pdf(pdf_list, file_name)"
      ],
      "metadata": {
        "id": "xk97gLDZDr2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output_txt_pdf_files.zip pdf-files/* txt-files/*"
      ],
      "metadata": {
        "id": "pDmQG4eJHjg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spacy"
      ],
      "metadata": {
        "id": "h2vdAgn-5nd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\"\"\"\n",
        "Graham Greene is his favorite author. He wrote his first book when he was a hundred and fifty years old.\n",
        "While writing this book, he had to fend off aliens and dinosaurs. Greene's second book might not have been written by him. \n",
        "Greene's cat in its deathbed testimony alleged that it was the original writer of the book. The fact that plot of the book revolves around \n",
        "rats conquering the world, lends credence to the idea that only a cat could have been the true writer of such an inane book.\"\"\")\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = [{\"LEMMA\": \"write\"},{\"OP\": \"*\"},{\"LEMMA\": \"book\"}]\n",
        "matcher.add(\"testy\", [pattern])\n",
        "\n",
        "print(\"----- Using Matcher -----\")\n",
        "for sent in doc.sents:\n",
        "    if matcher(sent):\n",
        "        print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSaoBF7n5ohe",
        "outputId": "0249955c-b76e-4b22-f342-2920adc5895b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Using Matcher -----\n",
            "He wrote his first book when he was a hundred and fifty years old.\n",
            "\n",
            "While writing this book, he had to fend off aliens and dinosaurs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- Using Dependency Matcher -----\")\n",
        "\n",
        "deppattern = [\n",
        "        {\"RIGHT_ID\": \"wrote\", \"RIGHT_ATTRS\": {\"LEMMA\": \"write\"}},\n",
        "        {\"LEFT_ID\": \"wrote\", \"REL_OP\": \">\", \"RIGHT_ID\": \"book\", \n",
        "            \"RIGHT_ATTRS\": {\"LEMMA\": \"book\"}}\n",
        "        ]\n",
        "\n",
        "from spacy.matcher import DependencyMatcher\n",
        "\n",
        "dmatcher = DependencyMatcher(nlp.vocab)\n",
        "\n",
        "dmatcher.add(\"BOOK\", [deppattern])\n",
        "\n",
        "for _, (start, end) in dmatcher(doc):\n",
        "    print(doc[start].sent)"
      ],
      "metadata": {
        "id": "EYC0Vtcq53Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regex = re.compile('[@_!#$%^&*()<>?/\\|}{~:.,]')\n",
        "True if(regex.search(\"Decreased white blood cell count, unspecified\") == None) else False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo4pWCXS8I0_",
        "outputId": "fc669694-9175-49ae-bbcb-6f4fe9dcdc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"The United States of America (USA) are commonly known as the United States (U.S. or US) or America.\")\n",
        "\n",
        "expression = r\"[Uu](nited|\\.?) ?[Ss](tates|\\.?)\"\n",
        "for match in re.finditer(expression, doc.text):\n",
        "    start, end = match.span()\n",
        "    span = doc.char_span(start, end)\n",
        "    # This is a Span object or None if match doesn't map to valid token sequence\n",
        "    if span is not None:\n",
        "        print(\"Found match:\", span.text)"
      ],
      "metadata": {
        "id": "VYbV4Db18rMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"The United States of America (USA) are commonly known as the United States (U.S. or US) or America.\")\n",
        "\n",
        "expression = r\"[Uu](nited|\\.?) ?[Ss](tates|\\.?)\"\n",
        "for match in re.finditer(expression, doc.text):\n",
        "    start, end = match.span()\n",
        "    span = doc.char_span(start, end)\n",
        "    # This is a Span object or None if match doesn't map to valid token sequence\n",
        "    if span is not None:\n",
        "        print(\"Found match:\", span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Yw0Hz17_Ta",
        "outputId": "e4ca5c80-9534-422f-db54-76a2e7a7ae83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found match: United States\n",
            "Found match: United States\n",
            "Found match: U.S.\n",
            "Found match: US\n"
          ]
        }
      ]
    }
  ]
}