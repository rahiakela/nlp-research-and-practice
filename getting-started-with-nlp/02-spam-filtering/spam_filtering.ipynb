{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjevF0BkuNqh8rikE8DEcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/getting-started-with-nlp/02-spam-filtering/spam_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spam Filtering"
      ],
      "metadata": {
        "id": "ilWdBgYCz8KE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to build a machine-learning classifier for spam detection, you need to provide\n",
        "your algorithm with a sufficient number of spam and ham emails. \n",
        "\n",
        "The best way to\n",
        "build such a classifier would be to collect your own ham and spam emails and train your algorithm to detect what you personally would consider spam."
      ],
      "metadata": {
        "id": "8vVxjDhy0A00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "USwamjfy0T2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import codecs\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk import NaiveBayesClassifier, classify\n",
        "from nltk.text import Text"
      ],
      "metadata": {
        "id": "FBFe1hBd0X7v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "wget https://github.com/rahiakela/nlp-research-and-practice/raw/main/getting-started-with-nlp/datasets/enron1.zip\n",
        "\n",
        "unzip enron1.zip\n",
        "rm -rf enron1.zip"
      ],
      "metadata": {
        "id": "VTalOqPc3qXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Define the data and classes"
      ],
      "metadata": {
        "id": "tqf8dwe-0q3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_in(folder):\n",
        "  files = os.listdir(folder)\n",
        "  a_list = []\n",
        "  for a_file in files:\n",
        "    # skip hidden files\n",
        "    if not a_file.startswith(\".\"):\n",
        "      # Read the contents of each files\n",
        "      f = codecs.open(folder + a_file, \"r\", encoding=\"ISO-8859-1\", errors=\"ignore\")\n",
        "      a_list.append(f.read())\n",
        "      f.close()\n",
        "  return a_list"
      ],
      "metadata": {
        "id": "3uCOA4gQ0spl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify that the data is uploaded and read in correctly\n",
        "spam_list = read_in(\"enron1/spam/\")\n",
        "print(len(spam_list))\n",
        "print(spam_list[0])"
      ],
      "metadata": {
        "id": "bDUUrvoY82dn",
        "outputId": "9a0d9e51-7e6f-40cc-999d-6426f384e747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500\n",
            "Subject: check it out\r\n",
            "Hello,\r\n",
            "If you want that roooock harrrrd john son\r\n",
            "Check out the first and original one on the market... Don' t be fooled by imitations and copy - cats.\r\n",
            "Later,\r\n",
            "Jordan\r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ham_list = read_in(\"enron1/ham/\")\n",
        "print(len(ham_list))\n",
        "print(ham_list[0])"
      ],
      "metadata": {
        "id": "O7dB9cWK9z6I",
        "outputId": "b460349a-146b-4e19-dc64-b840c4978409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3672\n",
            "Subject: natural gas nomination for december 2000 - - r e v I s I o n #2\r\n",
            "Please revise the natural gas nomination for the mtbe plant for december 2000\r\n",
            "As follows:\r\n",
            "10, 500 mmbtu for the entire month of december.\r\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by michael mitcham/gpgfin/enron on\r\n",
            "11/29/2000 08: 43 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n",
            "Maritta mullet\r\n",
            "11/27/2000 05: 08 pm\r\n",
            "To: david bush/ecf/enron@ enron, mark diedrich/gpgfin/enron@ enron, steven m\r\n",
            "Elliott/hou/ect@ ect, daren j farmer/hou/ect@ ect, paul fox/ecf/enron@ enron,\r\n",
            "David m johnson/ecf/enron@ enron, robert e lee/hou/ect@ ect, anita\r\n",
            "Luong/hou/ect@ ect, gregg lenart/hou/ect@ ect, thomas meers/gpgfin/enron@ enron,\r\n",
            "Michael mitcham/gpgfin/enron@ enron, john l nowlan/hou/ect@ ect, lee l\r\n",
            "Papayoti/hou/ect@ ect, james prentice/gpgfin/enron@ enron, kerry\r\n",
            "Roper/gpgfin/enron@ enron, sally shuler/gpgfin/enron@ enron\r\n",
            "Cc:\r\n",
            "Subject: natural gas nomination for december 2000 - - r e v I s I o n\r\n",
            "Please revise the natural gas nomination for the mtbe plant for december 2000\r\n",
            "As follows:\r\n",
            "10, 000 mmbtu for the first 15 days of the month\r\n",
            "2, 000 mmbut for the last half of the month\r\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by maritta mullet/gpgfin/enron on 11/27/2000\r\n",
            "05: 01 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n",
            "Maritta mullet\r\n",
            "11/27/2000 04: 44 pm\r\n",
            "To: david bush/ecf/enron@ enron, mark diedrich/gpgfin/enron@ enron, steven m\r\n",
            "Elliott/hou/ect@ ect, daren j farmer/hou/ect@ ect, paul fox/ecf/enron@ enron,\r\n",
            "David m johnson/ecf/enron@ enron, robert e lee/hou/ect@ ect, anita\r\n",
            "Luong/hou/ect@ ect, gregg lenart/hou/ect@ ect, thomas meers/gpgfin/enron@ enron,\r\n",
            "Michael mitcham/gpgfin/enron@ enron, john l nowlan/hou/ect@ ect, lee l\r\n",
            "Papayoti/hou/ect@ ect, james prentice/gpgfin/enron@ enron, kerry\r\n",
            "Roper/gpgfin/enron@ enron, sally shuler/gpgfin/enron@ enron\r\n",
            "Cc:\r\n",
            "Subject: natural gas nomination for december 2000\r\n",
            "Enron methanol nominates the following natural gas requirements for the\r\n",
            "Methanol plant for december 2000:\r\n",
            "33, 000 mmbtu per day\r\n",
            "Egpfc nominates the following natural gas requirements for the mtbe plant at\r\n",
            "Morgan' s point for december 2000:\r\n",
            "12, 000 mmbtu per day for the first 15 days of the month. None for the last\r\n",
            "Half of the month. Mtbe plant will be down after december 15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "# combine the data into a single structure\n",
        "all_emails = [(email_content, \"spam\") for email_content in spam_list]\n",
        "all_emails += [(email_content, \"ham\") for email_content in ham_list]\n",
        "\n",
        "random.shuffle(all_emails)\n",
        "print(f\"Dataset size = {str(len(all_emails))} emails\")"
      ],
      "metadata": {
        "id": "yoFbLrke-Kvp",
        "outputId": "3f601483-9c3e-4f35-ee54-f814445107b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size = 5172 emails\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Split the text into words"
      ],
      "metadata": {
        "id": "kvIEDQjB-K4N"
      }
    }
  ]
}