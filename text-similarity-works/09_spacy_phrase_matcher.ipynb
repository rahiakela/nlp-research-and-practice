{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNlKYfQbWUqjHqVIKsYpHNm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-research-and-practice/blob/main/text-similarity-works/09_spacy_phrase_matcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "73ORkeFzaRA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "[Rule-based entity recognition](https://spacy.io/usage/rule-based-matching#entityruler)"
      ],
      "metadata": {
        "id": "nAkX90V5vVML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "Ti6ZynbyaR9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just restart the colab environment."
      ],
      "metadata": {
        "id": "EIvuMvZfuhfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "\n",
        "import pdb\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.lang.en import English\n",
        "from spacy.language import Language\n",
        "from spacy.tokens import Span\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "import nltk"
      ],
      "metadata": {
        "id": "fAcHTn0JaM2S"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Efficient phrase matching"
      ],
      "metadata": {
        "id": "VgfMg5wIkc9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = PhraseMatcher(nlp.vocab)"
      ],
      "metadata": {
        "id": "qifnx1bq4aw0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms = [\"Barack Obama\", \"Angela Merkel\", \"Washington, D.C.\"]\n",
        "\n",
        "patterns = [nlp.make_doc(text) for text in terms]\n",
        "matcher.add(\"TerminologyList\", patterns)"
      ],
      "metadata": {
        "id": "pBoFg_MEFn8w"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"German Chancellor Angela Merkel and US President Barack Obama converse in the Oval Office inside the White House in Washington, D.C.\")\n",
        "matches = matcher(doc)"
      ],
      "metadata": {
        "id": "FmfCmxNkGEfZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for match_id, start, end in matches:\n",
        "  span = doc[start: end]\n",
        "  print(span.text)"
      ],
      "metadata": {
        "id": "OCg5Qps0PAaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c8ab44-7b3b-40c4-d01a-fe80dcc29f42"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Angela Merkel\n",
            "Barack Obama\n",
            "Washington, D.C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matched based on lowercase token\n",
        "nlp = English()\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "patterns = [nlp.make_doc(name) for name in [\"Angela Merkel\", \"Barack Obama\"]]\n",
        "matcher.add(\"Names\", patterns)"
      ],
      "metadata": {
        "id": "BWtYWxe_G22U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"angela merkel and us president barack Obama\")\n",
        "\n",
        "for match_id, start, end in matcher(doc):\n",
        "  print(\"Matched based on lowercase token text:\", doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl2Nm2D4G4AK",
        "outputId": "42898b04-7674-43b7-9c5d-55c37100bbf6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched based on lowercase token text: angela merkel\n",
            "Matched based on lowercase token text: barack Obama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/67906945/valueerror-nlp-add-pipe-now-takes-the-string-name-of-the-registered-component-f\n",
        "\n",
        "https://stackoverflow.com/questions/57187116/how-to-modify-spacy-tokens-doc-doc-tokens-with-pipeline-components-in-spacy"
      ],
      "metadata": {
        "id": "KlU85eM5xcz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matched based on lowercase token\n",
        "nlp = English()\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "terms = [\"Barack Obama\", \"Angela Merkel\", \"Washington D C\"]\n",
        "\n",
        "patterns = [nlp.make_doc(text) for text in terms]\n",
        "matcher.add(\"TerminologyList\", patterns)\n",
        "\n",
        "@Language.component(\"custom_matcher\")\n",
        "def extract_person_orgs(doc):\n",
        "  token_list = []\n",
        "  for index, token in enumerate(doc):\n",
        "    # skip the loop if token contains \".\" or \",\"\n",
        "    if token.text == '.' or token.text == ',':\n",
        "      continue\n",
        "\n",
        "    if \".\" in token.text:\n",
        "      #print(token.text)\n",
        "      token_list.append(token.text.replace(\".\", \"\"))\n",
        "    else:\n",
        "      token_list.append(token.text)\n",
        "  #print(token_list)\n",
        "  new_doc = Doc(doc.vocab, words=token_list)\n",
        "  return new_doc\n",
        "\n",
        "nlp.add_pipe(\"custom_matcher\")"
      ],
      "metadata": {
        "id": "wqGGdMRbRe-i",
        "outputId": "4db0bb70-6917-46e7-a6e6-3fe3ed2ca2df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.extract_person_orgs(doc)>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"German Chancellor Angela Merkel and US President Barack, Obama converse in the Oval Office inside the White House in Washington, D. C.\")\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "  span = doc[start: end]\n",
        "  print(span.text)"
      ],
      "metadata": {
        "id": "ijP9-DUZRzQD",
        "outputId": "db30c96f-79cf-4bc7-f1f1-82437bd4d7b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Angela Merkel\n",
            "Barack Obama\n",
            "Washington D C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = English()\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
        "matcher.add(\"IP\", [nlp(\"127.0.0.1\"), nlp(\"127.127.0.0\")])"
      ],
      "metadata": {
        "id": "6GEv7R4RL0lc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Often the router will have an IP address such as 192.168.1.1 or 192.168.2.1.\")\n",
        "for match_id, start, end in matcher(doc):\n",
        "  print(\"Matched based on token shape:\", doc[start:end])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqmy-5AOL09_",
        "outputId": "272a7949-f1ab-4c28-d69d-632c61c9fa28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched based on token shape: 192.168.1.1\n",
            "Matched based on token shape: 192.168.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Span ruler"
      ],
      "metadata": {
        "id": "7c5h3NWBORxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "ruler = nlp.add_pipe(\"span_ruler\")\n",
        "patterns = [\n",
        "  {\"label\": \"ORG\", \"pattern\": \"Apple\"},\n",
        "  {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}\n",
        "]\n",
        "ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "l2y7GVHFOTcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Apple is opening its first big office in San Francisco.\")\n",
        "print([(span.text, span.label_) for span in doc.spans[\"ruler\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BQkTDnsOZtb",
        "outputId": "78231b34-3ea8-45b6-84eb-1409bda47978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Apple', 'ORG'), ('San Francisco', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# only annotate doc.ents, not doc.spans\n",
        "config = {\"spans_key\": None, \"annotate_ents\": True, \"overwrite\": False}\n",
        "\n",
        "ruler = nlp.add_pipe(\"span_ruler\", config=config)\n",
        "patterns = [{\"label\": \"ORG\", \"pattern\": \"MyCorp Inc.\"}]\n",
        "ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "goqep_RPOsyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"MyCorp Inc. is a company in the U.S.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX52KbvuOyrJ",
        "outputId": "ea79b0ec-692b-49b9-f6ef-a89d60563ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('MyCorp Inc.', 'ORG'), ('U.S.', 'GPE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Expanding named entities"
      ],
      "metadata": {
        "id": "hxU5gDDfTW_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Dr. Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "eERbLASiTXu8",
        "outputId": "aae633f4-aa6b-4550-fc9f-34ea4b7f759a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Alex Smith', 'PERSON'), ('first', 'ORDINAL'), ('Acme Corp Inc.', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "@Language.component(\"expand_person_entities\")\n",
        "def expand_person_entities(doc):\n",
        "    new_ents = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\" and ent.start != 0:\n",
        "            prev_token = doc[ent.start - 1]\n",
        "            if prev_token.text in (\"Dr\", \"Dr.\", \"Mr\", \"Mr.\", \"Ms\", \"Ms.\"):\n",
        "                new_ent = Span(doc, ent.start - 1, ent.end, label=ent.label)\n",
        "                new_ents.append(new_ent)\n",
        "        else:\n",
        "            new_ents.append(ent)\n",
        "    doc.ents = new_ents\n",
        "    return doc\n",
        "\n",
        "# Add the component after the named entity recognizer\n",
        "nlp.add_pipe(\"expand_person_entities\", after=\"ner\")\n",
        "\n",
        "doc = nlp(\"Dr. Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "cPuhNqtZThG9",
        "outputId": "412d055f-6129-483c-8cff-a2c388e0ddc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Dr. Alex Smith', 'PERSON'), ('first', 'ORDINAL'), ('Acme Corp Inc.', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_person_title(span):\n",
        "    if span.label_ == \"PERSON\" and span.start != 0:\n",
        "        prev_token = span.doc[span.start - 1]\n",
        "        if prev_token.text in (\"Dr\", \"Dr.\", \"Mr\", \"Mr.\", \"Ms\", \"Ms.\"):\n",
        "            return prev_token.text\n",
        "\n",
        "# Register the Span extension as 'person_title'\n",
        "Span.set_extension(\"person_title\", getter=get_person_title)\n",
        "\n",
        "doc = nlp(\"Dr Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
        "print([(ent.text, ent.label_, ent._.person_title) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "EXoT73n2UD87",
        "outputId": "afbd936d-9337-4614-d008-cd37ac52767f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Alex Smith', 'PERSON', 'Dr'), ('first', 'ORDINAL', None), ('Acme Corp Inc.', 'ORG', None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Alex Smith worked at Acme Corp Inc.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "q23OUlwEUext",
        "outputId": "92fb7d43-5217-47b9-cd10-e3a886e17804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Alex Smith', 'PERSON'), ('Acme Corp Inc.', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "@Language.component(\"extract_person_orgs\")\n",
        "def extract_person_orgs(doc):\n",
        "    person_entities = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "    for ent in person_entities:\n",
        "        head = ent.root.head\n",
        "        if head.lemma_ == \"work\":\n",
        "            preps = [token for token in head.children if token.dep_ == \"prep\"]\n",
        "            for prep in preps:\n",
        "                orgs = [token for token in prep.children if token.ent_type_ == \"ORG\"]\n",
        "                print({'person': ent, 'orgs': orgs, 'past': head.tag_ == \"VBD\"})\n",
        "    return doc\n",
        "\n",
        "# To make the entities easier to work with, we'll merge them into single tokens\n",
        "nlp.add_pipe(\"merge_entities\")\n",
        "nlp.add_pipe(\"extract_person_orgs\")\n",
        "\n",
        "doc = nlp(\"Alex Smith worked at Acme Corp Inc.\")\n",
        "# If you're not in a Jupyter / IPython environment, use displacy.serve\n",
        "displacy.render(doc, options={\"fine_grained\": True})"
      ],
      "metadata": {
        "id": "Tj9lZMFWUjCB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}