{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-understanding-sentiment-using-glove-based-transfer-learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMcfw7jUlDy+YWeV4nmXeLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/advanced-natural-language-processing-with-tensorflow-2/blob/main/4-transfer-learning/1_understanding_sentiment_using_glove_based_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZQmMt3biyFJ"
      },
      "source": [
        "##Understanding Sentiment using GloVe based transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2oEUmwSjwFy"
      },
      "source": [
        "We have used BiLSTM model to predict the sentiment of IMDb movie reviews. That model learned embeddings of the words from scratch. This model had an accuracy of `83.55%` on the test set, while the SOTA result was closer to `97.4%`. If pre-trained embeddings are used, we expect an increase in model accuracy. \n",
        "\n",
        "After all the setup is completed, we will need to use TensorFlow to use these pre-trained embeddings. There will be two different models that will be tried – \n",
        "- the first will be based on feature extraction\n",
        "- the second one on fine-tuning\n",
        "\n",
        "Let's try this out and see the impact of transfer learning on this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAlD10-fkC9C"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u34tQYtIkEHv",
        "outputId": "002e1b4e-5bcb-4a6e-a238-6c719b8f52d7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hjVwYZ7kTr1",
        "outputId": "60022feb-1011-4563-e6ab-dea919965ed4"
      },
      "source": [
        "######## GPU CONFIGS FOR RTX 2070 ###############\n",
        "## Please ignore if not training on GPU       ##\n",
        "## this is important for running CuDNN on GPU ##\n",
        "\n",
        "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
        "\n",
        "# chck if GPU can be seen by TF\n",
        "tf.config.list_physical_devices('GPU')\n",
        "# only if you want to see how commands are executed\n",
        "#tf.debugging.set_log_device_placement(True)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "###############################################"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LojXqIvwhSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88decf5e-c4d1-4485-cead-8e56aa92caf1"
      },
      "source": [
        "# Download the GloVe embeddings\n",
        "!wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpQRIAuqklY1"
      },
      "source": [
        "##Loading IMDb training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_KDedC2kmPN"
      },
      "source": [
        "TensorFlow Datasets or the tfds package will be used to load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_KrBaGTkqro"
      },
      "source": [
        "imdb_train, ds_info = tfds.load(name=\"imdb_reviews\", split=\"train\", with_info=True, as_supervised=True)\n",
        "imdb_test = tfds.load(name=\"imdb_reviews\", split=\"test\", as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUvRVMTVm8qc",
        "outputId": "20d161bf-900a-49fa-c9ea-870235d32032"
      },
      "source": [
        "# Check label and example from the dataset\n",
        "for example, label in imdb_train.take(1):\n",
        "  print(example, \"\\n\", label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string) \n",
            " tf.Tensor(0, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmIXaviKnVri"
      },
      "source": [
        "## Create Vocab and Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2LLB3egnYBI"
      },
      "source": [
        "After the training and test sets are loaded, the content of the reviews needs to be tokenized and encoded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ_r73znnK50"
      },
      "source": [
        "# Use the default tokenizer settings\n",
        "tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "MAX_TOKENS = 0\n",
        "\n",
        "for example, label in imdb_train:\n",
        "  some_tokens = tokenizer.tokenize(example.numpy())\n",
        "  if MAX_TOKENS < len(some_tokens):\n",
        "    MAX_TOKENS = len(some_tokens)\n",
        "  vocabulary_set.update(some_tokens)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1OrV8IVobgq"
      },
      "source": [
        "We tokenizes the review text and constructs a vocabulary.\n",
        "This vocabulary is used to construct a tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXZQEDpQodFR",
        "outputId": "0769ac7c-51bc-4a05-bc4f-88f682ecec5f"
      },
      "source": [
        "imdb_encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set, lowercase=True, tokenizer=tokenizer)\n",
        "vocab_size = imdb_encoder.vocab_size\n",
        "\n",
        "print(vocab_size, MAX_TOKENS)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93931 2525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykT8a-7Fp_6L"
      },
      "source": [
        "Note that text was converted to lowercase before encoding. Converting to lowercase helps reduce the vocabulary size and may benefit the lookup of corresponding GloVe vectors. Note that capitalization may contain important information, which may help in tasks such as NER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnH7YoWjpt05",
        "outputId": "b3c71d8d-6aa5-46c6-ff1c-c5a331aed01f"
      },
      "source": [
        "# Lets verify tokenization and encoding works\n",
        "for example, label in imdb_train.take(1):\n",
        "  print(example, \"\\n\")\n",
        "  encoded = imdb_encoder.encode(example.numpy())\n",
        "  print(encoded, \"\\n\")\n",
        "  print(imdb_encoder.decode(encoded))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string) \n",
            "\n",
            "[86177, 89394, 73061, 91286, 76833, 52975, 92482, 77926, 81313, 47931, 50833, 87357, 39669, 55642, 58216, 70872, 26279, 66569, 67553, 61135, 36349, 67298, 86177, 87366, 93137, 81313, 85321, 85064, 75702, 50833, 69588, 84506, 85321, 61135, 66611, 67110, 90748, 49141, 86177, 52975, 19425, 34475, 43864, 86177, 52975, 93344, 73061, 67875, 32163, 77808, 54259, 63289, 50675, 82410, 74436, 61608, 92902, 55146, 78727, 50675, 70772, 67144, 92902, 63859, 85321, 76744, 89747, 92004, 82905, 66220, 69586, 90729, 47145, 79746, 88609, 89738, 71321, 90849, 79918, 55642, 89394, 37816, 67298, 92100, 74436, 81142, 36699, 50833, 92100, 52975, 82472, 89394, 91204, 91949, 42556, 61655, 49910, 16821, 48402, 8531, 82472, 63124, 67553, 50804, 46331, 86177, 84836, 91261, 19425, 46331, 39669, 55642, 19425, 86382, 53732, 16821, 67110, 77365, 64766, 90279, 75708] \n",
            "\n",
            "this was an absolutely terrible movie don t be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movie s ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revolutions maria conchita alonso appeared phony and her pseudo love affair with walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning i am disappointed that there are movies like this ruining actor s like christopher walken s good name i could barely sit through it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UneWjRGgtE-u"
      },
      "source": [
        "Now that the tokenizer is ready, the data needs to be tokenized, and sequences\n",
        "padded to a maximum length. Since we are interested in comparing performance\n",
        "with the previosly trained model,we can use the same setting of sampling a maximum of 150 words of the review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JexztWE6rYW5"
      },
      "source": [
        "# transformation functions to be used with the dataset\n",
        "def encode_pad_transform(sample):\n",
        "  encoded = imdb_encoder.encode(sample.numpy())\n",
        "  pad = sequence.pad_sequences([encoded], padding=\"post\", maxlen=150)\n",
        "\n",
        "  return np.array(pad[0], dtype=np.int64)\n",
        "\n",
        "def encode_tf_fn(sample, label):\n",
        "  encoded = tf.py_function(encode_pad_transform, inp=[sample], Tout=(tf.int64))\n",
        "  encoded.set_shape([None])\n",
        "  label.set_shape([])\n",
        "\n",
        "  return encoded, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P-20m9YuJWH"
      },
      "source": [
        "# test the transformation on a small subset\n",
        "subset = imdb_train.take(10)\n",
        "tst = subset.map(encode_tf_fn)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj_T4RM2ufAT",
        "outputId": "70ca3033-f061-4039-a91f-b5a90a9f9005"
      },
      "source": [
        "for review, label in tst.take(1):\n",
        "  print(review, label)\n",
        "  print(\"\\n\", imdb_encoder.decode(review))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[86177 89394 73061 91286 76833 52975 92482 77926 81313 47931 50833 87357\n",
            " 39669 55642 58216 70872 26279 66569 67553 61135 36349 67298 86177 87366\n",
            " 93137 81313 85321 85064 75702 50833 69588 84506 85321 61135 66611 67110\n",
            " 90748 49141 86177 52975 19425 34475 43864 86177 52975 93344 73061 67875\n",
            " 32163 77808 54259 63289 50675 82410 74436 61608 92902 55146 78727 50675\n",
            " 70772 67144 92902 63859 85321 76744 89747 92004 82905 66220 69586 90729\n",
            " 47145 79746 88609 89738 71321 90849 79918 55642 89394 37816 67298 92100\n",
            " 74436 81142 36699 50833 92100 52975 82472 89394 91204 91949 42556 61655\n",
            " 49910 16821 48402  8531 82472 63124 67553 50804 46331 86177 84836 91261\n",
            " 19425 46331 39669 55642 19425 86382 53732 16821 67110 77365 64766 90279\n",
            " 75708     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0], shape=(150,), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
            "\n",
            " this was an absolutely terrible movie don t be lured in by christopher walken or michael ironside both are great actors but this must simply be their worst role in history even their great acting could not redeem this movie s ridiculous storyline this movie is an early nineties us propaganda piece the most pathetic scenes were those when the columbian rebels were making their cases for revolutions maria conchita alonso appeared phony and her pseudo love affair with walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning i am disappointed that there are movies like this ruining actor s like christopher walken s good name i could barely sit through it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2f269CWu9JF"
      },
      "source": [
        "Finally, the data is encoded using the convenience functions above like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv1MIsBxuyUG"
      },
      "source": [
        "# now tokenize/encode/pad all training and testing data\n",
        "encoded_train = imdb_train.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "encoded_test = imdb_test.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsG9s3dcvbcG"
      },
      "source": [
        "At this point, all the training and test data is ready for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0zplq4IvcCE"
      },
      "source": [
        "## Loading pre-trained GloVe embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwCPpb_8wTWo"
      },
      "source": [
        "The next step is the foremost step in transfer learning – loading the pre-trained GloVe embeddings and using these as the weights of the embedding layer.\n",
        "\n",
        "The nearest GloVe dimension is 50, so let's use that. The file format is quite simple. Each line of the text has multiple values separated by spaces. The first item of each row is the word, and the rest of the items are the values of the vector for each dimension. So, in the 50-dimensional file, each row will have 51 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95QVg6XhvV-v"
      },
      "source": [
        "dict_w2v = {}\n",
        "\n",
        "with open(\"glove.6B.50d.txt\", \"r\") as file:\n",
        "  for line in file:\n",
        "    tokens = line.split()\n",
        "    word = tokens[0]\n",
        "    vector = np.array(tokens[1:], dtype=np.float32)\n",
        "\n",
        "    if vector.shape[0] == 50:\n",
        "      dict_w2v[word] = vector\n",
        "    else:\n",
        "      print(\"There was an issue with \", vector)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC4_pws83Vh-"
      },
      "source": [
        "You should see a dictionary size of 400,000 words. Once these vectors are loaded, an embedding matrix needs to be created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFsiC232-0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4870c8ee-a2b7-431f-e53f-b9a1a8864919"
      },
      "source": [
        "# let's check the vocabulary size\n",
        "print(\"Dictionary Size: \", len(dict_w2v))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary Size:  400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFRifDVx3c_h"
      },
      "source": [
        "##Creating a pre-trained embedding matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyDXc-Xm3drA"
      },
      "source": [
        "So far, we have a dataset, its vocabulary, and a dictionary of GloVe words and\n",
        "their corresponding vectors. However, there is no correlation between these two\n",
        "vocabularies. The way to connect them is through the creation of an embedding\n",
        "matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR0kuomt3GRl"
      },
      "source": [
        "# First, let's initialize an embedding matrix of zeros\n",
        "embedding_dim = 50\n",
        "embedding_matrix = np.zeros((imdb_encoder.vocab_size, embedding_dim))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWEy8494LkO"
      },
      "source": [
        "Note that this is a crucial step. When a pre-trained word list is used, finding a vector for each word in the training/test is not guaranteed.\n",
        "\n",
        "After this embedding matrix of zeros is initialized, it needs to be populated. For each word in the vocabulary of reviews, the corresponding vector is retrieved from the GloVe dictionary.\n",
        "\n",
        "The ID of the word is retrieved using the encoder, and then the embedding matrix\n",
        "entry corresponding to that entry is set to the retrieved vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9n0W_Ey4BX_"
      },
      "source": [
        "unk_cnt = 0\n",
        "unk_set = set()\n",
        "\n",
        "for word in imdb_encoder.tokens:\n",
        "  embedding_vector = dict_w2v.get(word)\n",
        "\n",
        "  if embedding_vector is not None:\n",
        "    token_id = imdb_encoder.encode(word)[0]\n",
        "    embedding_matrix[token_id] = embedding_vector\n",
        "  else:\n",
        "    unk_cnt += 1\n",
        "    unk_set.add(word)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQd9ddy5_Qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec679ad-0ac6-4704-c254-465eddd94e61"
      },
      "source": [
        "# how many weren't found?\n",
        "print(\"Total unknown words: \", unk_cnt)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unknown words:  14553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAbOr4XT7hoi"
      },
      "source": [
        "During the data loading step, we saw that the total number of tokens was 93,931.\n",
        "Out of these, 14,553 words could not be found, which is approximately 15% of\n",
        "the tokens. For these words, the embedding matrix will have zeros.\n",
        "\n",
        "**This is the first step in transfer learning.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8JDtcBI-AKs"
      },
      "source": [
        "##Feature extraction model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47byQiBj-A-u"
      },
      "source": [
        "The feature extraction model freezes the pre-trained\n",
        "weights and does not update them. An important issue with this approach in the\n",
        "current setup is that there are a large number of tokens, over 14,000, that have\n",
        "zero embedding vectors. These words could not be matched to an entry in the\n",
        "GloVe word list.\n",
        "\n",
        "---\n",
        "To minimize the chances of not finding matches between the\n",
        "pre-trained vocabulary and task-specific vocabulary, ensure\n",
        "that similar tokenization schemes are used.\n",
        "\n",
        "GloVe uses a wordbased tokenization scheme like the one provided by the Stanford\n",
        "tokenizer.This works better than a whitespace tokenizer.\n",
        "\n",
        "We see 15% unmatched tokens due to different tokenizers.\n",
        "\n",
        "As an exercise, we can implement the Stanford tokenizer\n",
        "and see the reduction in unknown tokens.\n",
        "\n",
        "Newer methods like BERT use parts of subword tokenizers.\n",
        "Subword tokenization schemes can break up words into parts,\n",
        "which minimizes this chance of mismatch in tokens. Some\n",
        "examples of subword tokenization schemes are Byte Pair Encoding\n",
        "(BPE) or WordPiece tokenization.\n",
        "\n",
        "---\n",
        "\n",
        "If pre-trained vectors were not used, then the vectors for all the words would start with nearly zero and get trained through gradient descent. \n",
        "\n",
        "In this case, the vectors are already trained, so we expect the training to go along much faster. \n",
        "\n",
        "For a baseline, one epoch of training of the BiLSTM model while training embeddings takes between 65 seconds and 100 seconds.\n",
        "\n",
        "Now, let's build the model and plug in the embedding matrix generated above into\n",
        "the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mSJBhgQBJSe"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = imdb_encoder.vocab_size   # len(chars)\n",
        "# Number of RNN units\n",
        "rnn_units = 64\n",
        "# batch size\n",
        "BATCH_SIZE = 100"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J2hKeCrp9Y6"
      },
      "source": [
        "A convenience function being set up will enable fast switching. This method enables building models with the same architecture but different hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xWlTgiep_k4"
      },
      "source": [
        "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, train_emb=False):\n",
        "  model = tf.keras.Sequential([\n",
        "       Embedding(vocab_size, embedding_dim, mask_zero=True, weights=[embedding_matrix], trainable=train_emb),\n",
        "       # Dropout(0.25)\n",
        "       Bidirectional(LSTM(rnn_units, return_sequences=True, dropout=0.5)),\n",
        "       Bidirectional(LSTM(rnn_units, dropout=0.5)),   \n",
        "       Dense(1, activation=\"sigmoid\")                     \n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDrJB61ursjn"
      },
      "source": [
        "A new parameter, weights, loads the embedding matrix as the weights for the layer. Just after this parameter, a Boolean parameter called trainable is passed that determines whether the weights of this layer should be updated during training time. \n",
        "\n",
        "A feature extraction-based model can now be created like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KdDvti1rtG0",
        "outputId": "ba7c61cd-5484-4663-c050-4074c09c4e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "featured_model = build_model_bilstm(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)\n",
        "\n",
        "featured_model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 50)          4696550   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 128)         58880     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 4,854,375\n",
            "Trainable params: 157,825\n",
            "Non-trainable params: 4,696,550\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyG0hFcBsaq7"
      },
      "source": [
        "This model needs to be compiled with the loss function, optimizer, and metrics for observation progress of the model. Binary cross-entropy is the right loss function for this problem of binary classification. The Adam optimizer is a decent choice in most cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dRM-9lIsd-4"
      },
      "source": [
        "featured_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dTwhbOotMG4"
      },
      "source": [
        "After setting up batches for preloading, the model is ready for training. Similar to previously, the model will be trained for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVCKlVUitOK0",
        "outputId": "df3e91a6-ae06-468a-c477-0d1a5eb62259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prefetch for performance\n",
        "encoded_train_batched = encoded_train.batch(BATCH_SIZE).prefetch(100)\n",
        "\n",
        "featured_model.fit(encoded_train_batched, epochs=10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 38s 75ms/step - loss: 0.5959 - accuracy: 0.6736 - precision: 0.6800 - recall: 0.6558\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 24s 94ms/step - loss: 0.5289 - accuracy: 0.7387 - precision: 0.7483 - recall: 0.7193\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 22s 89ms/step - loss: 0.5006 - accuracy: 0.7575 - precision: 0.7606 - recall: 0.7514\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.4833 - accuracy: 0.7662 - precision: 0.7697 - recall: 0.7598\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.4576 - accuracy: 0.7834 - precision: 0.7871 - recall: 0.7770\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.4449 - accuracy: 0.7906 - precision: 0.7928 - recall: 0.7870\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 22s 87ms/step - loss: 0.4332 - accuracy: 0.8006 - precision: 0.8009 - recall: 0.8002\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.4191 - accuracy: 0.8069 - precision: 0.8041 - recall: 0.8115\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 21s 86ms/step - loss: 0.4136 - accuracy: 0.8069 - precision: 0.8075 - recall: 0.8059\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.4068 - accuracy: 0.8118 - precision: 0.8110 - recall: 0.8131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b64105990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCNGz8ettpc_"
      },
      "source": [
        "A few things can be seen immediately. The model trained significantly faster.\n",
        "Secondly, the model has not overfit. The final accuracy is just over 81% on\n",
        "the training set.\n",
        "\n",
        ">It should also be noted that the accuracy was still increasing at the\n",
        "end of the tenth epoch, with lots of room to go. This indicates that\n",
        "training this model for longer would probably increase accuracy\n",
        "further.\n",
        "\n",
        "For now, let's understand the utility of this model. To make an assessment of the quality of this model, performance on the test set should be evaluated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buPhZmZpusN0",
        "outputId": "2cbcb3fc-2f90-43bd-fee0-f57e19993b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "featured_model.evaluate(encoded_test.batch(BATCH_SIZE))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 21s 69ms/step - loss: 0.4153 - accuracy: 0.8327 - precision: 0.7973 - recall: 0.8923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41534289717674255,\n",
              " 0.8327199816703796,\n",
              " 0.7972837686538696,\n",
              " 0.8923199772834778]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmlDPNB5u7Bb"
      },
      "source": [
        "This performance is quite impressive because this model is just 40% of the size of the previous model and represents a 70% reduction in training time for a less than 1% drop in accuracy. This model has a slightly better recall for slightly worse accuracy. \n",
        "\n",
        "This result should not be entirely unexpected. There are over 14,000 word vectors that are zeros in this model! To fix this issue, and also to try the fine-tuning sequential transfer learning approach, let's build a\n",
        "fine-tuning-based model.\n",
        "\n",
        "Let's retain it for epoch 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulOrmv5nt8dc",
        "outputId": "d6b67cd1-c66e-4582-b1bc-67104fb4fe07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "featured_model.fit(encoded_train_batched, epochs=20)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.3965 - accuracy: 0.8194 - precision: 0.8180 - recall: 0.8217\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3904 - accuracy: 0.8236 - precision: 0.8226 - recall: 0.8252\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 21s 86ms/step - loss: 0.3829 - accuracy: 0.8286 - precision: 0.8275 - recall: 0.8304\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3774 - accuracy: 0.8323 - precision: 0.8323 - recall: 0.8322\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 22s 87ms/step - loss: 0.3760 - accuracy: 0.8289 - precision: 0.8305 - recall: 0.8264\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.3655 - accuracy: 0.8360 - precision: 0.8368 - recall: 0.8349\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3632 - accuracy: 0.8380 - precision: 0.8359 - recall: 0.8413\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3594 - accuracy: 0.8394 - precision: 0.8420 - recall: 0.8356\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3550 - accuracy: 0.8405 - precision: 0.8398 - recall: 0.8416\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.3548 - accuracy: 0.8399 - precision: 0.8389 - recall: 0.8414\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3515 - accuracy: 0.8462 - precision: 0.8454 - recall: 0.8474\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 22s 87ms/step - loss: 0.3462 - accuracy: 0.8458 - precision: 0.8435 - recall: 0.8491\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3366 - accuracy: 0.8534 - precision: 0.8547 - recall: 0.8514\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3401 - accuracy: 0.8486 - precision: 0.8485 - recall: 0.8489\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 22s 87ms/step - loss: 0.3411 - accuracy: 0.8473 - precision: 0.8470 - recall: 0.8477\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 21s 86ms/step - loss: 0.3310 - accuracy: 0.8538 - precision: 0.8544 - recall: 0.8530\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3311 - accuracy: 0.8550 - precision: 0.8550 - recall: 0.8551\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 22s 87ms/step - loss: 0.3244 - accuracy: 0.8569 - precision: 0.8584 - recall: 0.8548\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 22s 86ms/step - loss: 0.3235 - accuracy: 0.8594 - precision: 0.8559 - recall: 0.8642\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 22s 87ms/step - loss: 0.3154 - accuracy: 0.8618 - precision: 0.8607 - recall: 0.8634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b767e6090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q79h61N7v9iv",
        "outputId": "cf999151-bde8-4720-d145-9434df1dbc6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "featured_model.evaluate(encoded_test.batch(BATCH_SIZE))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 18s 72ms/step - loss: 0.3447 - accuracy: 0.8604 - precision: 0.8178 - recall: 0.9276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3447362184524536,\n",
              " 0.8604400157928467,\n",
              " 0.8177586793899536,\n",
              " 0.9276000261306763]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKkgUOl4-CRq"
      },
      "source": [
        "##Fine-tuning model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8jZ8vH6-KGj"
      },
      "source": [
        "Creating the fine-tuning model is trivial when using the convenience function. All that is needed is to pass the train_emb parameter as true."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4HL-BM_6FYI",
        "outputId": "5e73aa5d-ff4f-4d02-f747-d9d16366a999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fine_tuned_model = build_model_bilstm(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE, train_emb=True)\n",
        "\n",
        "fine_tuned_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 50)          4696550   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 128)         58880     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 4,854,375\n",
            "Trainable params: 4,854,375\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n54V2pstwrV-"
      },
      "source": [
        "This model is identical to the feature extraction model in size. However, since the embeddings will be fine-tuned, training is expected to take a little longer. There are several thousand zero embeddings, which can now be updated. The resulting accuracy is expected to be much better than the previous model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKvMb3ogwxUD",
        "outputId": "74b218b3-9fe8-48a0-ce81-cfa43a5a9838",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fine_tuned_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", \"Precision\", \"Recall\"])\n",
        "fine_tuned_model.fit(encoded_train_batched, epochs=20)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 44s 121ms/step - loss: 0.0987 - accuracy: 0.9631 - precision: 0.9646 - recall: 0.9615\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 32s 127ms/step - loss: 0.0895 - accuracy: 0.9679 - precision: 0.9671 - recall: 0.9687\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 32s 129ms/step - loss: 0.0734 - accuracy: 0.9736 - precision: 0.9739 - recall: 0.9734\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 32s 127ms/step - loss: 0.0634 - accuracy: 0.9784 - precision: 0.9784 - recall: 0.9783\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 32s 128ms/step - loss: 0.0543 - accuracy: 0.9804 - precision: 0.9815 - recall: 0.9794\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 32s 127ms/step - loss: 0.0526 - accuracy: 0.9814 - precision: 0.9824 - recall: 0.9803\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 32s 129ms/step - loss: 0.0447 - accuracy: 0.9838 - precision: 0.9830 - recall: 0.9846\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.0412 - accuracy: 0.9858 - precision: 0.9853 - recall: 0.9863\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 32s 129ms/step - loss: 0.0358 - accuracy: 0.9869 - precision: 0.9863 - recall: 0.9876\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.0286 - accuracy: 0.9900 - precision: 0.9897 - recall: 0.9902\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 32s 128ms/step - loss: 0.0319 - accuracy: 0.9892 - precision: 0.9900 - recall: 0.9884\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 32s 128ms/step - loss: 0.0298 - accuracy: 0.9897 - precision: 0.9897 - recall: 0.9898\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 32s 129ms/step - loss: 0.0245 - accuracy: 0.9913 - precision: 0.9911 - recall: 0.9914\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.0204 - accuracy: 0.9932 - precision: 0.9929 - recall: 0.9934\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.0195 - accuracy: 0.9934 - precision: 0.9934 - recall: 0.9934\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.0187 - accuracy: 0.9936 - precision: 0.9935 - recall: 0.9936\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 32s 129ms/step - loss: 0.0173 - accuracy: 0.9938 - precision: 0.9941 - recall: 0.9935\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 32s 129ms/step - loss: 0.0197 - accuracy: 0.9936 - precision: 0.9945 - recall: 0.9927\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 32s 130ms/step - loss: 0.0150 - accuracy: 0.9948 - precision: 0.9949 - recall: 0.9948\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 32s 128ms/step - loss: 0.0148 - accuracy: 0.9946 - precision: 0.9947 - recall: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b79291050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnLB7Qllw9-x"
      },
      "source": [
        "This accuracy is very impressive but needs to be checked against the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjC81wyGw_B0",
        "outputId": "d4db6bbe-7e29-482b-dd90-ec8414ebc876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fine_tuned_model.evaluate(encoded_test.batch(BATCH_SIZE))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 21s 70ms/step - loss: 0.9735 - accuracy: 0.8390 - precision: 0.8230 - recall: 0.8638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9734604954719543,\n",
              " 0.8390399813652039,\n",
              " 0.8230183124542236,\n",
              " 0.8638399839401245]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TbyyFo1xN5q"
      },
      "source": [
        "That is the best result we have obtained so far at an accuracy of 87.1%.\n",
        "\n",
        "It can also be seen that the network is overfitting a little bit. A Dropout layer can be added between the Embedding layer and the first LSTM layer to help reduce this overfitting. It should also be noted that this network is still much faster than training embeddings from scratch. Most epochs took 24 seconds for training. \n",
        "\n",
        "Overall, this model is smaller in size, takes much less time to train, and has much higher accuracy!\n",
        "\n",
        "**This is why transfer learning is so important in machine learning in general and NLP more specifically.**\n",
        "\n",
        "So far, we have seen the use of context-free word embeddings. The major challenge with this approach is that a word could have multiple meanings depending on the context.\n",
        "\n",
        "The word bank could refer to a place for storing money and valuables and\n",
        "also the side of a river.\n",
        "\n",
        "**A more recent innovation in this area is BERT that is a contextual word embeddings.**"
      ]
    }
  ]
}