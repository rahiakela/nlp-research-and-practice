{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPdfGDjRB4FvoalEFCsqW/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/getting-started-with-nlp/03-information-retrieval/information_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Information Retrieval"
      ],
      "metadata": {
        "id": "pPnk7t1ZVcoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might have come across the term information retrieval in the context of\n",
        "search engines; for example, Google famously started its business by providing a\n",
        "powerful search algorithm that kept improving over time. The search for information,\n",
        "however, is a basic need that you may face beyond searching online.\n",
        "\n",
        "For\n",
        "instance, every time you search for the files on your computer, you are performing\n",
        "a sort of information retrieval.\n",
        "\n",
        "Information search is based on\n",
        "the idea that the content of a document or set of documents is relevant given the content\n",
        "of a particular query, so a documents data structure should keep the contents of\n",
        "all available documents for the algorithm to select from.\n",
        "\n"
      ],
      "metadata": {
        "id": "agOlcZQuVdZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "yDE2FJXVX9OY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import string\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize, WordNetLemmatizer, pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from operator import itemgetter"
      ],
      "metadata": {
        "id": "tP1a1ShAX-iq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "wget https://github.com/ekochmar/Getting-Started-with-NLP/raw/master/cisi.zip\n",
        "\n",
        "unzip cisi.zip\n",
        "rm -rf cisi.zip"
      ],
      "metadata": {
        "id": "p87lVQd-3vUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "tUyrhVHiX-0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three components to this data:\n",
        "\n",
        "* documents with their ids and content-there are 1460 of those to be precise\n",
        "* questions/queries with their ids and content- there are 112 of those;\n",
        "* mapping between the queries and relevant documents\n",
        "\n",
        "First, let's read in documents from the `CISI.ALL` file and store the result in `documents` data structure- set of tuples of document ids matched with contents:"
      ],
      "metadata": {
        "id": "TwIKGc9CYAOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# populate the documents dictionary\n",
        "def read_documents():\n",
        "  f = open(\"cisi/CISI.ALL\")\n",
        "  merged = \"\"\n",
        "\n",
        "  for line in f.readlines():\n",
        "    if line.startswith(\".\"):\n",
        "      merged += \"\\n\" + line.strip()\n",
        "    else:\n",
        "      merged += \" \" + line.strip()\n",
        "\n",
        "  documents = {}\n",
        "  content = \"\"\n",
        "  doc_id = \"\"\n",
        "  for line in merged.split(\"\\n\"):\n",
        "    if line.startswith(\".I\"):\n",
        "      doc_id = line.split(\" \")[1].strip()\n",
        "    elif line.startswith(\".X\"):\n",
        "        documents[doc_id] = content\n",
        "        content = \"\"\n",
        "        doc_id = \"\"\n",
        "    else:\n",
        "      content += line.strip()[3:] + \" \"\n",
        "  \n",
        "  documents[doc_id] = content\n",
        "  f.close()\n",
        "  return documents"
      ],
      "metadata": {
        "id": "Of7iARpdbmzQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's do a sanity check\n",
        "documents = read_documents()\n",
        "print(len(documents))\n",
        "print(documents.get(\"1\"))"
      ],
      "metadata": {
        "id": "GVludlRu5dVV",
        "outputId": "48ca9a68-10ce-43db-bd7d-1e36f5b2d97d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1461\n",
            " 18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second, let's read in queries from the `CISI.QRY` file and store the result in `queries` data structure – set of tuples of query ids matched with contents:"
      ],
      "metadata": {
        "id": "eYu1KQY77rMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# populate the queries dictionary\n",
        "def read_queries():\n",
        "  f = open(\"cisi/CISI.QRY\")\n",
        "  merged = \"\"\n",
        "\n",
        "  for line in f.readlines():\n",
        "    if line.startswith(\".\"):\n",
        "      merged += \"\\n\" + line.strip()\n",
        "    else:\n",
        "      merged += \" \" + line.strip()\n",
        "\n",
        "  queries = {}\n",
        "  content = \"\"\n",
        "  query_id = \"\"\n",
        "  for line in merged.split(\"\\n\"):\n",
        "    if line.startswith(\".I\"):\n",
        "      if not content==\"\":\n",
        "        queries[query_id] = content\n",
        "        content = \"\"\n",
        "        query_id = \"\"\n",
        "      query_id = line.split(\" \")[1].strip()\n",
        "    elif line.startswith(\".W\") or line.startswith(\".T\"):\n",
        "      content += line.strip()[3:] + \" \"\n",
        "  \n",
        "  queries[query_id] = content\n",
        "  f.close()\n",
        "  return queries"
      ],
      "metadata": {
        "id": "QrS_BmyM5odO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's do a sanity check\n",
        "queries = read_queries()\n",
        "print(len(queries))\n",
        "print(queries.get(\"1\"))"
      ],
      "metadata": {
        "id": "jKmGq6B_7mNI",
        "outputId": "c2c7d955-1b26-4d97-f4d0-39077805380f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112\n",
            "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's read in the mapping between the queries and the documents – we'll keep these in the `mappings` data structure – with tuples where each query index (key) corresponds to the list of one or more document indices (value):"
      ],
      "metadata": {
        "id": "KgWinhU18382"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# populate the mappings dictionary\n",
        "def read_mappings():\n",
        "  f = open(\"cisi/CISI.REL\")\n",
        "\n",
        "  mappings = {}\n",
        "  for line in f.readlines():\n",
        "    voc = line.strip().split()\n",
        "    key = voc[0].strip()\n",
        "    current_value = voc[1].strip()\n",
        "    value = []\n",
        "    if key in mappings.keys():\n",
        "      value = mappings.get(key)\n",
        "    value.append(current_value)\n",
        "    mappings[key] = value\n",
        "  \n",
        "  f.close()\n",
        "  return mappings"
      ],
      "metadata": {
        "id": "6K3t0oYX84I_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's do a sanity check\n",
        "mappings = read_mappings()\n",
        "print(len(mappings))\n",
        "print(mappings.keys())\n",
        "print(mappings.get(\"1\"))"
      ],
      "metadata": {
        "id": "-6WBdqN4-QsG",
        "outputId": "8117bbfd-e752-4d90-cc3b-d1b6d158f44c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76\n",
            "dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '37', '39', '41', '42', '43', '44', '45', '46', '49', '50', '52', '54', '55', '56', '57', '58', '61', '62', '65', '66', '67', '69', '71', '76', '79', '81', '82', '84', '90', '92', '95', '96', '97', '98', '99', '100', '101', '102', '104', '109', '111'])\n",
            "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That’s it! You have successfully initialized one dictionary for `documents` with the\n",
        "IDs linked to the articles content, another dictionary for `queries` linking query IDs to\n",
        "their correspondent texts, and the `mappings` dictionary, which matches the query IDs\n",
        "to the lists of relevant document IDs."
      ],
      "metadata": {
        "id": "uNWFJHOw-uN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Boolean search algorithm"
      ],
      "metadata": {
        "id": "ME_rsUrT-1Z8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6CIEy2MQ-6Yp"
      }
    }
  ]
}