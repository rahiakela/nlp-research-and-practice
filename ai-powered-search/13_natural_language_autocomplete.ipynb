{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/ai-powered-search/13_natural_language_autocomplete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51uM8gPIW0mO"
      },
      "source": [
        "## Setup\n",
        "\n",
        "In this notebook, we\"re going to install a transformer model, analyze the embedding output, and compare some vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#outdoors\n",
        "![ ! -d 'outdoors' ] && git clone --depth=1 https://github.com/ai-powered-search/outdoors.git\n",
        "! cd outdoors && git pull\n",
        "! cd outdoors && cat outdoors.tgz.part* > outdoors.tgz\n",
        "! cd outdoors && mkdir -p '../data/outdoors/' && tar -xvf outdoors.tgz -C '../data/outdoors/'"
      ],
      "metadata": {
        "id": "5xShS9pNXKtl",
        "outputId": "34ef403e-921f-4230-f95e-c5766130830c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'outdoors'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 25 (delta 0), reused 22 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 491.39 MiB | 25.64 MiB/s, done.\n",
            "Updating files: 100% (23/23), done.\n",
            "Already up to date.\n",
            "README.md\n",
            "concepts.pickle\n",
            "._guesses.csv\n",
            "guesses.csv\n",
            "._guesses_all.json\n",
            "guesses_all.json\n",
            "outdoors_concepts.pickle\n",
            "outdoors_embeddings.pickle\n",
            "._outdoors_golden_answers.csv\n",
            "outdoors_golden_answers.csv\n",
            "._outdoors_golden_answers.xlsx\n",
            "outdoors_golden_answers.xlsx\n",
            "._outdoors_golden_answers_20210130.csv\n",
            "outdoors_golden_answers_20210130.csv\n",
            "outdoors_labels.pickle\n",
            "outdoors_question_answering_contexts.json\n",
            "outdoors_questionanswering_test_set.json\n",
            "outdoors_questionanswering_train_set.json\n",
            "._posts.csv\n",
            "posts.csv\n",
            "predicates.pickle\n",
            "pull_aips_dependency.py\n",
            "._question-answer-seed-contexts.csv\n",
            "question-answer-seed-contexts.csv\n",
            "question-answer-squad2-guesses.csv\n",
            "._roberta-base-squad2-outdoors\n",
            "roberta-base-squad2-outdoors/\n",
            "roberta-base-squad2-outdoors/._tokenizer_config.json\n",
            "roberta-base-squad2-outdoors/tokenizer_config.json\n",
            "roberta-base-squad2-outdoors/._special_tokens_map.json\n",
            "roberta-base-squad2-outdoors/special_tokens_map.json\n",
            "roberta-base-squad2-outdoors/._config.json\n",
            "roberta-base-squad2-outdoors/config.json\n",
            "roberta-base-squad2-outdoors/._merges.txt\n",
            "roberta-base-squad2-outdoors/merges.txt\n",
            "roberta-base-squad2-outdoors/._training_args.bin\n",
            "roberta-base-squad2-outdoors/training_args.bin\n",
            "roberta-base-squad2-outdoors/._pytorch_model.bin\n",
            "roberta-base-squad2-outdoors/pytorch_model.bin\n",
            "roberta-base-squad2-outdoors/._vocab.json\n",
            "roberta-base-squad2-outdoors/vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xA3xmRRHW0mQ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(\"../..\")\n",
        "# from aips import *\n",
        "import pandas\n",
        "import numpy\n",
        "import pickle\n",
        "import json\n",
        "import tqdm\n",
        "\n",
        "import sentence_transformers\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ruXhtGPW0mR"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "transformer = SentenceTransformer(\"roberta-base-nli-stsb-mean-tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOivJ3IsW0mR"
      },
      "source": [
        "## Introduction to Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GABSXr_DW0mR",
        "outputId": "2ef63e70-4423-43ee-fd72-fafb3c36e311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of embeddings: 4\n",
            "Dimensions per embedding: 768\n",
            "The embedding feature values of \"it's raining hard\":\n",
            "tensor(0.5095)\n"
          ]
        }
      ],
      "source": [
        "phrases = [\n",
        "    \"it's raining hard\",\n",
        "    \"it is wet outside\",\n",
        "    \"cars drive fast\",\n",
        "    \"motorcycles are loud\"\n",
        "]\n",
        "\n",
        "embeddings = transformer.encode(phrases, convert_to_tensor=True)\n",
        "print(\"Number of embeddings:\", len(embeddings))\n",
        "print(\"Dimensions per embedding:\", len(embeddings[0]))\n",
        "print(\"The embedding feature values of \\\"it's raining hard\\\":\")\n",
        "print(embeddings[0][10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7wP--SMrW0mS",
        "outputId": "31f283ad-c287-46a9-a14f-099302c1b033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the resulting similarities: torch.Size([4, 4])\n"
          ]
        }
      ],
      "source": [
        "def normalize_embedding(embedding):\n",
        "    normalized = numpy.divide(embedding, numpy.linalg.norm(embedding))\n",
        "    return list(map(float, normalized))\n",
        "\n",
        "# Unit-normalizes embeddings for speed\n",
        "normalized_embeddings = list(map(normalize_embedding, embeddings))\n",
        "similarities = sentence_transformers.util.dot_score(normalized_embeddings,\n",
        "                                                    normalized_embeddings)\n",
        "print(\"The shape of the resulting similarities:\", similarities.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0KFbyiT-W0mS",
        "outputId": "1849742b-d860-4578-d109-93b4b35ed989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>score</th>\n",
              "      <th>phrase a</th>\n",
              "      <th>phrase b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.669060</td>\n",
              "      <td>it's raining hard</td>\n",
              "      <td>it is wet outside</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.590783</td>\n",
              "      <td>cars drive fast</td>\n",
              "      <td>motorcycles are loud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.281166</td>\n",
              "      <td>it's raining hard</td>\n",
              "      <td>cars drive fast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.280800</td>\n",
              "      <td>it's raining hard</td>\n",
              "      <td>motorcycles are loud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.204867</td>\n",
              "      <td>it is wet outside</td>\n",
              "      <td>motorcycles are loud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.138172</td>\n",
              "      <td>it is wet outside</td>\n",
              "      <td>cars drive fast</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def rank_similarities(phrases, similarities):\n",
        "    a_phrases = []\n",
        "    b_phrases = []\n",
        "    scores = []\n",
        "    for a in range(len(similarities) - 1):\n",
        "        for b in range(a + 1, len(similarities)):\n",
        "            a_phrases.append(phrases[a])\n",
        "            b_phrases.append(phrases[b])\n",
        "            scores.append(float(similarities[a][b]))\n",
        "    dataframe = pandas.DataFrame({\"score\": scores,\n",
        "                                  \"phrase a\": a_phrases, \"phrase b\": b_phrases})\n",
        "    dataframe[\"idx\"] = dataframe.index\n",
        "    dataframe = dataframe.reindex(columns=[\"idx\", \"score\", \"phrase a\", \"phrase b\"])\n",
        "    return dataframe.sort_values(by=[\"score\"], ascending=False, ignore_index=True)\n",
        "\n",
        "dataframe = rank_similarities(phrases, similarities)\n",
        "display(HTML(dataframe.to_html(index=False)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get embeddings"
      ],
      "metadata": {
        "id": "KzFEJ0VxFGTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = SentenceTransformer(\"roberta-base-nli-stsb-mean-tokens\")"
      ],
      "metadata": {
        "id": "PS92mGrsFKl5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(text, model, cache_name, ignore_cache=False):\n",
        "  cache_file_name = f\"data/outdoors/{cache_name}.pickle\"\n",
        "  if ignore_cache or not os.path.isfile(cache_file_name):\n",
        "    return numpy.load(cache_file_name)\n",
        "    embeddings = model.encode(texts)\n",
        "    os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
        "    with open(cache_file_name, \"wb\") as cache_file:\n",
        "      pickle.dump(embeddings, cache_file)\n",
        "  else:\n",
        "    with open(cache_file_name, \"rb\") as cache_file:\n",
        "      embeddings = pickle.load(cache_file)\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "WipDDFrAFdsl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/outdoors/outdoors_concepts.pickle\", \"rb\") as concepts:\n",
        "  concepts = pickle.load(concepts)"
      ],
      "metadata": {
        "id": "1bYMatxAISZc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Note!  This is a hyperparameter.\n",
        "#We are ignoring terms that occur less than this numner in the entire corpus.\n",
        "#Lowering this number may lower precision\n",
        "#Raising this number may lower recall\n",
        "minimum_frequency = 6\n",
        "phrases = [key for (key, tf) in concepts.items() if tf >= minimum_frequency]\n",
        "\n",
        "cache_name = \"outdoors_embeddings\"\n",
        "# set ignore_cache=True to regenerate the embeddings rather than loading from the cache\n",
        "embeddings = get_embeddings(phrases, transformer, cache_name, ignore_cache=False)\n",
        "\n",
        "print(f\"Number of embeddings: {len(embeddings)}\")\n",
        "print(f\"Dimensions per embedding: {len(embeddings[0])}\")"
      ],
      "metadata": {
        "id": "EELT4G3DHPym",
        "outputId": "5e7c4863-19dc-44f5-a415-13d9ef6d1e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of embeddings: 12375\n",
            "Dimensions per embedding: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate similarity score"
      ],
      "metadata": {
        "id": "FlXBiAgzLy2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_embedding(embedding):\n",
        "  normalized = numpy.divide(embedding, numpy.linalg.norm(embedding))\n",
        "  return list(map(float, normalized))"
      ],
      "metadata": {
        "id": "omx47ZZ5JHY_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_similarities(phrases, similarities):\n",
        "  a_phrases = []\n",
        "  b_phrases = []\n",
        "  scores = []\n",
        "  for a in range(len(similarities) - 1):\n",
        "    for b in range(a + 1, len(similarities)):\n",
        "      a_phrases.append(phrases[a])\n",
        "      b_phrases.append(phrases[b])\n",
        "      scores.append(float(similarities[a][b]))\n",
        "  dataframe = pandas.DataFrame({\n",
        "      \"score\": scores,\n",
        "      \"phrase a\": a_phrases,\n",
        "      \"phrase b\": b_phrases\n",
        "  })\n",
        "  dataframe[\"idx\"] = range(len(dataframe))\n",
        "  dataframe = dataframe.reindex(columns=[\"idx\", \"score\", \"phrase a\", \"phrase b\"])\n",
        "  return dataframe.sort_values(by=[\"score\"], ascending=False, ignore_index=True)"
      ],
      "metadata": {
        "id": "LruNemFbMFjZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the pairs with the highest cosine similarity scores\n",
        "normalized_embeddings = list(map(normalize_embedding, embeddings))\n",
        "similarities = sentence_transformers.util.dot_score(\n",
        "    normalized_embeddings[0:250],\n",
        "    normalized_embeddings[0:250]\n",
        ")\n",
        "# Ranks similarities\n",
        "comparisons = rank_similarities(phrases, similarities)\n",
        "display(HTML(comparisons[:10].to_html(index=False)))"
      ],
      "metadata": {
        "id": "iXXB60LnM-KQ",
        "outputId": "d6a0d3e7-cf59-4c02-b747-a709ba8482a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>score</th>\n",
              "      <th>phrase a</th>\n",
              "      <th>phrase b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>31096</td>\n",
              "      <td>0.928150</td>\n",
              "      <td>protect</td>\n",
              "      <td>protection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13241</td>\n",
              "      <td>0.923570</td>\n",
              "      <td>climbing</td>\n",
              "      <td>climber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18096</td>\n",
              "      <td>0.878894</td>\n",
              "      <td>camp</td>\n",
              "      <td>camping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7282</td>\n",
              "      <td>0.833662</td>\n",
              "      <td>climb</td>\n",
              "      <td>climbing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10312</td>\n",
              "      <td>0.821081</td>\n",
              "      <td>something</td>\n",
              "      <td>someone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8813</td>\n",
              "      <td>0.815187</td>\n",
              "      <td>hike</td>\n",
              "      <td>hiking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4182</td>\n",
              "      <td>0.784663</td>\n",
              "      <td>people</td>\n",
              "      <td>person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7354</td>\n",
              "      <td>0.782962</td>\n",
              "      <td>climb</td>\n",
              "      <td>climber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1027</td>\n",
              "      <td>0.770643</td>\n",
              "      <td>go</td>\n",
              "      <td>leave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4422</td>\n",
              "      <td>0.768612</td>\n",
              "      <td>keep</td>\n",
              "      <td>stay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from plotnine import *\n",
        "from plotnine.data import mpg\n",
        "import matplotlib.pyplot as plt\n",
        "candidate_synonyms = comparisons[comparisons[\"score\"] > 0.0]\n",
        "{\n",
        "    ggplot(comparisons, aes(\"idx\", \"score\")) +\n",
        "    geom_violin(color=\"blue\") +\n",
        "    scale_y_continuous(limits=[-0.4, 1.0],\n",
        "                       breaks=[-0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "}"
      ],
      "metadata": {
        "id": "A6PMZzhUNoq8",
        "outputId": "c354fced-60dd-47ea-9789-afef151acf02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{<plotnine.ggplot.ggplot at 0x7df99a8fae30>}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Search embeddings"
      ],
      "metadata": {
        "id": "Zbjb6yEHPscY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sNWZ9u50OifI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}