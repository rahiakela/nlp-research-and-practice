{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJOxz/o0jdcrDk6KMA5Vk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/nlp-in-real-world/02-advanced-nlp-applications/02_ner_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "LCbxNJZpcfKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install transformers\n",
        "!pip -q install spacy\n",
        "!pip install spacy-transformers==1.1.5 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "3WhrYAcJcgVG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "mXUnM_u0c059"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://noisy-text.github.io/2017/files/wnut17train.conll"
      ],
      "metadata": {
        "id": "k-sYdNzug3LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##spaCy fine-tuning"
      ],
      "metadata": {
        "id": "JpidC2lIcm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [\n",
        "    (\n",
        "        \"Chef added some salt and pepper to the rice.\",\n",
        "        {\n",
        "            \"entities\": [\n",
        "            (16, 20, 'SPICE'),\n",
        "            (25, 31, 'SPICE'),\n",
        "            (39, 43, 'INGREDIENT')\n",
        "          ]\n",
        "        }\n",
        "    ),\n",
        "    (\n",
        "        \"The pasta was set to boil with some salt.\",\n",
        "        {\n",
        "            \"entities\": [\n",
        "            (4, 9, 'INGREDIENT'),\n",
        "            (36, 40, 'SPICE')\n",
        "          ]\n",
        "        }\n",
        "    ),\n",
        "    (\n",
        "        \"Adding egg to the rice dish with some pepper.\",\n",
        "        {\n",
        "            \"entities\": [\n",
        "            (7, 10, 'INGREDIENT'),\n",
        "            (18, 22, 'INGREDIENT'),\n",
        "            (38, 44, 'SPICE')\n",
        "          ]\n",
        "        }\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "H4qMPoWamTde"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "print(\"Created a blank en model\")\n",
        "\n",
        "nlp.add_pipe(\"ner\", last=True)\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "print(\"pipe_names\", nlp.pipe_names)\n",
        "\n",
        "for _, annotations in train_data:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])\n",
        "\n",
        "# begin training\n",
        "optimizer = nlp.begin_training()"
      ],
      "metadata": {
        "id": "sOha62hycnfc",
        "outputId": "91a086fd-2a55-42d7-96c1-6da94bd7f58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a blank en model\n",
            "pipe_names ['ner']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 100\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiece\", \"trf_tok2vec\"]\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "  for _ in range(n_iter):\n",
        "    random.shuffle(train_data)\n",
        "    losses = {}\n",
        "    for batch in spacy.util.minibatch(train_data, size=2):\n",
        "      for text, annots in batch:\n",
        "        doc = nlp.make_doc(text)\n",
        "        nlp.update([Example.from_dict(doc, annots)], drop=0.5, sgd=optimizer, losses=losses)\n",
        "    print(f\"losses: {losses}\")"
      ],
      "metadata": {
        "id": "P02brnERdE57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entities(raw_text):\n",
        "  doc = nlp(raw_text)\n",
        "  result = []\n",
        "  for word in doc.ents:\n",
        "    result.append((word.text, word.label_))\n",
        "  return result"
      ],
      "metadata": {
        "id": "ArxlMZBEh1IA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_entities(\"Add water to the spaghetti\"))"
      ],
      "metadata": {
        "id": "EFfn3jFaX3EV",
        "outputId": "e0359dc3-ccd7-47d3-e323-0efbd1f75561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('water', 'SPICE'), ('spaghetti', 'SPICE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_entities(\"Add some paprika on top to your pasta.\"))"
      ],
      "metadata": {
        "id": "faN039OjX7xQ",
        "outputId": "4f2b7fd7-a3f5-497e-9308-da93a52f4130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('paprika', 'SPICE'), ('pasta', 'INGREDIENT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformers fine-tuning"
      ],
      "metadata": {
        "id": "SocN2Ugna8Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ho85PyOlbGJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}