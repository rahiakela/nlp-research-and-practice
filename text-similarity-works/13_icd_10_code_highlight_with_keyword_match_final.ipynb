{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0hK4nU35JVaA",
        "N4dDTs-rJL_h",
        "TycHgKTZJ6a6"
      ],
      "authorship_tag": "ABX9TyMfm9jKJapVDIp+V9kPNVpW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/nlp-research-and-practice/blob/main/text-similarity-works/13_icd_10_code_highlight_with_keyword_match_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "u6vazPC0Ja4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install pillow\n",
        "\n",
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install -U pdftotext\n",
        "!pip install PyPDF2\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "gdwgVvXuJdz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import difflib\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "import fitz\n",
        "import pdftotext\n",
        "from PyPDF2 import PdfFileReader, PdfReader, PdfFileWriter, PdfWriter\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from spacy.lang.en import English\n",
        "\n",
        "from keyword_extraction import call\n",
        "from concurrent import futures"
      ],
      "metadata": {
        "id": "gKbd7WsfyYX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p pdf-files\n",
        "!mkdir -p txt-files\n",
        "!mkdir -p output_pdf_files_path"
      ],
      "metadata": {
        "id": "WyuzUOer0FFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p input_files"
      ],
      "metadata": {
        "id": "2dfljcHuOVw3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define directory path after creating it\n",
        "pdf_files_path = \"pdf-files\"\n",
        "txt_files_path = \"txt-files\"\n",
        "ocr_pdf_files_path = \"ocr-pdf-files\"\n",
        "\n",
        "MAX_WORKERS = 20"
      ],
      "metadata": {
        "id": "6RzBfwkuyfv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Functions"
      ],
      "metadata": {
        "id": "0hK4nU35JVaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pdf(pdf_path):\n",
        "  pdf_in_file = open(pdf_path, \"rb\")\n",
        "  pdf = PdfFileReader(pdf_in_file)\n",
        "  pdf_list = []\n",
        "  for page in range(pdf.numPages):\n",
        "      inputpdf = PdfFileReader(pdf_in_file)\n",
        "      output = PdfFileWriter()\n",
        "      output.addPage(inputpdf.getPage(page))\n",
        "      with open(f\"{pdf_files_path}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "          output.write(outputStream)\n",
        "          pdf_list.append(f\"page-{page}.pdf\")\n",
        "  return pdf_list\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_list):\n",
        "    txt_file_list = []\n",
        "    i = 0\n",
        "    for pdf_file in pdf_list:\n",
        "        with open(os.path.join(pdf_files_path, pdf_file), \"rb\") as f:\n",
        "            pdf = pdftotext.PDF(f)\n",
        "\n",
        "        # Read all the text into one string\n",
        "        pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "        # write text into file\n",
        "        with open(f\"{txt_files_path}/page-{str(i)}.txt\", \"a\") as f:\n",
        "            f.write(pdf_text)\n",
        "        txt_file_list.append(f\"{txt_files_path}/page-{str(i)}.txt\")\n",
        "        i += 1\n",
        "    return txt_file_list\n",
        "\n",
        "\n",
        "def get_opt_pattern(icd_10_code):\n",
        "  # create alternate pattern\n",
        "  code_arr = icd_10_code.split(\".\")\n",
        "  if len(code_arr) > 1:\n",
        "    code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "    code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "    code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "    return [code1, code2, code3]\n",
        "  else:\n",
        "    return icd_10_code\n",
        "\n",
        "\n",
        "def isExactMatch(page, term, clip, fullMatch=False, caseSensitive=False):\n",
        "  # clip is an item from page.search_for(term, quads=True)\n",
        "  termLen = len(term)\n",
        "  termBboxLen = max(clip.height, clip.width)\n",
        "  termfontSize = termBboxLen/termLen\n",
        "  f = termfontSize*2\n",
        "\n",
        "  #clip = clip.rect\n",
        "\n",
        "  validate = page.get_text(\"blocks\", clip = clip + (-f, -f, f, f), flags=0)[0][4]\n",
        "  flag = 0\n",
        "  if not caseSensitive:\n",
        "      flag = re.IGNORECASE\n",
        "\n",
        "  matches = len(re.findall(f'{term}', validate, flags=flag)) > 0\n",
        "  if fullMatch:\n",
        "      matches = len(re.findall(f'\\\\b{term}\\\\b', validate))>0\n",
        "  return matches\n",
        "\n",
        "def highlight_icd_code_and_keyword(icd10_code_dict, \n",
        "                                   icd_keywords_dict=None, \n",
        "                                   pdf_file_name=None, \n",
        "                                   cords_file_name=None):\n",
        "  pdf_file = fitz.open(pdf_file_name)\n",
        "  already_highlighted_list = []\n",
        "\n",
        "  def highlight_pdf(highlight, icd10_code, code_type):\n",
        "    cords_list = []\n",
        "    for inst in highlight:\n",
        "      highlight = page.add_highlight_annot(inst)\n",
        "      if code_type == \"ICD-9\":\n",
        "        highlight.set_colors(stroke=[1, 0.5, 0.8]) # light red color (r, g, b)\n",
        "      highlight.update()\n",
        "      highlight = page.search_for(icd10_code)\n",
        "      cords_list.append(highlight)\n",
        "\n",
        "    if cords_list:\n",
        "      num_page = page_num + 1\n",
        "      code_cors_output = f\"Page-{num_page} | {icd10_code}\"\n",
        "      txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "\n",
        "  # create file to write cordinate \n",
        "  txt_output_file_name = open(cords_file_name, \"a\")\n",
        "\n",
        "  for page_num, page in enumerate(pdf_file):\n",
        "    # highlight ICD-10 code\n",
        "    if page_num in icd10_code_dict:\n",
        "      for code in icd10_code_dict[page_num]:\n",
        "        highlight = page.search_for(code)\n",
        "        if len(highlight) == 0:\n",
        "          alternate_code_list = get_opt_pattern(code)\n",
        "          for alt_code in alternate_code_list:\n",
        "            highlight = page.search_for(alt_code)\n",
        "            # highlight pdf for option pattern\n",
        "            highlight_pdf(highlight, alt_code, code_type=\"ICD-10\")\n",
        "        # highlight pdf for main pattern   \n",
        "        highlight_pdf(highlight, code, code_type=\"ICD-10\")\n",
        "\n",
        "    # highlight ICD key phrase\n",
        "    if page_num in icd_keywords_dict:\n",
        "      icd_keyword_dict = icd_keywords_dict[page_num]\n",
        "      for key_phrase, key_phrase_sents in icd_keyword_dict.items():\n",
        "        for key_phrase_sent in key_phrase_sents:\n",
        "          coordinates = page.search_for(key_phrase_sent)\n",
        "          #print(f\"Keyword: {keyword}, Length: {len(coordinates)}\")\n",
        "          cords_list = []\n",
        "          keyword_cors_output = \"\"\n",
        "          for inst in coordinates:\n",
        "            #print(f\"Keyword: {keyword}, inst: {inst}\")\n",
        "            # if isExactMatch(page, key_phrase, inst, fullMatch=True, caseSensitive=True):\n",
        "            highlight = page.add_highlight_annot(inst)\n",
        "            highlight.set_colors(stroke=[1, 0.8, 0.8])\n",
        "            highlight.update()\n",
        "            highlight = page.search_for(key_phrase_sent)\n",
        "            cords_list.append(highlight)\n",
        "            num_page = page_num + 1\n",
        "            keyword_cors_output = f\"Page-{num_page} | {key_phrase} | {key_phrase_sent}\"\n",
        "\n",
        "          if cords_list:\n",
        "            txt_output_file_name.write(\"%s\\n\" % keyword_cors_output)\n",
        "            #print(f\"Page-{page_num}: \", highlight, end='\\n')\n",
        "\n",
        "  txt_output_file_name.close()\n",
        "\n",
        "  pdf_output_file_name = f\"{pdf_file_name.split('.')[0]}_output.pdf\"\n",
        "  pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "  return pdf_output_file_name, cords_file_name\n",
        "\n",
        "\n",
        "def filter_unwanted_code(code_list, page_text):\n",
        "    filtered_code_list = []\n",
        "    # if re.search(\"ICD\", page_text):\n",
        "    # match_list = re.findall(\"(ICD-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "    match_list = re.findall(\"(IC[(A-z)]-[0-9][a-zA-z]*\\-.+)[ ]\", page_text)\n",
        "    # print(\"Match list:\\n\", match_list)\n",
        "    for found_code in match_list:\n",
        "        for code in code_list:\n",
        "            if code in found_code:\n",
        "                filtered_code_list.append(code)\n",
        "    return filtered_code_list\n",
        "\n",
        "\n",
        "def search_icd_code(txt_list, nlp, code_type):\n",
        "    pdf_page_vocab = {}\n",
        "    for txt_file in txt_list:\n",
        "        with open(txt_file, \"r\") as f:\n",
        "            page_txt = f.read()\n",
        "            # filter the page that have line number instead of code\n",
        "            if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "                doc = nlp(page_txt)\n",
        "                code_list = [ent.text for ent in doc.ents]\n",
        "                page_number = 0\n",
        "                if len(code_list) != 0:\n",
        "                    page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "                    pdf_page_vocab[page_number] = code_list\n",
        "                    # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "\n",
        "                # filter the page that dont have ICD string into it\n",
        "                if code_type == \"ICD-9\":\n",
        "                    filtered_code_list = filter_unwanted_code(code_list, page_txt)\n",
        "                    pdf_page_vocab[page_number] = filtered_code_list\n",
        "                    # print(f\"Page[{txt_file.split('/')[1]}]: {filtered_code_list}\")\n",
        "\n",
        "    return pdf_page_vocab\n",
        "\n",
        "\n",
        "def get_json_array_list(text_path):\n",
        "  json_arr = None\n",
        "  try:\n",
        "    #print(f\"Running '{text_path}'\")\n",
        "    json_arr = call(text_path)\n",
        "    #print(f\"Got json for '{text_path}'\")\n",
        "  except Exception as err:\n",
        "    print(f\"Error for file[{text_path}] is:\\n{err}\")\n",
        "  return json_arr\n",
        "\n",
        "\n",
        "def get_wrong_keyword_dict2(text_path_list):\n",
        "  wrong_keyword_dict = {}\n",
        "  json_arr_list = list(map(get_json_array_list, text_path_list))\n",
        "  wrong_keyword_dict = {\n",
        "    idx: set([list(element.values())[0] for element in json_arr if json_arr is not None]) \n",
        "    for idx, json_arr in enumerate(json_arr_list)\n",
        "  }\n",
        "  return wrong_keyword_dict\n",
        "\n",
        "\n",
        "def get_wrong_keyword_dict(text_files_list, with_thread=False, with_process=False):\n",
        "\n",
        "    def get_sorted_dict(json_arr_list):\n",
        "      wrong_keyword_dict = {\n",
        "        idx: set([list(element.values())[0] for element in json_arr if json_arr]) \n",
        "        for idx, json_arr in enumerate(json_arr_list)\n",
        "      }\n",
        "      return dict(sorted(wrong_keyword_dict.items(), key=lambda item: item[0]))\n",
        "\n",
        "    if with_thread:\n",
        "        # take care so that unnecessary thread should not be created\n",
        "        workers = min(MAX_WORKERS, len(text_files_list))\n",
        "        with futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "            json_arr_list = executor.map(get_json_array_list, text_files_list)\n",
        "        return get_sorted_dict(json_arr_list)\n",
        "    if with_process:\n",
        "        with futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "            json_arr_list = executor.map(get_json_array_list, text_files_list)\n",
        "        return get_sorted_dict(json_arr_list)\n",
        "    else:\n",
        "      json_arr_list = list(map(get_json_array_list, text_files_list))\n",
        "      wrong_keyword_dict = {\n",
        "        idx: set([list(element.values())[0] for element in json_arr if json_arr is not None]) \n",
        "        for idx, json_arr in enumerate(json_arr_list)\n",
        "      }\n",
        "      return wrong_keyword_dict\n",
        "\n",
        "\n",
        "def extract_sentence(wrong_kerword_list, sample_text_list):\n",
        "  match_keyword_dict = {}\n",
        "  # create file to write cordinate \n",
        "  #icd_keyword_found_filename = open(\"icd_keyword_found.txt\", \"w\")\n",
        "  #icd_keyword_found_filename2 = open(\"icd_keyword_match.txt\", \"w\")\n",
        "  for key, kerword_set in wrong_kerword_list.items():\n",
        "    match_dicts = {}\n",
        "    for key_phrase in kerword_set:\n",
        "      #print(key, key_phrase)\n",
        "      keyword_found_output2 = f\"Page-{key} | {key_phrase} |\\n\"\n",
        "      #icd_keyword_found_filename2.write(\"%s\\n\" % keyword_found_output2)\n",
        "\n",
        "      with open(sample_text_list[key], \"r\") as f:\n",
        "        file_txt = f.read()\n",
        "      # match_list = re.findall(f\"([^\\n]*?(?i){key_phrase}[^.]*\\.)\", file_txt)\n",
        "      match_list = re.findall(f\"([^\\n]*{key_phrase}[^\\n]*\\n)\", file_txt)\n",
        "      if match_list:\n",
        "        match_dicts[key_phrase] = [match.replace(\"\\n\", \"\") for match in match_list]\n",
        "    match_keyword_dict[key] = match_dicts\n",
        "    #keyword_found_output = f\"Page-{key} | {key_phrase} | {match_dicts}|\\n\"\n",
        "    #icd_keyword_found_filename.write(\"%s\\n\" % keyword_found_output)\n",
        "\n",
        "  #icd_keyword_found_filename.close()\n",
        "  #icd_keyword_found_filename2.close()\n",
        "  return match_keyword_dict\n",
        "\n",
        "\n",
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "qB-XpoweygN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Classes"
      ],
      "metadata": {
        "id": "9oNqjgIsRpNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Highlighter:\n",
        "  def __init__(self):\n",
        "      # loading and updating patterns for ICD-10 code\n",
        "      self.nlp_code10 = English()\n",
        "      self.nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"icd10_code_patterns-v4.jsonl\")\n",
        "\n",
        "      # define required directory path\n",
        "      self.PDF_FILES_PATH = \"pdf-files\"\n",
        "      self.TXT_FILES_PATH = \"txt-files\"\n",
        "      self.OUTPUT_FILES_PATH = \"output\"\n",
        "      create_directory(self.PDF_FILES_PATH)\n",
        "      create_directory(self.TXT_FILES_PATH)\n",
        "      create_directory(self.OUTPUT_FILES_PATH)\n",
        "\n",
        "\n",
        "  def split_pdf(self, pdf_path):\n",
        "      pdf_in_file = open(pdf_path, \"rb\")\n",
        "      pdf = PdfReader(pdf_in_file)\n",
        "      pdf_list = []\n",
        "      for page in range(len(pdf.pages)):\n",
        "          input_pdf = PdfReader(pdf_in_file)\n",
        "          output = PdfWriter()\n",
        "          #output.addPage(input_pdf.getPage(page))\n",
        "          output.add_page(input_pdf.pages[page])\n",
        "          with open(f\"{self.PDF_FILES_PATH}/page-{page}.pdf\", \"wb\") as outputStream:\n",
        "              output.write(outputStream)\n",
        "              pdf_list.append(f\"page-{page}.pdf\")\n",
        "      return pdf_list\n",
        "\n",
        "  def extract_text_from_pdf(self, pdf_list):\n",
        "      txt_file_list = []\n",
        "      i = 0\n",
        "      for pdf_file in pdf_list:\n",
        "          with open(os.path.join(self.PDF_FILES_PATH, pdf_file), \"rb\") as f:\n",
        "              pdf = pdftotext.PDF(f)\n",
        "\n",
        "          # Read all the text into one string\n",
        "          pdf_text = \"\\n\\n\".join(pdf)\n",
        "\n",
        "          # write text into file\n",
        "          with open(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\", \"a\") as f:\n",
        "              f.write(pdf_text)\n",
        "          txt_file_list.append(f\"{self.TXT_FILES_PATH}/page-{str(i)}.txt\")\n",
        "          i += 1\n",
        "      return txt_file_list\n",
        "\n",
        "  def highlight_icd_code(self, icd10_code_dict, pdf_file_name=None, cords_file_name=None):\n",
        "      pdf_file = fitz.open(pdf_file_name)\n",
        "      # create file to write coordinate\n",
        "      txt_output_file_name = open(f\"{self.OUTPUT_FILES_PATH}/{cords_file_name}\", \"a\")\n",
        "\n",
        "      def highlight_pdf(highlight, icd10_code):\n",
        "          cords_list = []\n",
        "          for inst in highlight:\n",
        "            highlight = page.add_highlight_annot(inst)\n",
        "            highlight.update()\n",
        "            highlight = page.search_for(icd10_code)\n",
        "            cords_list.append(highlight)\n",
        "\n",
        "          if cords_list:\n",
        "            num_page = page_num + 1\n",
        "            code_cors_output = f\"Page-{num_page} | {reverse_code_pattern(icd10_code)} | {cords_list} \\n\"\n",
        "            txt_output_file_name.write(\"%s\\n\" % code_cors_output)\n",
        "\n",
        "      for page_num, page in enumerate(pdf_file):\n",
        "          # highlight ICD-10 code\n",
        "          if page_num in icd10_code_dict:\n",
        "              for code in icd10_code_dict[page_num]:\n",
        "                  highlight = page.search_for(code)\n",
        "                  if len(highlight) == 0:\n",
        "                      alternate_code_list = self.get_opt_pattern(code)\n",
        "                      for alt_code in alternate_code_list:\n",
        "                          highlight = page.search_for(alt_code)\n",
        "                          # highlight pdf for option pattern\n",
        "                          highlight_pdf(highlight, alt_code)\n",
        "                  # highlight pdf for main pattern\n",
        "                  highlight_pdf(highlight, code)\n",
        "\n",
        "      txt_output_file_name.close()\n",
        "\n",
        "      pdf_output_file_name = f\"{self.OUTPUT_FILES_PATH}/{pdf_file_name.split('/')[1].split('.')[0]}_output.pdf\"\n",
        "      pdf_file.save(pdf_output_file_name, garbage=4, deflate=True, clean=True)\n",
        "\n",
        "      return pdf_output_file_name, cords_file_name\n",
        "\n",
        "  def get_opt_pattern(self, icd_10_code):\n",
        "    # create alternate pattern\n",
        "    code_arr = icd_10_code.split(\".\")\n",
        "    if len(code_arr) > 1:\n",
        "      code1 = f\"{code_arr[0]}. {code_arr[1]}\"\n",
        "      code2 = f\"{code_arr[0]} .{code_arr[1]}\"\n",
        "      code3 = f\"{code_arr[0]} . {code_arr[1]}\"\n",
        "      return [code1, code2, code3]\n",
        "    else:\n",
        "      return icd_10_code\n",
        "\n",
        "  def search_icd_code(self, txt_list):\n",
        "    pdf_page_vocab = {}\n",
        "    for txt_file in txt_list:\n",
        "      with open(txt_file, \"r\") as f:\n",
        "        page_txt = f.read()\n",
        "\n",
        "        # check the page that have line number instead of code\n",
        "        index_page = False\n",
        "        if re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", page_txt):\n",
        "          index_page = True\n",
        "\n",
        "        doc = self.nlp_code10(page_txt)\n",
        "        code_list = []\n",
        "        for ent in doc.ents:\n",
        "          if index_page:\n",
        "            # check the code contain letter \"L\"\n",
        "            if re.search(\"(L[0-9]+)\", ent.text):\n",
        "              continue\n",
        "            else:\n",
        "              code_list.append(ent.text)\n",
        "          else:\n",
        "            code_list.append(ent.text)\n",
        "\n",
        "        #code_list = [ent.text for ent in doc.ents if not re.search(\"(P[ ][0-9]+)(,\\s)(L[0-9]+)\", ent.text)]\n",
        "        if len(code_list) != 0:\n",
        "            page_number = int(txt_file.split(\"/\")[1].split(\".\")[0].split(\"-\")[1])\n",
        "            pdf_page_vocab[page_number] = code_list\n",
        "            # print(f\"Page[{txt_file.split('/')[1]}]: {code_list}\")\n",
        "    return pdf_page_vocab\n",
        "\n",
        "\n",
        "def reverse_code_pattern(p_code):\n",
        "  orig_code = \"\"\n",
        "\n",
        "  # check for code contains space(\" \")\n",
        "  tmp_code = p_code.split(\" \")\n",
        "  if len(tmp_code) > 1:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "\n",
        "  # check for code contains dot(\".\")\n",
        "  tmp_code = p_code.split(\".\")\n",
        "  if len(tmp_code) > 1:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "  \n",
        "  # check for code contains comma(\",\")\n",
        "  tmp_code = p_code.split(\",\")\n",
        "  if len(tmp_code) == 2:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[1].strip()}\"\n",
        "  elif len(tmp_code) == 2:\n",
        "    orig_code = f\"{tmp_code[0].strip()}.{tmp_code[2].strip()}\"\n",
        "\n",
        "  # handle if the first char of code is missing\n",
        "  alphabats = {\"Z\": \"2\", \"B\": \"8\", \"O\": \"0\", \"S\": \"5\", \"l\": \"1\", \"G\": \"6\"}\n",
        "  for key, val in alphabats.items():\n",
        "    if orig_code.startswith(val):\n",
        "      orig_code = orig_code.replace(val, key)\n",
        "      break\n",
        "\n",
        "  return orig_code\n",
        "\n",
        "def create_directory(dir_name):\n",
        "  if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)"
      ],
      "metadata": {
        "id": "W0oEZzP_RrlP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceExtractor:\n",
        "  def __init__(self):\n",
        "    self.MAX_WORKERS = 20\n",
        "\n",
        "  def get_json_array_list(self, text_path):\n",
        "    json_arr = None\n",
        "    try:\n",
        "      # print(f\"Running '{text_path}'\")\n",
        "      json_arr = call(text_path)\n",
        "      # print(f\"Got json for '{text_path}'\")\n",
        "    except Exception as err:\n",
        "      print(f\"Error for file[{text_path}] is:\\n{err}\")\n",
        "    return json_arr\n",
        "\n",
        "  def get_wrong_keyword_dict(self, text_files_list, with_thread=False, with_process=False):\n",
        "    def get_sorted_dict(p_json_arr_list):\n",
        "      wrong_keyword_dict = {\n",
        "        idx: set([list(element.values())[0] for element in json_arr if json_arr])\n",
        "        for idx, json_arr in enumerate(p_json_arr_list)\n",
        "      }\n",
        "      return dict(sorted(wrong_keyword_dict.items(), key=lambda item: item[0]))\n",
        "\n",
        "    if with_thread:\n",
        "      # take care so that unnecessary thread should not be created\n",
        "      workers = min(self.MAX_WORKERS, len(text_files_list))\n",
        "      with futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
        "        json_arr_list = executor.map(self.get_json_array_list, text_files_list)\n",
        "      return get_sorted_dict(json_arr_list)\n",
        "    if with_process:\n",
        "      with futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
        "        json_arr_list = executor.map(self.get_json_array_list, text_files_list)\n",
        "      return get_sorted_dict(json_arr_list)\n",
        "    else:\n",
        "      json_arr_list = list(map(self.get_json_array_list, text_files_list))\n",
        "      tmp_wrong_keyword_dict = {\n",
        "        idx: set([list(element.values())[0] for element in json_arr if json_arr is not None])\n",
        "        for idx, json_arr in enumerate(json_arr_list)\n",
        "      }\n",
        "      return tmp_wrong_keyword_dict\n",
        "\n",
        "  def extract_sentence(self, wrong_keyword_list, sample_text_list):\n",
        "    match_keyword_dict = {}\n",
        "    for key, keyword_set in wrong_keyword_list.items():\n",
        "      match_dicts = {}\n",
        "      for key_phrase in keyword_set:\n",
        "        # print(key, key_phrase)\n",
        "        with open(sample_text_list[key], \"r\") as f:\n",
        "          file_txt = f.read()\n",
        "        # match_list = re.findall(f\"([^\\n]*?(?i){key_phrase}[^.]*\\.)\", file_txt)\n",
        "        match_list = re.findall(f\"([^\\n]*{key_phrase}[^\\n]*\\n)\", file_txt)\n",
        "        if match_list:\n",
        "          match_dicts[key_phrase] = [match.replace(\"\\n\", \"\") for match in match_list]\n",
        "      match_keyword_dict[key] = match_dicts\n",
        "    return match_keyword_dict"
      ],
      "metadata": {
        "id": "e2MLJ7q_AA6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Single Searching & Highlighting"
      ],
      "metadata": {
        "id": "N4dDTs-rJL_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v3.jsonl\")\n",
        "\n",
        "# loading and updating patterns for ICD-9 code\n",
        "#nlp_code9 = English()\n",
        "#nlp_code9.add_pipe(\"entity_ruler\").from_disk(\"./icd9_code_patterns-v1.jsonl\")"
      ],
      "metadata": {
        "id": "y8UcOwHpJnpd",
        "outputId": "a077a0ab-27f6-4935-addc-cf41f6d89293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x7f0ddf861c40>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "5i_7mtx2e56B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: spliting pdf file\n",
        "pdf_file_name = \"APS386.pdf\"\n",
        "pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "# Step-2: Extracting text from pdf\n",
        "txt_list = extract_text_from_pdf(pdf_list)"
      ],
      "metadata": {
        "id": "qw22evt02aRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Searching ICD-10 code\n",
        "page_code10_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")"
      ],
      "metadata": {
        "id": "flLgpUfg2ghi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Step-4: Get coloset match of ICD-10 keyword\n",
        "wrong_keyword_dict = get_wrong_keyword_dict(txt_list)\n",
        "# wrong_keyword_dict = get_wrong_keyword_dict(txt_list, with_thread=True)\n",
        "# wrong_keyword_dict = get_wrong_keyword_dict(txt_list, with_process=False)\n",
        "# wrong_keyword_dict = get_wrong_keyword_dict2(txt_list)"
      ],
      "metadata": {
        "id": "f7C3J8jbnzPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953f079e-37e0-437a-b6a9-7a609e3a253f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5min 35s, sys: 13.5 s, total: 5min 49s\n",
            "Wall time: 5min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict[21]"
      ],
      "metadata": {
        "id": "X9swFK9Jsizl",
        "outputId": "2a22c1cf-efaf-49d1-f372-396f26644e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Acute maxillary sinusitis',\n",
              " 'Back Pain',\n",
              " 'Body mass index [BMI]',\n",
              " 'Contact with and (suspected) exposure to COVID-19',\n",
              " 'Cough',\n",
              " 'Dietary counseling and surveillance',\n",
              " 'Elevated blood-pressure reading, without diagnosis of hypertension',\n",
              " 'Hernia',\n",
              " 'Hypertension',\n",
              " 'Hypertriglyceridemia',\n",
              " 'Left lower quadrant pain',\n",
              " 'Low back pain',\n",
              " 'Overweight',\n",
              " 'Prostate Cancer',\n",
              " 'Sciatica',\n",
              " 'Sprain of calcaneofibular ligament',\n",
              " 'Sprain of calcaneofibular ligament of right ankle',\n",
              " 'Sprain of calcaneofibular ligament of right ankle, initial encounter',\n",
              " 'Thrombocytopenia',\n",
              " 'sprain'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Step-5: Extract sentence of ICD-10 keyword\n",
        "icd_keywords_dict = extract_sentence(wrong_keyword_dict, txt_list)"
      ],
      "metadata": {
        "id": "5OaO5U4PnR6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0937f2-70ce-424f-c65e-5b188e5449c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 550 ms, sys: 20.9 ms, total: 571 ms\n",
            "Wall time: 577 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "icd_keywords_dict[21]"
      ],
      "metadata": {
        "id": "DGnsLSzCmh3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-6: Highlighting ICD-10 code and keyword into pdf\n",
        "pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(page_code10_dict, \n",
        "                                                                  icd_keywords_dict=icd_keywords_dict,\n",
        "                                                                  pdf_file_name=\"APS386.pdf\", \n",
        "                                                                  cords_file_name=\"APS386_cords.txt\")\n",
        "print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")"
      ],
      "metadata": {
        "id": "IsgIgN1hB528",
        "outputId": "208aec6b-8156-47cb-b27d-f03cc56362fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File[APS386_output.pdf] is saved after highlighting ICD-10 code and keyword\n",
            "Highlighted coordinates are saved into [APS386_cords.txt] file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Searching & Highlighting"
      ],
      "metadata": {
        "id": "TycHgKTZJ6a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Load prerequisite instance\n",
        "# create nlp instance\n",
        "nlp_keyword = spacy.load('en_core_web_sm')\n",
        "\n",
        "# loading and updating patterns for ICD-10 code\n",
        "nlp_code10 = English()\n",
        "nlp_code10.add_pipe(\"entity_ruler\").from_disk(\"./icd10_code_patterns-v3.jsonl\")"
      ],
      "metadata": {
        "id": "TWMPYgIJJ8xG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd53111e-94f0-4660-f5f0-6d6f00151c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.entityruler.EntityRuler at 0x7fd29c418640>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for pdf_file in os.listdir(ocr_pdf_files_path):\n",
        "  pdf_file_name = f\"{ocr_pdf_files_path}/{pdf_file}\"\n",
        "  cords_file_name = f\"{pdf_file_name.split('.')[0]}_cords.txt\"\n",
        "\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = extract_text_from_pdf(pdf_list)\n",
        "\n",
        "  # Step-3: Searching ICD-10 code\n",
        "  icd10_code_dict = search_icd_code(txt_list, nlp_code10, code_type=\"ICD-10\")\n",
        "\n",
        "  # Step-4: Get coloset match of ICD-10 keyword\n",
        "  wrong_keyword_dict = get_wrong_keyword_dict(txt_list)\n",
        "\n",
        "  # Step-5: Extract sentence of ICD-10 keyword\n",
        "  icd_keywords_dict = extract_sentence(wrong_keyword_dict, txt_list)\n",
        "\n",
        "  # Step-6: Highlighting ICD-10 code and keyword into pdf\n",
        "  pdf_output_file, txt_output_file = highlight_icd_code_and_keyword(icd10_code_dict, \n",
        "                                                                    icd_keywords_dict=icd_keywords_dict,\n",
        "                                                                    pdf_file_name=pdf_file_name, \n",
        "                                                                    cords_file_name=cords_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code and keyword\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "id": "AA7AygDDy06C",
        "outputId": "93cea076-04d5-4189-d0da-ea59d008a81a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File[ocr-pdf-files/APS_38600000R_final_output.pdf] is saved after highlighting ICD-10 code and keyword\n",
            "Highlighted coordinates are saved into [ocr-pdf-files/APS_38600000R_final_cords.txt] file.\n",
            "CPU times: user 5min 46s, sys: 3.74 s, total: 5min 50s\n",
            "Wall time: 5min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ocr-pdf-files ocr-pdf-files2"
      ],
      "metadata": {
        "id": "mdUVrpzCOsOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ocr-pdf-files\n",
        "!mkdir -p ocr-pdf-files"
      ],
      "metadata": {
        "id": "kbTuptfC1xrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ocr-pdf-files2/*.pdf ocr-pdf-files/"
      ],
      "metadata": {
        "id": "Cfh3F3DmOzvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ocr-pdf-files2"
      ],
      "metadata": {
        "id": "gTuKanyTTUjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "purge(\"ocr-pdf-files/*.txt\")\n",
        "purge(\"ocr-pdf-files/*_output.pdf\")\n",
        "purge(\"pdf-files/*.pdf\")\n",
        "purge(\"txt-files/*.txt\")"
      ],
      "metadata": {
        "id": "l06JNkJQ1yGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip ocr-pdf-files/*_cords.txt ocr-pdf-files/*_output.pdf"
      ],
      "metadata": {
        "id": "rZI3lkYT1zxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Class-based Searching & Highlighting"
      ],
      "metadata": {
        "id": "k14TfaJgX-y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"input_pdf_files_path/Redacted_Sample.pdf\".split(\"/\")[1].split(\".\")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QIHrfvqMdYFr",
        "outputId": "ca59350b-012c-462a-99c1-067cef135d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Redacted_Sample'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def purge(file_path):\n",
        "  for f in glob.glob(file_path):\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "-gz3UJ9AJcaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-0: Define prerequisite instance\n",
        "INPUT_PDF_FILES_PATH = \"input_pdf_files_path\"\n",
        "\n",
        "highlighter = Highlighter()"
      ],
      "metadata": {
        "id": "y20Jew29JiqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for pdf_file in os.listdir(INPUT_PDF_FILES_PATH):\n",
        "  pdf_file_name = f\"{INPUT_PDF_FILES_PATH}/{pdf_file}\"\n",
        "  cords_file_name = f\"{pdf_file_name.split('/')[1].split('.')[0]}_cords.txt\"\n",
        "\n",
        "  # Step-1: splitting pdf file\n",
        "  pdf_list = highlighter.split_pdf(pdf_file_name)\n",
        "\n",
        "  # Step-2: Extracting text from pdf\n",
        "  txt_list = highlighter.extract_text_from_pdf(pdf_list)\n",
        "\n",
        "  # Step-3: Searching ICD-10 cod\n",
        "  icd10_code_dict = highlighter.search_icd_code(txt_list)\n",
        "\n",
        "  # Step-4: Highlighting ICD-10 code into pdf\n",
        "  pdf_output_file, txt_output_file = highlighter.highlight_icd_code(icd10_code_dict,\n",
        "                                                                    pdf_file_name=pdf_file_name,\n",
        "                                                                    cords_file_name=cords_file_name)\n",
        "  print(f\"File[{pdf_output_file}] is saved after highlighting ICD-10 code\")\n",
        "  print(f\"Highlighted coordinates are saved into [{txt_output_file}] file.\")\n",
        "\n",
        "  # remove all pdf and text files\n",
        "  purge(\"pdf-files/*.pdf\")\n",
        "  purge(\"txt-files/*.txt\")\n",
        "  pdf_list = []\n",
        "  txt_list = []"
      ],
      "metadata": {
        "id": "8Jebcbz4YChR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input_pdf_files_path\n",
        "!mkdir -p input_pdf_files_path"
      ],
      "metadata": {
        "id": "gsxg17J0kLdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output"
      ],
      "metadata": {
        "id": "7biDWeNPmHXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output.zip output/*.*"
      ],
      "metadata": {
        "id": "OF-Bc6axsumx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Keyword Matching & Highlighting "
      ],
      "metadata": {
        "id": "7s7ZxYMUBAol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Step 1 - Z87.5\n",
        "- Step 2 - Personal history of complications of pregnancy, childbirth and the puerperium\n",
        "- Step 3 - Page keyword\n",
        "- Step 4 - calculate cosine similirity\n",
        "- Step 5 - \"Green\" > 60% otherwise \"Yellow\""
      ],
      "metadata": {
        "id": "9KDyJlx9bIH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "highlighter = Highlighter()"
      ],
      "metadata": {
        "id": "leBmw505CQUl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_extractor = SentenceExtractor()"
      ],
      "metadata": {
        "id": "0xY2eW4sGiKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: spliting pdf file\n",
        "pdf_file_name = \"APS_38600000R_final.pdf\"\n",
        "pdf_list = highlighter.split_pdf(pdf_file_name)\n",
        "\n",
        "# Step-2: Extracting text from pdf\n",
        "txt_list = highlighter.extract_text_from_pdf(pdf_list)"
      ],
      "metadata": {
        "id": "GJrJ862VBKhE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Searching ICD-10 code\n",
        "page_code10_dict = highlighter.search_icd_code(txt_list)"
      ],
      "metadata": {
        "id": "wTFQkZtHBiLO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Step-4: Get coloset match of ICD-10 keyword\n",
        "wrong_keyword_dict = sent_extractor.get_wrong_keyword_dict(txt_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nexq5ERBim2",
        "outputId": "64fab4ac-e252-482e-cee2-e5a0b3bbf2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5min 38s, sys: 1.83 s, total: 5min 40s\n",
            "Wall time: 5min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict[21]"
      ],
      "metadata": {
        "id": "Zch6FJgmBxlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_code10_dict[21]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stm7poqQBx-e",
        "outputId": "261c2f09-691f-478e-e6d4-8c4178a6926b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Z68.25',\n",
              " '278.9',\n",
              " 'E78.3',\n",
              " 'R03',\n",
              " 'R05',\n",
              " 'R05',\n",
              " 'R53.83',\n",
              " '268.25',\n",
              " 'Z78.9',\n",
              " 'E78.3',\n",
              " 'R05',\n",
              " 'J01.00',\n",
              " 'E78.3',\n",
              " 'Z00.00',\n",
              " 'E78.3',\n",
              " 'R50.9',\n",
              " 'R50.9',\n",
              " 'L73.9',\n",
              " 'Z78.9',\n",
              " 'Z68.25',\n",
              " 'Z00.00',\n",
              " '212.5',\n",
              " '287.5',\n",
              " 'D69.6',\n",
              " 'Z78.9',\n",
              " '268.25',\n",
              " 'E78.3',\n",
              " '268.25',\n",
              " 'J01.00',\n",
              " '268.25',\n",
              " 'R10.32',\n",
              " 'Z78.9',\n",
              " 'K46.9',\n",
              " 'Z68.25',\n",
              " 'J01.00',\n",
              " 'Z78.9',\n",
              " 'S93.411A',\n",
              " 'M54.5',\n",
              " 'Z78.9',\n",
              " 'Z68.25']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_keyword_dict[21]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeJNRKZdKZ50",
        "outputId": "50bc16bc-75c1-4892-bde3-3569d76afab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Acute maxillary sinusitis',\n",
              " 'Back Pain',\n",
              " 'Body mass index [BMI]',\n",
              " 'Contact with and (suspected) exposure to COVID-19',\n",
              " 'Cough',\n",
              " 'Dietary counseling and surveillance',\n",
              " 'Elevated blood-pressure reading, without diagnosis of hypertension',\n",
              " 'Hernia',\n",
              " 'Hypertension',\n",
              " 'Hypertriglyceridemia',\n",
              " 'Left lower quadrant pain',\n",
              " 'Low back pain',\n",
              " 'Overweight',\n",
              " 'Prostate Cancer',\n",
              " 'Sciatica',\n",
              " 'Sprain of calcaneofibular ligament',\n",
              " 'Sprain of calcaneofibular ligament of right ankle',\n",
              " 'Sprain of calcaneofibular ligament of right ankle, initial encounter',\n",
              " 'Thrombocytopenia',\n",
              " 'sprain'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt_list[21]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1cqncdV0Lpj7",
        "outputId": "f988daf6-8a7b-4814-8aff-476595b85639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'txt-files/page-21.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword1 = \"Body mass index [BMI] 25.0-25.9, adult\"\n",
        "keyword2 = \"Body mass index [BMI]\"\n",
        "\n",
        "SequenceMatcher(None, keyword1, keyword2).ratio()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrWQ0QD6Ny6o",
        "outputId": "c47e69c7-bc2e-438a-db10-849bbace45c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.711864406779661"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for keyword in wrong_keyword_dict[21]:\n",
        "  seq = SequenceMatcher(None, keyword, keyword1)\n",
        "  print(f\"{round(seq.ratio(), 3)} : {keyword}\")\n",
        "  if round(seq.ratio(), 3) > .70:\n",
        "    print(f\"Max ratio found: {round(seq.ratio(), 3)} : {keyword}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywx50dACOT5I",
        "outputId": "6b7c8b27-5fc2-495c-b675-cabab5e39e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.093 : brace\n",
            "0.184 : Contact with and (suspected) exposure to COVID-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_keyword = \"Unspecified abdominal hernia without obstruction or gangrene\"\n",
        "max([SequenceMatcher(None, keyword, curr_keyword).ratio() for keyword in wrong_keyword_dict[21]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXYuRToRRRZJ",
        "outputId": "6319ffc5-f81c-4dd6-cced-7ef1c3eeec61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38095238095238093"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{txt_list[21]}\", \"r\") as f:\n",
        "  my_text = f.read()"
      ],
      "metadata": {
        "id": "ZQbtFeu6V299"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text.split(\"\\n\")"
      ],
      "metadata": {
        "id": "7StZaPWdWGI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_phrase_list = [[key_phrase for key_phrase in textlist.split(\",\") if len(key_phrase) > 0] for textlist in my_text.split(\"\\n\")]\n",
        "len(key_phrase_list)"
      ],
      "metadata": {
        "id": "CmitUQMAV6-V",
        "outputId": "0bd62830-06a1-4793-d117-f6d20d0cb46c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_phrase_list"
      ],
      "metadata": {
        "id": "ItvgVMIVWlr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_phrase_list = []\n",
        "for textlist in my_text.split(\"\\n\"):\n",
        "  for key_phrase in textlist.split(\",\"):\n",
        "    if len(key_phrase) > 0:\n",
        "      key_phrase_list.append(key_phrase)"
      ],
      "metadata": {
        "id": "4_6UiqKAPiuU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(key_phrase_list)"
      ],
      "metadata": {
        "id": "AvAh0QCcVvAq",
        "outputId": "96699192-c661-43d5-916e-687e73216246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_phrase_list"
      ],
      "metadata": {
        "id": "tbrI-QJ0WryZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key_phrase in key_phrase_list:\n",
        "  seq = SequenceMatcher(None, key_phrase, \"Non-smoker\")\n",
        "  print(f\"{round(seq.ratio(), 3)} : {key_phrase}\")\n",
        "  if round(seq.ratio(), 3) > .70:\n",
        "    print(f\"Max ratio found: {round(seq.ratio(), 3)} : {key_phrase}\")"
      ],
      "metadata": {
        "id": "5ipGl3T2Xpf0",
        "outputId": "77388f88-8973-4793-bddd-c0f4abbd7df2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.381 :  Encounters\n",
            "0.211 : Encounter 21 Date 12/28/202'\n",
            "0.145 : Diagnosis Contact with and (suspected) exposure to COVID-19\n",
            "0.211 : Encounter 20 Date 12/27/2021\n",
            "0.147 : Diagnosis Contact with and (suspected) exposureto COVID-19\n",
            "0.083 :           Body mass index (BMI) of 25.0-25.9 in adult (268.25)\n",
            "0.645 :    Non-smoker (278.9)\n",
            "0.211 : Encounter 19 Date 12/09/2021\n",
            "0.129 : ROO)        Sinusitis\n",
            "0.125 :  acute\n",
            "0.222 :  frontal\n",
            "0.129 :  Hypertriglyceridemia\n",
            "0.222 :  sporadic (E78.3)\n",
            "0.104 :   Elevated blood pressure reading without diagnosis of hypertension\n",
            "0.0 : (R03.\n",
            "0.211 : Encounter 18 Date 03/25/2021\n",
            "0.129 : Diagnosis Contact with and (suspected) exposureto other viral communicable diseases\n",
            "0.091 :  Cough (R05)\n",
            "0.211 : Encounter 17 Date 03/25/2021\n",
            "0.159 : Diagnosis Contact with/suspected exposure to COVID-19\n",
            "0.067 :          Cough (R05)\n",
            "0.074 :  Fatigue (R53.83)\n",
            "0.103 :  Overweight (BMI 25.0 - 29.9)\n",
            "0.188 :  Body mass index (BMI)\n",
            "0.1 : of 25.0-25.9 in adult (268.25)\n",
            "0.69 :  Non-smoker (Z78.9)\n",
            "0.211 : Encounter 16 Date 01/25/2021\n",
            "0.2 : Diagnosis Hypertriglyceridemia\n",
            "0.182 :  sporadic      ( E78.3)\n",
            "0.211 : Encounter 15 Date 12/23/2020\n",
            "0.129 : Diagnosis Cough (R05)\n",
            "0.211 : Encounter 14 Date 12/23/2020\n",
            "0.118 : Diagnosis Acute non-recurrent maxillary sinusitis (JO1.00)\n",
            "0.114 :      Hypertriglyceridemia\n",
            "0.222 :  sporadic (E78.3)\n",
            "0.211 : Encounter 13 Date 12/16/2020\n",
            "0.136 : Diagnosis Influenza vaccine needed\n",
            "0.186 : Encounter    12   Date 05/08/2020\n",
            "0.089 : Diagnosis Routine general medical examination at a health care facility (200.00)\n",
            "0.129 :  Hypertriglyceridemia\n",
            "0.222 :  sporadic (E78.3)\n",
            "0.211 : Encounter 11 Date 04/02/2020\n",
            "0.242 : Diagnosis Fever (R50.9)\n",
            "0.2 :  Sinusitis\n",
            "0.125 :  acute\n",
            "0.167 :      maxillary\n",
            "0.211 : Encounter 10 Date 03/30/2020\n",
            "0.242 : Diagnosis Fever (R50.9)\n",
            "0.216 : Encounter 9 Date 02/05/2020\n",
            "0.1 : Diagnosis Folliculitis (L73.9)\n",
            "0.69 :  Non-smoker (278.9)\n",
            "0.103 :  Overweight (BMI 25.0 - 29.9)\n",
            "0.095 :  Body mass index (BMI) of 26.0-25.9 in adult (268.25)\n",
            "0.154 :          Dietary\n",
            "0.27 : counseling and surveillance\n",
            "0.216 : Encounter 8 Date 12/18/2019\n",
            "0.091 : Diagnosis Encntr for general adult medical exam w/o abnormal findings (200.00)\n",
            "0.167 :  Screening for prostate cancer (212.5)\n",
            "0.216 : Encounter 7 Date 12/12/2019\n",
            "0.138 : Diagnosis Sinusitis\n",
            "0.125 :  acute\n",
            "0.2 :  maxillary\n",
            "0.047 :  Thrombocytopenia (287.5) (D69.6)\n",
            "0.69 :  Non-smoker (278.9)\n",
            "0.103 :  Overweight (BMI 25.0 - 29.9)\n",
            "0.231 :  Body mass index\n",
            "0.087 : (BMI) of 25.0-25.9 in adult (268.25)\n",
            "0.087 :  Dietary counseling and surveillance\n",
            "0.216 : Encounter 6 Date 11/25/2019\n",
            "0.205 : Diagnosis Hypertrig ceridemia\n",
            "0.222 :  sporadic (E78.3)\n",
            "0.103 :  Overweight (BMI 25.0 - 29.9)\n",
            "0.083 :  Body          mass index (BMI) of 25.0-25.9 in adult (268.25)\n",
            "0.211 :   Dietary\n",
            "0.27 : counseling and surveillance\n",
            "0.114 :  Influenza vaccine needed\n",
            "0.1 :  Triggering of finger (M6. 30)\n",
            "0.216 : Encounter 5 Date 02/22/2019\n",
            "0.148 : Diagnosis Acute maxillary sinusitis (J01.00)\n",
            "0.095 :  Body mass index (BMI) of 25.0-25.9 in adult (268.25)\n",
            "0.216 : Encounter 4 Date 10/31/2018\n",
            "0.151 : Diagnosis Left lower quadrant pain (R10.32)\n",
            "0.69 :  Non-smoker (Z78.9)\n",
            "0.16 :  Hernia (K46.9)\n",
            "0.103 :  Overweight (BMI 25.0 - 29.9)\n",
            "0.171 :  Body mass index (BMI) of\n",
            "0.054 : 25.0-25.9 in adult (268.25)\n",
            "0.087 :  Dietary counseling and surveillance\n",
            "0.216 : Encounter 3 Date 09/14/2018\n",
            "0.118 : Diagnosis Acute non-recurrent maxillary sinusitis (JO1.00)\n",
            "0.606 :      Non-smoker (Z78.9)\n",
            "0.216 : Encounter 2 Date 05/10/2018\n",
            "0.087 : Diagnosis Sprain of calcaneofibular ligament of right ankle\n",
            "0.2 :  initial encounter (S93.41 1A)\n",
            "0.216 : Encounter 1 Date 01/17/2018\n",
            "0.108 : Diagnosis Chronic midline low back pain without sciatica (M54.5)\n",
            "0.571 :        Non-smoker (Z78.9)\n",
            "0.103 :  Overweight (BMI 25.0 - 29.9)\n",
            "0.171 :  Body mass index (BMI) of\n",
            "0.054 : 25.0-25.9 in adult (268.25)\n",
            "0.087 :  Dietary counseling and surveillance\n",
            "0.025 : 06/28/2022 12:27 pm                                          ll       lh                                                                    Page 2/144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max([SequenceMatcher(None, key_phrase, \"Non-smoker\").ratio() for key_phrase in key_phrase_list])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWArMd6QWb-D",
        "outputId": "e2b0b6d0-20fb-4ae7-aaf5-34842934dd2c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6896551724137931"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similarity_score(keyword, text_file):\n",
        "  # load text file\n",
        "  with open(text_file, \"r\") as f:\n",
        "    my_text = f.read()\n",
        "\n",
        "  # prepare key phrase\n",
        "  key_phrase_list = []\n",
        "  for textlist in my_text.split(\"\\n\"):\n",
        "    for key_phrase in textlist.split(\",\"):\n",
        "      if len(key_phrase) > 0:\n",
        "        key_phrase_list.append(key_phrase)\n",
        "  # return max similarity score\n",
        "  return max([SequenceMatcher(None, k_phrase, keyword).ratio() for k_phrase in key_phrase_list])"
      ],
      "metadata": {
        "id": "w6oOPyyNcd4E"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_similarity_score(\"Non-smoker\", txt_list[21])"
      ],
      "metadata": {
        "id": "wikn8KpBd2VT",
        "outputId": "5fab1469-80d9-4f63-8359-307d64dfffe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6896551724137931"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = \"Diagnosis Left lower quadrant pain (R10.32), Non-smoker (Z78.9), Hernia (K46.9), Overweight (BMI 25.0 - 29.9), Body mass index (BMI) of\"\n",
        "\n",
        "max([SequenceMatcher(None, my_text, \"Hernia\").ratio() for my_text in my_text.split(\",\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48gIw7FtWnCO",
        "outputId": "75c736e6-aaa7-48a0-e0f8-82ce4fcbec16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5714285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for keyword in my_text.split(\",\"):\n",
        "  seq = SequenceMatcher(None, keyword, \"Hernia\")\n",
        "  print(f\"{round(seq.ratio(), 3)} : {keyword}\")\n",
        "  if round(seq.ratio(), 3) > .70:\n",
        "    print(f\"Max ratio found: {round(seq.ratio(), 3)} : {keyword}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBZpE5-zZYlf",
        "outputId": "595a2636-7db8-4b99-b799-a29007189281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.082 : Diagnosis Left lower quadrant pain (R10.32)\n",
            "0.16 :  Non-smoker (Z78.9)\n",
            "0.571 :  Hernia (K46.9)\n",
            "0.171 :  Overweight (BMI 25.0 - 29.9)\n",
            "0.065 :  Body mass index (BMI) of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_string = \"the cat and this dog are in the garden\"    \n",
        "splitted = my_string.split(\"dog\")\n",
        "\n",
        "first = my_string.split(\"dog\")[:2]\n",
        "second = my_string.split(\"dog\")[2:]\n",
        "print(first, second)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlJFryoLXR67",
        "outputId": "2515460d-0591-42ae-e942-1f737f4664fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the cat and this ', ' are in the garden'] []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_string.split(\"dog\")[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-KBtrMj3YK_Z",
        "outputId": "c4da089e-eecc-47a7-ac5c-505ecd9c482f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}